{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dp4g6lliBrLI",
    "outputId": "c90cefd7-c969-4694-8bca-e18225a39d82",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/ElectronicHug/distil-whisper.git\n",
    "# !pip install -r /content/distil-whisper/training/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "oHHw0XpyBsLh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cp /content/distil-whisper/training/create_student_model.py /content/create_student_model.py\n",
    "# !cp /content/distil-whisper/training/run_pseudo_labelling.py /content/run_pseudo_labelling.py\n",
    "# !cp /content/distil-whisper/training/run_distillation.py /content/run_distillation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HrIfSoVZBtys",
    "outputId": "bfbfa883-87b8-47e6-e815-acf524ffc842",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: read).\n",
      "Your token has been saved in your configured git credential helpers (manager,store).\n",
      "Your token has been saved to C:\\Users\\Zhenya\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='', add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "90ce_YgqBvK_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import os\n",
    "# You can also adapt this script for your own pseudo-labelling tasks. Pointers for this are left as comments.\n",
    "import logging\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from accelerate import Accelerator, InitProcessGroupKwargs\n",
    "from accelerate.logging import get_logger\n",
    "from datasets import (\n",
    "    DatasetDict,\n",
    "    IterableDatasetDict,\n",
    "    load_dataset,\n",
    ")\n",
    "from huggingface_hub import HfFolder, Repository, create_repo, get_full_repo_name\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    WhisperConfig,\n",
    "    WhisperFeatureExtractor,\n",
    "    WhisperForConditionalGeneration,\n",
    "    WhisperProcessor,\n",
    "    WhisperTokenizerFast,\n",
    ")\n",
    "from transformers.models.whisper.english_normalizer import EnglishTextNormalizer, BasicTextNormalizer\n",
    "from transformers.utils import check_min_version\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "\n",
    "# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n",
    "check_min_version(\"4.34.0.dev0\")\n",
    "\n",
    "require_version(\"datasets>=2.14.6\", \"To fix: `pip install --upgrade datasets`\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FgmRr9JYByjo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ME9Ez_3IBzpk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from run_pseudo_labelling import (ModelArguments, DataTrainingArguments, shift_tokens_right,\n",
    "                                  DataCollatorSpeechSeq2SeqWithPadding, log_metric, log_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oONkHi5LB2nr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Parse input arguments\n",
    "# We keep distinct sets of args, for cleaner separation of model/data/training related args\n",
    "parser = HfArgumentParser((ModelArguments, DataTrainingArguments, Seq2SeqTrainingArguments))\n",
    "\n",
    "list_args = [\n",
    "'--model_name_or_path=./local_whisper_medium',\n",
    "# '--dataset_name=mozilla-foundation/common_voice_13_0',\n",
    "# '--dataset_config_name=en',\n",
    "# '--dataset_split_name=train+validation+test',\n",
    "'--text_column_name=text',\n",
    "'--id_column_name=file',\n",
    "'--output_dir=librespeach_labeled',\n",
    "# '--wandb_project=distil-whisper-labelling-v2',\n",
    "'--per_device_eval_batch_size=32',\n",
    "'--dtype=float16',\n",
    "'--dataloader_num_workers=4',\n",
    "'--preprocessing_num_workers=4',\n",
    "'--logging_steps=100',\n",
    "'--max_label_length=128',\n",
    "'--task=transcribe',\n",
    "#'--attn_type=None',\n",
    "# '--streaming=True',\n",
    "'--generation_num_beams=1',\n",
    "'--decode_token_ids=False',\n",
    "'--cache_dir=model_cache/',\n",
    "'--dataset_cache_dir=cache',\n",
    "'--preprocessing_only=False',\n",
    "'--report_to=wandb'\n",
    "]\n",
    "\n",
    "model_args, data_args, training_args = parser.parse_args_into_dataclasses(list_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Ll-sNdIkCIqS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# raw_datasets = load_dataset(\"librispeech_asr\", \"clean\",\n",
    "#  cache_dir='hug_libra_raw_dataset/cache',\n",
    "#  split= ['train.100', 'validation', 'test'],\n",
    "#  data_dir='hug_libra_raw_dataset/dataset',)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QsZuufguOH7X",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Fd038a96OGtk",
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such files: 'F:/distiling_whisper_local/raw_datasets/train.360/dataset_info.json', nor 'F:/distiling_whisper_local/raw_datasets/train.360/state.json' found. Expected to load a `Dataset` object but provided path is not a `Dataset`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m raw_datasets \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraw_datasets/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\anaconda\\envs\\disenv\\lib\\site-packages\\datasets\\load.py:2239\u001b[0m, in \u001b[0;36mload_from_disk\u001b[1;34m(dataset_path, fs, keep_in_memory, storage_options)\u001b[0m\n\u001b[0;32m   2237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39mload_from_disk(dataset_path, keep_in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory, storage_options\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m   2238\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m fs\u001b[38;5;241m.\u001b[39misfile(posixpath\u001b[38;5;241m.\u001b[39mjoin(dataset_path, config\u001b[38;5;241m.\u001b[39mDATASETDICT_JSON_FILENAME)):\n\u001b[1;32m-> 2239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDatasetDict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   2242\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is neither a `Dataset` directory nor a `DatasetDict` directory.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2243\u001b[0m     )\n",
      "File \u001b[1;32mF:\\anaconda\\envs\\disenv\\lib\\site-packages\\datasets\\dataset_dict.py:1356\u001b[0m, in \u001b[0;36mDatasetDict.load_from_disk\u001b[1;34m(dataset_dict_path, fs, keep_in_memory, storage_options)\u001b[0m\n\u001b[0;32m   1354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m splits:\n\u001b[0;32m   1355\u001b[0m     dataset_dict_split_path \u001b[38;5;241m=\u001b[39m posixpath\u001b[38;5;241m.\u001b[39mjoin(fs\u001b[38;5;241m.\u001b[39munstrip_protocol(dataset_dict_path), k)\n\u001b[1;32m-> 1356\u001b[0m     dataset_dict[k] \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_disk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_dict_split_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset_dict\n",
      "File \u001b[1;32mF:\\anaconda\\envs\\disenv\\lib\\site-packages\\datasets\\arrow_dataset.py:1663\u001b[0m, in \u001b[0;36mDataset.load_from_disk\u001b[1;34m(dataset_path, fs, keep_in_memory, storage_options)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dataset_dict_is_file:\n\u001b[0;32m   1660\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1661\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such files: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_info_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, nor \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_state_json_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m found. Expected to load a `Dataset` object, but got a `DatasetDict`. Please use either `datasets.load_from_disk` or `DatasetDict.load_from_disk` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1662\u001b[0m         )\n\u001b[1;32m-> 1663\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1664\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such files: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_info_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, nor \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_state_json_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m found. Expected to load a `Dataset` object but provided path is not a `Dataset`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1665\u001b[0m     )\n\u001b[0;32m   1666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dataset_info_is_file:\n\u001b[0;32m   1667\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dataset_dict_is_file:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such files: 'F:/distiling_whisper_local/raw_datasets/train.360/dataset_info.json', nor 'F:/distiling_whisper_local/raw_datasets/train.360/state.json' found. Expected to load a `Dataset` object but provided path is not a `Dataset`."
     ]
    }
   ],
   "source": [
    "raw_datasets = load_from_disk('raw_datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "BAjwkFbJFV2I",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_splits = [\n",
    "    'train.100', 'validation','test']\n",
    "# 'train.360',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "q9wDSlkLFDsx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 3. Load dataset\n",
    "# raw_datasets = IterableDatasetDict() if data_args.streaming else DatasetDict()\n",
    "# token = model_args.token if model_args.token is not None else HfFolder().get_token()\n",
    "\n",
    "# data_splits = data_args.dataset_split_name.split(\"+\")\n",
    "# for split in data_splits:\n",
    "#     print(split)\n",
    "#     if data_args.streaming:\n",
    "#         raw_datasets[split] = load_dataset(\n",
    "#             data_args.dataset_name,\n",
    "#             data_args.dataset_config_name,\n",
    "#             split=split,\n",
    "#             cache_dir=data_args.dataset_cache_dir,\n",
    "#             token=token,\n",
    "#             streaming=True,\n",
    "#         )\n",
    "#     else:\n",
    "#         raw_datasets[split] = load_dataset(\n",
    "#             data_args.dataset_name,\n",
    "#             data_args.dataset_config_name,\n",
    "#             split=split,\n",
    "#             cache_dir=data_args.dataset_cache_dir,\n",
    "#             token=token,\n",
    "#             streaming=False,\n",
    "#             num_proc=data_args.preprocessing_num_workers,\n",
    "#         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accelerator = Accelerator(\n",
    "    gradient_accumulation_steps=training_args.gradient_accumulation_steps,\n",
    "    mixed_precision=mixed_precision,\n",
    "    log_with='wandb',#training_args.report_to,\n",
    "    project_dir=training_args.output_dir,\n",
    "    kwargs_handlers=[kwargs],\n",
    ")\n",
    "\n",
    "accelerator.init_trackers(project_name=data_args.wandb_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "id": "bfbouFpkEqcL",
    "outputId": "7b836f95-7b85-466c-ac1c-79732af56ed5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/20/2024 21:01:35 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "01/20/2024 21:01:35 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=4,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_config=None,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=librespeach_labeled\\runs\\Jan20_20-55-36_DESKTOP-9H5C6TS,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=100,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "output_dir=librespeach_labeled,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=16,\n",
      "per_device_train_batch_size=8,\n",
      "predict_with_generate=False,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['wandb'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=librespeach_labeled,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "split_batches=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 2. Initialize the accelerator\n",
    "# We will let the accelerator handle device placement for us in this example\n",
    "# We simply have to specify the training precision and any trackers being used\n",
    "# We'll use the same dtype arguments as our JAX/Flax training script and convert\n",
    "# it to accelerate format\n",
    "if model_args.dtype == \"float16\":\n",
    "    mixed_precision = \"fp16\"\n",
    "    torch_dtype = torch.float16\n",
    "elif model_args.dtype == \"bfloat16\":\n",
    "    mixed_precision = \"bf16\"\n",
    "    torch_dtype = torch.bfloat160\n",
    "else:\n",
    "    mixed_precision = \"no\"\n",
    "    torch_dtype = torch.float32\n",
    "\n",
    "kwargs = InitProcessGroupKwargs(timeout=timedelta(seconds=7200))\n",
    "\n",
    "accelerator = Accelerator(\n",
    "    gradient_accumulation_steps=training_args.gradient_accumulation_steps,\n",
    "    mixed_precision=mixed_precision,\n",
    "    log_with=training_args.report_to,\n",
    "    project_dir=training_args.output_dir,\n",
    "    kwargs_handlers=[kwargs],\n",
    ")\n",
    "\n",
    "accelerator.init_trackers(project_name=data_args.wandb_project)\n",
    "\n",
    "# 3. Set-up basic logging\n",
    "# Create one log on every process with the configuration for debugging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "# Log a small summary on each proces\n",
    "logger.warning(\n",
    "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}, \"\n",
    "    f\"distributed training: {training_args.parallel_mode.value == 'distributed'}, 16-bits training: {training_args.fp16}\"\n",
    ")\n",
    "\n",
    "\n",
    "# Set the verbosity to info of the Transformers logger (on main process only)\n",
    "if accelerator.is_local_main_process:\n",
    "    datasets.utils.logging.set_verbosity_warning()\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "else:\n",
    "    datasets.utils.logging.set_verbosity_error()\n",
    "    transformers.utils.logging.set_verbosity_error()\n",
    "logger.info(\"Training/evaluation parameters %s\", training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "vmxoOpoeHYxr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if data_args.audio_column_name not in next(iter(raw_datasets.values())).column_names:\n",
    "    raise ValueError(\n",
    "        f\"--audio_column_name '{data_args.audio_column_name}' not found in dataset\"\n",
    "        f\" '{data_args.dataset_name}'. Make sure to set `--audio_column_name` to\"\n",
    "        \" the correct audio column - one of\"\n",
    "        f\" {', '.join(next(iter(raw_datasets.values())).column_names)}.\"\n",
    "    )\n",
    "\n",
    "if data_args.text_column_name not in next(iter(raw_datasets.values())).column_names:\n",
    "    raise ValueError(\n",
    "        f\"--text_column_name {data_args.text_column_name} not found in dataset\"\n",
    "        f\" '{data_args.dataset_name}'. Make sure to set `--text_column_name` to the\"\n",
    "        \" correct text column - one of\"\n",
    "        f\" {', '.join(next(iter(raw_datasets.values())).column_names)}.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "DH9uZ_iwLPKj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "token = model_args.token if model_args.token is not None else HfFolder().get_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jISUEsooHeX_",
    "outputId": "084bf907-9fbb-4f84-ab84-09250b658dd0",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7682a9d05847f1830a004c3e394653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.99k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\353117b351a2a3d740c3bdbba1396b06e2499bde\\config.json\n",
      "Model config WhisperConfig {\n",
      "  \"_name_or_path\": \"openai/whisper-medium\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"apply_spec_augment\": false,\n",
      "  \"architectures\": [\n",
      "    \"WhisperForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50257\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 24,\n",
      "  \"decoder_start_token_id\": 50258,\n",
      "  \"dropout\": 0.0,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 24,\n",
      "  \"eos_token_id\": 50257,\n",
      "  \"forced_decoder_ids\": [\n",
      "    [\n",
      "      1,\n",
      "      50259\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      50359\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      50363\n",
      "    ]\n",
      "  ],\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"max_length\": 448,\n",
      "  \"max_source_positions\": 1500,\n",
      "  \"max_target_positions\": 448,\n",
      "  \"median_filter_width\": 7,\n",
      "  \"model_type\": \"whisper\",\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_mel_bins\": 80,\n",
      "  \"pad_token_id\": 50257,\n",
      "  \"scale_embedding\": false,\n",
      "  \"suppress_tokens\": [\n",
      "    1,\n",
      "    2,\n",
      "    7,\n",
      "    8,\n",
      "    9,\n",
      "    10,\n",
      "    14,\n",
      "    25,\n",
      "    26,\n",
      "    27,\n",
      "    28,\n",
      "    29,\n",
      "    31,\n",
      "    58,\n",
      "    59,\n",
      "    60,\n",
      "    61,\n",
      "    62,\n",
      "    63,\n",
      "    90,\n",
      "    91,\n",
      "    92,\n",
      "    93,\n",
      "    359,\n",
      "    503,\n",
      "    522,\n",
      "    542,\n",
      "    873,\n",
      "    893,\n",
      "    902,\n",
      "    918,\n",
      "    922,\n",
      "    931,\n",
      "    1350,\n",
      "    1853,\n",
      "    1982,\n",
      "    2460,\n",
      "    2627,\n",
      "    3246,\n",
      "    3253,\n",
      "    3268,\n",
      "    3536,\n",
      "    3846,\n",
      "    3961,\n",
      "    4183,\n",
      "    4667,\n",
      "    6585,\n",
      "    6647,\n",
      "    7273,\n",
      "    9061,\n",
      "    9383,\n",
      "    10428,\n",
      "    10929,\n",
      "    11938,\n",
      "    12033,\n",
      "    12331,\n",
      "    12562,\n",
      "    13793,\n",
      "    14157,\n",
      "    14635,\n",
      "    15265,\n",
      "    15618,\n",
      "    16553,\n",
      "    16604,\n",
      "    18362,\n",
      "    18956,\n",
      "    20075,\n",
      "    21675,\n",
      "    22520,\n",
      "    26130,\n",
      "    26161,\n",
      "    26435,\n",
      "    28279,\n",
      "    29464,\n",
      "    31650,\n",
      "    32302,\n",
      "    32470,\n",
      "    36865,\n",
      "    42863,\n",
      "    47425,\n",
      "    49870,\n",
      "    50254,\n",
      "    50258,\n",
      "    50358,\n",
      "    50359,\n",
      "    50360,\n",
      "    50361,\n",
      "    50362\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 51865\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063a72b403a6483ab8f7b6e9ba84f19b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file preprocessor_config.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\353117b351a2a3d740c3bdbba1396b06e2499bde\\preprocessor_config.json\n",
      "Feature extractor WhisperFeatureExtractor {\n",
      "  \"chunk_length\": 30,\n",
      "  \"feature_extractor_type\": \"WhisperFeatureExtractor\",\n",
      "  \"feature_size\": 80,\n",
      "  \"hop_length\": 160,\n",
      "  \"n_fft\": 400,\n",
      "  \"n_samples\": 480000,\n",
      "  \"nb_max_frames\": 3000,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0.0,\n",
      "  \"processor_class\": \"WhisperProcessor\",\n",
      "  \"return_attention_mask\": false,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece809a7c6594241a867b058396f0b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/805 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad0954a936e474e96916c1f13a99566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d34ce671a1421cb6e3050cd491ffe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b445c8c358494d37a037ca43ecb9a3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0adf683ea1940d4aa9d1d099a8999d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f1241a9fba430090e0041662e8aacd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea4326528ad4cc898341e1da9fb11bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\353117b351a2a3d740c3bdbba1396b06e2499bde\\vocab.json\n",
      "loading file tokenizer.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\353117b351a2a3d740c3bdbba1396b06e2499bde\\tokenizer.json\n",
      "loading file merges.txt from cache at model_cache/models--openai--whisper-medium\\snapshots\\353117b351a2a3d740c3bdbba1396b06e2499bde\\merges.txt\n",
      "loading file normalizer.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\353117b351a2a3d740c3bdbba1396b06e2499bde\\normalizer.json\n",
      "loading file added_tokens.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\353117b351a2a3d740c3bdbba1396b06e2499bde\\added_tokens.json\n",
      "loading file special_tokens_map.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\353117b351a2a3d740c3bdbba1396b06e2499bde\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\353117b351a2a3d740c3bdbba1396b06e2499bde\\tokenizer_config.json\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file preprocessor_config.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\353117b351a2a3d740c3bdbba1396b06e2499bde\\preprocessor_config.json\n",
      "Feature extractor WhisperFeatureExtractor {\n",
      "  \"chunk_length\": 30,\n",
      "  \"feature_extractor_type\": \"WhisperFeatureExtractor\",\n",
      "  \"feature_size\": 80,\n",
      "  \"hop_length\": 160,\n",
      "  \"n_fft\": 400,\n",
      "  \"n_samples\": 480000,\n",
      "  \"nb_max_frames\": 3000,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0.0,\n",
      "  \"processor_class\": \"WhisperProcessor\",\n",
      "  \"return_attention_mask\": false,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\353117b351a2a3d740c3bdbba1396b06e2499bde\\vocab.json\n",
      "loading file tokenizer.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\353117b351a2a3d740c3bdbba1396b06e2499bde\\tokenizer.json\n",
      "loading file merges.txt from cache at model_cache/models--openai--whisper-medium\\snapshots\\353117b351a2a3d740c3bdbba1396b06e2499bde\\merges.txt\n",
      "loading file normalizer.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\353117b351a2a3d740c3bdbba1396b06e2499bde\\normalizer.json\n",
      "loading file added_tokens.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\353117b351a2a3d740c3bdbba1396b06e2499bde\\added_tokens.json\n",
      "loading file special_tokens_map.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\353117b351a2a3d740c3bdbba1396b06e2499bde\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\353117b351a2a3d740c3bdbba1396b06e2499bde\\tokenizer_config.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c0c652d50f4da9b2eb923a1dcc10fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file model.safetensors from cache at model_cache/models--openai--whisper-medium\\snapshots\\353117b351a2a3d740c3bdbba1396b06e2499bde\\model.safetensors\n",
      "Instantiating WhisperForConditionalGeneration model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50257\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"decoder_start_token_id\": 50258,\n",
      "  \"eos_token_id\": 50257,\n",
      "  \"forced_decoder_ids\": [\n",
      "    [\n",
      "      1,\n",
      "      50259\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      50359\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      50363\n",
      "    ]\n",
      "  ],\n",
      "  \"max_length\": 448,\n",
      "  \"pad_token_id\": 50257,\n",
      "  \"suppress_tokens\": [\n",
      "    1,\n",
      "    2,\n",
      "    7,\n",
      "    8,\n",
      "    9,\n",
      "    10,\n",
      "    14,\n",
      "    25,\n",
      "    26,\n",
      "    27,\n",
      "    28,\n",
      "    29,\n",
      "    31,\n",
      "    58,\n",
      "    59,\n",
      "    60,\n",
      "    61,\n",
      "    62,\n",
      "    63,\n",
      "    90,\n",
      "    91,\n",
      "    92,\n",
      "    93,\n",
      "    359,\n",
      "    503,\n",
      "    522,\n",
      "    542,\n",
      "    873,\n",
      "    893,\n",
      "    902,\n",
      "    918,\n",
      "    922,\n",
      "    931,\n",
      "    1350,\n",
      "    1853,\n",
      "    1982,\n",
      "    2460,\n",
      "    2627,\n",
      "    3246,\n",
      "    3253,\n",
      "    3268,\n",
      "    3536,\n",
      "    3846,\n",
      "    3961,\n",
      "    4183,\n",
      "    4667,\n",
      "    6585,\n",
      "    6647,\n",
      "    7273,\n",
      "    9061,\n",
      "    9383,\n",
      "    10428,\n",
      "    10929,\n",
      "    11938,\n",
      "    12033,\n",
      "    12331,\n",
      "    12562,\n",
      "    13793,\n",
      "    14157,\n",
      "    14635,\n",
      "    15265,\n",
      "    15618,\n",
      "    16553,\n",
      "    16604,\n",
      "    18362,\n",
      "    18956,\n",
      "    20075,\n",
      "    21675,\n",
      "    22520,\n",
      "    26130,\n",
      "    26161,\n",
      "    26435,\n",
      "    28279,\n",
      "    29464,\n",
      "    31650,\n",
      "    32302,\n",
      "    32470,\n",
      "    36865,\n",
      "    42863,\n",
      "    47425,\n",
      "    49870,\n",
      "    50254,\n",
      "    50258,\n",
      "    50358,\n",
      "    50359,\n",
      "    50360,\n",
      "    50361,\n",
      "    50362\n",
      "  ]\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing WhisperForConditionalGeneration.\n",
      "\n",
      "All the weights of WhisperForConditionalGeneration were initialized from the model checkpoint at openai/whisper-medium.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use WhisperForConditionalGeneration for predictions without further training.\n",
      "F:\\anaconda\\envs\\disenv\\lib\\site-packages\\transformers\\utils\\hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ebc6d85d538406294be9509f9579465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/3.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file generation_config.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\353117b351a2a3d740c3bdbba1396b06e2499bde\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"alignment_heads\": [\n",
      "    [\n",
      "      13,\n",
      "      15\n",
      "    ],\n",
      "    [\n",
      "      15,\n",
      "      4\n",
      "    ],\n",
      "    [\n",
      "      15,\n",
      "      15\n",
      "    ],\n",
      "    [\n",
      "      16,\n",
      "      1\n",
      "    ],\n",
      "    [\n",
      "      20,\n",
      "      0\n",
      "    ],\n",
      "    [\n",
      "      23,\n",
      "      4\n",
      "    ]\n",
      "  ],\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50257\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"decoder_start_token_id\": 50258,\n",
      "  \"eos_token_id\": 50257,\n",
      "  \"forced_decoder_ids\": [\n",
      "    [\n",
      "      1,\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      50359\n",
      "    ]\n",
      "  ],\n",
      "  \"is_multilingual\": true,\n",
      "  \"lang_to_id\": {\n",
      "    \"<|af|>\": 50327,\n",
      "    \"<|am|>\": 50334,\n",
      "    \"<|ar|>\": 50272,\n",
      "    \"<|as|>\": 50350,\n",
      "    \"<|az|>\": 50304,\n",
      "    \"<|ba|>\": 50355,\n",
      "    \"<|be|>\": 50330,\n",
      "    \"<|bg|>\": 50292,\n",
      "    \"<|bn|>\": 50302,\n",
      "    \"<|bo|>\": 50347,\n",
      "    \"<|br|>\": 50309,\n",
      "    \"<|bs|>\": 50315,\n",
      "    \"<|ca|>\": 50270,\n",
      "    \"<|cs|>\": 50283,\n",
      "    \"<|cy|>\": 50297,\n",
      "    \"<|da|>\": 50285,\n",
      "    \"<|de|>\": 50261,\n",
      "    \"<|el|>\": 50281,\n",
      "    \"<|en|>\": 50259,\n",
      "    \"<|es|>\": 50262,\n",
      "    \"<|et|>\": 50307,\n",
      "    \"<|eu|>\": 50310,\n",
      "    \"<|fa|>\": 50300,\n",
      "    \"<|fi|>\": 50277,\n",
      "    \"<|fo|>\": 50338,\n",
      "    \"<|fr|>\": 50265,\n",
      "    \"<|gl|>\": 50319,\n",
      "    \"<|gu|>\": 50333,\n",
      "    \"<|haw|>\": 50352,\n",
      "    \"<|ha|>\": 50354,\n",
      "    \"<|he|>\": 50279,\n",
      "    \"<|hi|>\": 50276,\n",
      "    \"<|hr|>\": 50291,\n",
      "    \"<|ht|>\": 50339,\n",
      "    \"<|hu|>\": 50286,\n",
      "    \"<|hy|>\": 50312,\n",
      "    \"<|id|>\": 50275,\n",
      "    \"<|is|>\": 50311,\n",
      "    \"<|it|>\": 50274,\n",
      "    \"<|ja|>\": 50266,\n",
      "    \"<|jw|>\": 50356,\n",
      "    \"<|ka|>\": 50329,\n",
      "    \"<|kk|>\": 50316,\n",
      "    \"<|km|>\": 50323,\n",
      "    \"<|kn|>\": 50306,\n",
      "    \"<|ko|>\": 50264,\n",
      "    \"<|la|>\": 50294,\n",
      "    \"<|lb|>\": 50345,\n",
      "    \"<|ln|>\": 50353,\n",
      "    \"<|lo|>\": 50336,\n",
      "    \"<|lt|>\": 50293,\n",
      "    \"<|lv|>\": 50301,\n",
      "    \"<|mg|>\": 50349,\n",
      "    \"<|mi|>\": 50295,\n",
      "    \"<|mk|>\": 50308,\n",
      "    \"<|ml|>\": 50296,\n",
      "    \"<|mn|>\": 50314,\n",
      "    \"<|mr|>\": 50320,\n",
      "    \"<|ms|>\": 50282,\n",
      "    \"<|mt|>\": 50343,\n",
      "    \"<|my|>\": 50346,\n",
      "    \"<|ne|>\": 50313,\n",
      "    \"<|nl|>\": 50271,\n",
      "    \"<|nn|>\": 50342,\n",
      "    \"<|no|>\": 50288,\n",
      "    \"<|oc|>\": 50328,\n",
      "    \"<|pa|>\": 50321,\n",
      "    \"<|pl|>\": 50269,\n",
      "    \"<|ps|>\": 50340,\n",
      "    \"<|pt|>\": 50267,\n",
      "    \"<|ro|>\": 50284,\n",
      "    \"<|ru|>\": 50263,\n",
      "    \"<|sa|>\": 50344,\n",
      "    \"<|sd|>\": 50332,\n",
      "    \"<|si|>\": 50322,\n",
      "    \"<|sk|>\": 50298,\n",
      "    \"<|sl|>\": 50305,\n",
      "    \"<|sn|>\": 50324,\n",
      "    \"<|so|>\": 50326,\n",
      "    \"<|sq|>\": 50317,\n",
      "    \"<|sr|>\": 50303,\n",
      "    \"<|su|>\": 50357,\n",
      "    \"<|sv|>\": 50273,\n",
      "    \"<|sw|>\": 50318,\n",
      "    \"<|ta|>\": 50287,\n",
      "    \"<|te|>\": 50299,\n",
      "    \"<|tg|>\": 50331,\n",
      "    \"<|th|>\": 50289,\n",
      "    \"<|tk|>\": 50341,\n",
      "    \"<|tl|>\": 50348,\n",
      "    \"<|tr|>\": 50268,\n",
      "    \"<|tt|>\": 50351,\n",
      "    \"<|uk|>\": 50280,\n",
      "    \"<|ur|>\": 50290,\n",
      "    \"<|uz|>\": 50337,\n",
      "    \"<|vi|>\": 50278,\n",
      "    \"<|yi|>\": 50335,\n",
      "    \"<|yo|>\": 50325,\n",
      "    \"<|zh|>\": 50260\n",
      "  },\n",
      "  \"max_initial_timestamp_index\": 1,\n",
      "  \"max_length\": 448,\n",
      "  \"no_timestamps_token_id\": 50363,\n",
      "  \"pad_token_id\": 50257,\n",
      "  \"return_timestamps\": false,\n",
      "  \"suppress_tokens\": [\n",
      "    1,\n",
      "    2,\n",
      "    7,\n",
      "    8,\n",
      "    9,\n",
      "    10,\n",
      "    14,\n",
      "    25,\n",
      "    26,\n",
      "    27,\n",
      "    28,\n",
      "    29,\n",
      "    31,\n",
      "    58,\n",
      "    59,\n",
      "    60,\n",
      "    61,\n",
      "    62,\n",
      "    63,\n",
      "    90,\n",
      "    91,\n",
      "    92,\n",
      "    93,\n",
      "    359,\n",
      "    503,\n",
      "    522,\n",
      "    542,\n",
      "    873,\n",
      "    893,\n",
      "    902,\n",
      "    918,\n",
      "    922,\n",
      "    931,\n",
      "    1350,\n",
      "    1853,\n",
      "    1982,\n",
      "    2460,\n",
      "    2627,\n",
      "    3246,\n",
      "    3253,\n",
      "    3268,\n",
      "    3536,\n",
      "    3846,\n",
      "    3961,\n",
      "    4183,\n",
      "    4667,\n",
      "    6585,\n",
      "    6647,\n",
      "    7273,\n",
      "    9061,\n",
      "    9383,\n",
      "    10428,\n",
      "    10929,\n",
      "    11938,\n",
      "    12033,\n",
      "    12331,\n",
      "    12562,\n",
      "    13793,\n",
      "    14157,\n",
      "    14635,\n",
      "    15265,\n",
      "    15618,\n",
      "    16553,\n",
      "    16604,\n",
      "    18362,\n",
      "    18956,\n",
      "    20075,\n",
      "    21675,\n",
      "    22520,\n",
      "    26130,\n",
      "    26161,\n",
      "    26435,\n",
      "    28279,\n",
      "    29464,\n",
      "    31650,\n",
      "    32302,\n",
      "    32470,\n",
      "    36865,\n",
      "    42863,\n",
      "    47425,\n",
      "    49870,\n",
      "    50254,\n",
      "    50258,\n",
      "    50358,\n",
      "    50359,\n",
      "    50360,\n",
      "    50361,\n",
      "    50362\n",
      "  ],\n",
      "  \"task_to_id\": {\n",
      "    \"transcribe\": 50359,\n",
      "    \"translate\": 50358\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Load pretrained model, tokenizer, and feature extractor\n",
    "config = WhisperConfig.from_pretrained(\n",
    "    (model_args.config_name if model_args.config_name else model_args.model_name_or_path),\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    token=token,\n",
    ")\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\n",
    "    (model_args.feature_extractor_name if model_args.feature_extractor_name else model_args.model_name_or_path),\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    token=token,\n",
    ")\n",
    "tokenizer = WhisperTokenizerFast.from_pretrained(\n",
    "    (model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path),\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    use_fast=model_args.use_fast_tokenizer,\n",
    "    revision=model_args.model_revision,\n",
    "    token=token,\n",
    ")\n",
    "processor = WhisperProcessor.from_pretrained(\n",
    "    (model_args.processor_name if model_args.processor_name else model_args.model_name_or_path),\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    token=token,\n",
    ")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    config=config,\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    subfolder=model_args.subfolder,\n",
    "    token=token,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    use_flash_attention_2=model_args.attn_type == \"flash_attn_2\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1l9mPbUaHiZ4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_args.attn_type == \"flash_attn\":\n",
    "    model = model.to_bettertransformer()\n",
    "elif model_args.attn_type not in [None, \"flash_attn\", \"flash_attn_2\"]:\n",
    "    raise ValueError(\n",
    "        f\"Argument `attn_type` is set to {model_args.attn_type}. Should be one of:\"\n",
    "        \"1. `None`: default Transformers attention implementation.\"\n",
    "        \"2. `flash_attn`: Flash Attention through PyTorch SDPA. Requires `torch>=2.0` and `optimum` to be installed. Recommended for hardware where Flash Attention 2 is not supported, e.g. Turing GPUs, (T4, RTX 2080).\"\n",
    "        \"3. `flash_attn_2`: Flash Attention 2 through the Flash Attention package https://github.com/Dao-AILab/flash-attention. **Always** recommended on supported hardware (Ampere, Ada, or Hopper GPUs, e.g., A100, RTX 3090, RTX 4090, H100).\"\n",
    "    )\n",
    "\n",
    "model.eval()\n",
    "\n",
    "if model.config.decoder_start_token_id is None:\n",
    "    raise ValueError(\"Make sure that `config.decoder_start_token_id` is correctly defined\")\n",
    "\n",
    "return_timestamps = data_args.return_timestamps\n",
    "if hasattr(model.generation_config, \"is_multilingual\") and model.generation_config.is_multilingual:\n",
    "    # We need to set the language and task ids for multilingual checkpoints\n",
    "    tokenizer.set_prefix_tokens(\n",
    "        language=data_args.language, task=data_args.task, predict_timestamps=return_timestamps\n",
    "    )\n",
    "elif data_args.language is not None:\n",
    "    raise ValueError(\n",
    "        \"Setting language token for an English-only checkpoint is not permitted. The language argument should \"\n",
    "        \"only be set for multilingual checkpoints.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "f66ef2a647a34ecda62ad1376ecc0787",
      "b25f2d354f9c4ec3b1d81a8d1d039266",
      "116f8c908f1d42f9bee1525787dc60b0",
      "b50ac10536424294a4391bed34d4d101",
      "85230fee517245a1b9db2d19eb87a46f",
      "25eb176a19c340dda3b264a28e203cbf",
      "3e8bd264b90b4b16a08d5ce3952f0561",
      "4f5b8f35e56d492995c1ef3d824da234",
      "1f7fd128e7ba4f2a8556a5a6997fd946",
      "41fb328527f541afbc7c86e963f7ba21",
      "a2b830af92a4492d89ea87e8280bf1b7",
      "8ac4f7ff7d594defbe6a662f45affd3b",
      "7732642b5f394f43b843346b9bb6300e",
      "1bda516d2d99431ebe4694090fa5c8fa",
      "8b421cf642cd407491a002a3223fc00f",
      "37a59b12c6d5445aa4266cea168f3a0f",
      "dc514e78b8454182abd681ee7f196dd7",
      "fd01f17c91ff4fcc9c32fd3e674e52cf",
      "17951ff284bc44cc8025a23d7403dfb5",
      "f8f7a9e8383f4dbba1199f8ae38c9de7",
      "5a1b7e1a32494ac7bb671b7046d51c09",
      "c02e564fec994102a5df7f2b8aac1af3"
     ]
    },
    "id": "-Lt3p9y_HnRP",
    "outputId": "672011b1-0ce8-4b66-bc71-407a248ccd7b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444163c0a77146b09fb6264899e99e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocess dataset:   0%|          | 0/28539 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6dabcdad9ee40e0a8bae28953a86879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocess dataset:   0%|          | 0/2703 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee205ed578c45b788627a15cf81055f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocess dataset:   0%|          | 0/2620 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/20/2024 15:08:46 - INFO - __main__ - Data preprocessing finished. Files cached at {'train.100': [{'filename': 'F:\\\\distiling_whisper_local\\\\raw_datasets\\\\train.100\\\\cache-462d543ea5a2846c.arrow'}], 'validation': [{'filename': 'F:\\\\distiling_whisper_local\\\\raw_datasets\\\\validation\\\\cache-726212e0b27a0154.arrow'}], 'test': [{'filename': 'F:\\\\distiling_whisper_local\\\\raw_datasets\\\\test\\\\cache-71dc5047b0e560c9.arrow'}]}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd51034c2dd44687919695f8dc36235a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6. Resample speech dataset: `datasets` takes care of automatically loading and resampling the audio,\n",
    "# so we just need to set the correct target sampling rate.\n",
    "raw_datasets = raw_datasets.cast_column(\n",
    "    data_args.audio_column_name,\n",
    "    datasets.features.Audio(sampling_rate=feature_extractor.sampling_rate),\n",
    ")\n",
    "\n",
    "# 7. Preprocessing the datasets.\n",
    "# We need to read the audio files as arrays and tokenize the targets.\n",
    "max_label_length = (\n",
    "    data_args.max_label_length if data_args.max_label_length is not None else model.config.max_length\n",
    ")\n",
    "audio_column_name = data_args.audio_column_name\n",
    "num_workers = data_args.preprocessing_num_workers\n",
    "dataloader_num_workers = training_args.dataloader_num_workers\n",
    "text_column_name = data_args.text_column_name\n",
    "model_input_name = feature_extractor.model_input_names[0]\n",
    "id_column_name = data_args.id_column_name\n",
    "normalizer = (\n",
    "    BasicTextNormalizer() if data_args.language is not None else EnglishTextNormalizer(tokenizer.english_spelling_normalizer)\n",
    ")\n",
    "\n",
    "if data_args.max_samples_per_split is not None:\n",
    "    for split in data_splits:\n",
    "        raw_datasets[split] = (\n",
    "            raw_datasets[split].take(data_args.max_samples_per_split)\n",
    "            if data_args.streaming\n",
    "            else raw_datasets[split].select(range(data_args.max_samples_per_split))\n",
    "        )\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    # process audio\n",
    "    sample = batch[audio_column_name]\n",
    "    inputs = feature_extractor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"])\n",
    "    # process audio length\n",
    "    batch[model_input_name] = inputs.get(model_input_name)[0]\n",
    "\n",
    "    # process targets\n",
    "    input_str = batch[text_column_name]\n",
    "    batch[\"labels\"] = tokenizer(input_str, max_length=max_label_length, truncation=True).input_ids\n",
    "\n",
    "    # record the id of the sample as token ids\n",
    "    batch[\"file_id\"] = tokenizer(batch[id_column_name], add_special_tokens=False).input_ids\n",
    "    return batch\n",
    "\n",
    "raw_datasets_features = list(next(iter(raw_datasets.values())).features.keys())\n",
    "if data_args.streaming:\n",
    "    vectorized_datasets = raw_datasets.map(prepare_dataset, remove_columns=raw_datasets_features)\n",
    "else:\n",
    "    vectorized_datasets = raw_datasets.map(\n",
    "        prepare_dataset,\n",
    "        remove_columns=raw_datasets_features,\n",
    "        # num_proc=1,\n",
    "        desc=\"preprocess dataset\",\n",
    "    )\n",
    "\n",
    "# for large datasets it is advised to run the preprocessing on a\n",
    "# single machine first with `args.preprocessing_only` since there will mostly likely\n",
    "# be a timeout when running the script in distributed mode.\n",
    "# In a second step `args.preprocessing_only` can then be set to `False` to load the\n",
    "# cached dataset\n",
    "if data_args.preprocessing_only:\n",
    "    cache = {k: v.cache_files for k, v in vectorized_datasets.items()}\n",
    "    logger.info(f\"Data preprocessing finished. Files cached at {cache}.\")\n",
    "    # return\n",
    "\n",
    "if data_args.streaming and dataloader_num_workers > 0:\n",
    "    logger.warning(\n",
    "        \"Using multiple dataloader num workers with streaming mode will result in different shards of \"\n",
    "        \"data being transcribed in parallel. This is not advised if you want to preserve the order of the \"\n",
    "        \"audio-text data.\"\n",
    "    )\n",
    "\n",
    "# Handle the repository creation\n",
    "output_dir = training_args.output_dir\n",
    "if training_args.push_to_hub:\n",
    "    if training_args.hub_model_id is None:\n",
    "        repo_name = get_full_repo_name(\n",
    "            Path(output_dir).absolute().name,\n",
    "            token=token,\n",
    "        )\n",
    "    else:\n",
    "        repo_name = training_args.hub_model_id\n",
    "    create_repo(repo_name, exist_ok=True, token=token, repo_type=\"dataset\", private=data_args.private_dataset)\n",
    "    repo = Repository(\n",
    "        output_dir,\n",
    "        clone_from=repo_name,\n",
    "        token=token,\n",
    "        repo_type=\"dataset\",\n",
    "    )\n",
    "    # Ensure large txt files can be pushed to the Hub with git-lfs\n",
    "    with open(os.path.join(output_dir, \".gitattributes\"), \"r+\") as f:\n",
    "        git_lfs_extensions = f.read()\n",
    "        if \"*.csv\" not in git_lfs_extensions:\n",
    "            f.write(\"*.csv filter=lfs diff=lfs merge=lfs -text\")\n",
    "else:\n",
    "    # this is where we'll save our transcriptions\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "# 8. Load Metric\n",
    "metric = evaluate.load(\"wer\")\n",
    "\n",
    "def compute_metrics(preds, labels, file_ids):\n",
    "    # replace padded labels by the padding token\n",
    "    for idx in range(len(labels)):\n",
    "        labels[idx][labels[idx] == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(preds, skip_special_tokens=True, decode_with_timestamps=return_timestamps)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    wer_ortho = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    # normalize everything and re-compute the WER\n",
    "    norm_pred_str = [normalizer(pred) for pred in pred_str]\n",
    "    norm_label_str = [normalizer(label) for label in label_str]\n",
    "    # for logging, we need the pred/labels to match the norm_pred/norm_labels, so discard any filtered samples here\n",
    "    pred_str = [pred_str[i] for i in range(len(norm_pred_str)) if len(norm_label_str[i]) > 0]\n",
    "    label_str = [label_str[i] for i in range(len(norm_label_str)) if len(norm_label_str[i]) > 0]\n",
    "    file_ids = [file_ids[i] for i in range(len(file_ids)) if len(norm_label_str[i]) > 0]\n",
    "    # filtering step to only evaluate the samples that correspond to non-zero normalized references:\n",
    "    norm_pred_str = [norm_pred_str[i] for i in range(len(norm_pred_str)) if len(norm_label_str[i]) > 0]\n",
    "    norm_label_str = [norm_label_str[i] for i in range(len(norm_label_str)) if len(norm_label_str[i]) > 0]\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=norm_pred_str, references=norm_label_str)\n",
    "\n",
    "    return {\"wer\": wer, \"wer_ortho\": wer_ortho}, pred_str, label_str, norm_pred_str, norm_label_str, file_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "01/20/2024 15:08:46 - INFO - __main__ - Data preprocessing finished. Files cached at {'train.100': [{'filename': 'F:\\\\distiling_whisper_local\\\\raw_datasets\\\\train.100\\\\cache-462d543ea5a2846c.arrow'}], 'validation': [{'filename': 'F:\\\\distiling_whisper_local\\\\raw_datasets\\\\validation\\\\cache-726212e0b27a0154.arrow'}], 'test': [{'filename': 'F:\\\\distiling_whisper_local\\\\raw_datasets\\\\test\\\\cache-71dc5047b0e560c9.arrow'}]}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "RuwkOQkjHomk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 12. Define Training Schedule\n",
    "per_device_eval_batch_size = int(training_args.per_device_eval_batch_size)\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,  # <|startoftranscript|>\n",
    "    input_padding=\"longest\",\n",
    "    target_padding=\"max_length\",\n",
    "    max_target_length=max_label_length,\n",
    ")\n",
    "\n",
    "# 14. Define generation arguments - we need to do this before we wrap the models in DDP\n",
    "# so that we can still access the configs\n",
    "num_beams = (\n",
    "    training_args.generation_num_beams\n",
    "    if training_args.generation_num_beams is not None\n",
    "    else getattr(model.generation_config, \"num_beams\", 1)\n",
    ")\n",
    "\n",
    "gen_kwargs = {\n",
    "    \"max_length\": max_label_length,\n",
    "    \"num_beams\": num_beams,\n",
    "    \"return_timestamps\": return_timestamps,\n",
    "}\n",
    "if hasattr(model.generation_config, \"is_multilingual\") and model.generation_config.is_multilingual:\n",
    "    # forcing the language and task tokens helps multilingual models in their generations\n",
    "    gen_kwargs.update(\n",
    "        {\n",
    "            \"language\": data_args.language,\n",
    "            \"task\": data_args.task,\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "fjN4iScSHpsU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# 15. Prepare everything with accelerate\n",
    "model = accelerator.prepare(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "7UeOJVpJHrcB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_step_with_save(split=\"eval\"):\n",
    "    # ======================== Evaluating ==============================\n",
    "    eval_preds = []\n",
    "    eval_labels = []\n",
    "    eval_ids = []\n",
    "    eval_start = time.time()\n",
    "\n",
    "    eval_loader = DataLoader(\n",
    "        vectorized_datasets[split],\n",
    "        batch_size=per_device_eval_batch_size,\n",
    "        collate_fn=data_collator,\n",
    "        num_workers=dataloader_num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    eval_loader = accelerator.prepare(eval_loader)\n",
    "    batches = tqdm(eval_loader, desc=f\"Evaluating {split}...\", disable=not accelerator.is_local_main_process)\n",
    "\n",
    "    # make the split name pretty for librispeech etc\n",
    "    # split = split.replace(\".\", \"-\").split(\"/\")[-1]\n",
    "    output_csv = os.path.join(output_dir, f\"{split}-transcription.csv\")\n",
    "\n",
    "    for step, batch in enumerate(batches):\n",
    "        file_ids = batch.pop(\"file_ids\")\n",
    "        # Generate predictions and pad to max generated length\n",
    "        generate_fn = model.module.generate if accelerator.num_processes > 1 else model.generate\n",
    "        generated_ids = generate_fn(batch[\"input_features\"].to(dtype=torch_dtype), **gen_kwargs)\n",
    "        generated_ids = accelerator.pad_across_processes(generated_ids, dim=1, pad_index=tokenizer.pad_token_id)\n",
    "        # Gather all predictions and targets\n",
    "        file_ids, generated_ids, labels = accelerator.gather_for_metrics(\n",
    "            (file_ids, generated_ids, batch[\"labels\"])\n",
    "        )\n",
    "        eval_preds.extend(generated_ids.cpu().numpy())\n",
    "        eval_labels.extend(labels.cpu().numpy())\n",
    "        file_ids = tokenizer.batch_decode(file_ids, skip_special_tokens=True)\n",
    "        eval_ids.extend(file_ids)\n",
    "\n",
    "        if step % training_args.logging_steps == 0 and step > 0:\n",
    "            batches.write(f\"Saving transcriptions for split {split} step {step}\")\n",
    "            accelerator.wait_for_everyone()\n",
    "            if data_args.decode_token_ids:\n",
    "                eval_preds = tokenizer.batch_decode(\n",
    "                    eval_preds, skip_special_tokens=True, decode_with_timestamps=return_timestamps\n",
    "                )\n",
    "            csv_data = [[eval_ids[i], eval_preds[i]] for i in range(len(eval_preds))]\n",
    "\n",
    "            with open(output_csv, \"w\", encoding=\"UTF8\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                # write multiple rows\n",
    "                writer.writerow([\"file_id\", \"whisper_transcript\"])\n",
    "                writer.writerows(csv_data)\n",
    "\n",
    "            if training_args.push_to_hub and accelerator.is_main_process:\n",
    "                repo.push_to_hub(\n",
    "                    commit_message=f\"Saving transcriptions for split {split} step {step}.\",\n",
    "                    blocking=False,\n",
    "                )\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    eval_time = time.time() - eval_start\n",
    "\n",
    "    # compute WER metric for eval sets\n",
    "    wer_desc = \"\"\n",
    "    if \"validation\" in split or \"test\" in split:\n",
    "        wer_metric, pred_str, label_str, norm_pred_str, norm_label_str, eval_ids = compute_metrics(\n",
    "            eval_preds, eval_labels, eval_ids\n",
    "        )\n",
    "        wer_desc = \" \".join([f\"Eval {key}: {value} |\" for key, value in wer_metric.items()])\n",
    "        # Save metrics + predictions\n",
    "        # log_metric(\n",
    "        #     accelerator,\n",
    "        #     metrics=wer_metric,\n",
    "        #     train_time=eval_time,\n",
    "        #     prefix=split,\n",
    "        # )\n",
    "        # log_pred(\n",
    "        #     accelerator,\n",
    "        #     pred_str,\n",
    "        #     label_str,\n",
    "        #     norm_pred_str,\n",
    "        #     norm_label_str,\n",
    "        #     prefix=split,\n",
    "        # )\n",
    "        if data_args.decode_token_ids:\n",
    "            eval_preds = pred_str\n",
    "    elif data_args.decode_token_ids:\n",
    "        eval_preds = tokenizer.batch_decode(\n",
    "            eval_preds, skip_special_tokens=True, decode_with_timestamps=return_timestamps\n",
    "        )\n",
    "\n",
    "    batches.write(f\"Saving final transcriptions for split {split}.\")\n",
    "    csv_data = [[eval_ids[i], eval_preds[i]] for i in range(len(eval_preds))]\n",
    "    with open(output_csv, \"w\", encoding=\"UTF8\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        # write multiple rows\n",
    "        writer.writerow([\"file_id\", \"whisper_transcript\"])\n",
    "        writer.writerows(csv_data)\n",
    "\n",
    "    # Print metrics\n",
    "    logger.info(wer_desc)\n",
    "\n",
    "    if not data_args.streaming:\n",
    "        raw_datasets[split] = raw_datasets[split].add_column(\"whisper_transcript\", eval_preds)\n",
    "        \n",
    "    # return eval_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# train_100_df = pd.read_csv('librespeach_labeled/train-100-transcription.csv')\n",
    "# row = train_100_df['whisper_transcript'].iloc[-1]\n",
    "\n",
    "\n",
    "# def read_train_trans_array(row):\n",
    "#     array_str = row.replace('[', '').replace(']', '').replace('\\n', '')\n",
    "#     result_array = np.fromstring(array_str, sep=' ',dtype='int64')\n",
    "#     return result_array\n",
    "\n",
    "\n",
    "# train_100_df['whisper_transcript_arr'] = train_100_df['whisper_transcript'].apply(lambda row: read_train_trans_array(row))\n",
    "# eval_preds = train_100_df['whisper_transcript_arr'].to_list()\n",
    "# raw_datasets[split] = raw_datasets[split].add_column(\"whisper_transcript\", eval_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'validation'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     wer_desc = \"\"\n",
    "#     if \"validation\" in split or \"test\" in split:\n",
    "#         wer_metric, pred_str, label_str, norm_pred_str, norm_label_str, eval_ids = compute_metrics(\n",
    "#             eval_preds, eval_labels, eval_ids\n",
    "#         )\n",
    "#         wer_desc = \" \".join([f\"Eval {key}: {value} |\" for key, value in wer_metric.items()])\n",
    "#         # Save metrics + predictions\n",
    "#         # log_metric(\n",
    "#         #     accelerator,\n",
    "#         #     metrics=wer_metric,\n",
    "#         #     train_time=eval_time,\n",
    "#         #     prefix=split,\n",
    "#         # )\n",
    "#         # log_pred(\n",
    "#         #     accelerator,\n",
    "#         #     pred_str,\n",
    "#         #     label_str,\n",
    "#         #     norm_pred_str,\n",
    "#         #     norm_label_str,\n",
    "#         #     prefix=split,\n",
    "#         # )\n",
    "#         if data_args.decode_token_ids:\n",
    "#             eval_preds = pred_str\n",
    "#     elif data_args.decode_token_ids:\n",
    "#         eval_preds = tokenizer.batch_decode(\n",
    "#             eval_preds, skip_special_tokens=True, decode_with_timestamps=return_timestamps\n",
    "#         )\n",
    "\n",
    "#     batches.write(f\"Saving final transcriptions for split {split}.\")\n",
    "#     csv_data = [[eval_ids[i], eval_preds[i]] for i in range(len(eval_preds))]\n",
    "#     with open(output_csv, \"w\", encoding=\"UTF8\", newline=\"\") as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         # write multiple rows\n",
    "#         writer.writerow([\"file_id\", \"whisper_transcript\"])\n",
    "#         writer.writerows(csv_data)\n",
    "\n",
    "#     # Print metrics\n",
    "#     logger.info(wer_desc)\n",
    "\n",
    "#     if not data_args.streaming:\n",
    "#         raw_datasets[split] = raw_datasets[split].add_column(\"whisper_transcript\", eval_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_pred_custom_table(\n",
    "    accelerator,\n",
    "    pred_str: List[str],\n",
    "    label_str: List[str],\n",
    "    norm_pred_str: List[str],\n",
    "    norm_label_str: List[str],\n",
    "    prefix: str = \"eval\",\n",
    "    num_lines: int = 200000,\n",
    "):\n",
    "    \"\"\"Helper function to log target/predicted transcriptions to weights and biases (wandb).\"\"\"\n",
    "    if accelerator.is_main_process:\n",
    "        wandb_tracker = accelerator.get_tracker(\"wandb\")\n",
    "        wandb_tracker.init(key='1f66b21fc46ede46b6bb2532b457545962b60ac4')\n",
    "        # pretty name for split\n",
    "        prefix = prefix.replace(\"/\", \"-\")\n",
    "\n",
    "        # convert str data to a wandb compatible format\n",
    "        str_data = [[label_str[i], pred_str[i], norm_label_str[i], norm_pred_str[i]] for i in range(len(pred_str))]\n",
    "        # log as a table with the appropriate headers\n",
    "        wandb_tracker.log_table(\n",
    "            table_name=f\"{prefix}/all_predictions\",\n",
    "            columns=[\"Target\", \"Pred\", \"Norm Target\", \"Norm Pred\"],\n",
    "            data=str_data[:num_lines],\n",
    "        )\n",
    "\n",
    "        # log incorrect normalised predictions\n",
    "        str_data = np.asarray(str_data)\n",
    "        str_data_incorrect = str_data[str_data[:, -2] != str_data[:, -1]]\n",
    "        # log as a table with the appropriate headers\n",
    "        wandb_tracker.log_table(\n",
    "            table_name=f\"{prefix}/incorrect_predictions\",\n",
    "            columns=[\"Target\", \"Pred\", \"Norm Target\", \"Norm Pred\"],\n",
    "            data=str_data_incorrect[:num_lines],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wandb_tracker = accelerator.get_tracker(\"wandb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_pred_custom(\n",
    "    accelerator,\n",
    "    pred_str: List[str],\n",
    "    label_str: List[str],\n",
    "    norm_pred_str: List[str],\n",
    "    norm_label_str: List[str],\n",
    "    prefix: str = \"eval\",\n",
    "    num_lines: int = 200000,\n",
    "):\n",
    "    if accelerator.is_main_process:\n",
    "        wandb_tracker = accelerator.get_tracker(\"wandb\")\n",
    "        prefix = prefix.replace(\"/\", \"-\")\n",
    "\n",
    "        # Convert str data to a wandb-compatible format\n",
    "        str_data = [[label_str[i], pred_str[i], norm_label_str[i], norm_pred_str[i]] for i in range(len(pred_str))]\n",
    "\n",
    "        # Log individual columns\n",
    "        wandb.log({f\"{prefix}/all_predictions_Target\": [item[0] for item in str_data[:num_lines]]})\n",
    "        wandb.log({f\"{prefix}/all_predictions_Pred\": [item[1] for item in str_data[:num_lines]]})\n",
    "        wandb.log({f\"{prefix}/all_predictions_Norm_Target\": [item[2] for item in str_data[:num_lines]]})\n",
    "        wandb.log({f\"{prefix}/all_predictions_Norm_Pred\": [item[3] for item in str_data[:num_lines]]})\n",
    "\n",
    "        # Log incorrect normalized predictions\n",
    "        str_data = np.asarray(str_data)\n",
    "        str_data_incorrect = str_data[str_data[:, -2] != str_data[:, -1]]\n",
    "\n",
    "        wandb.log({f\"{prefix}/incorrect_predictions_Target\": [item[0] for item in str_data_incorrect[:num_lines]]})\n",
    "        wandb.log({f\"{prefix}/incorrect_predictions_Pred\": [item[1] for item in str_data_incorrect[:num_lines]]})\n",
    "        wandb.log({f\"{prefix}/incorrect_predictions_Norm_Target\": [item[2] for item in str_data_incorrect[:num_lines]]})\n",
    "        wandb.log({f\"{prefix}/incorrect_predictions_Norm_Pred\": [item[3] for item in str_data_incorrect[:num_lines]]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wandb_tracker = accelerator.get_tracker(\"wandb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "94b72KMDHtJ6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/20/2024 22:17:53 - INFO - __main__ - ***** Running Labelling *****\n",
      "01/20/2024 22:17:53 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
      "01/20/2024 22:17:53 - INFO - __main__ -   Total eval batch size (w. parallel & distributed) = 16\n",
      "01/20/2024 22:17:53 - INFO - __main__ -   Predict labels with timestamps = False\n",
      "01/20/2024 22:17:53 - INFO - __main__ -   Decode labels to transcriptions = False\n",
      "Evaluating test...:  62%|                       | 101/164 [07:12<04:17,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving transcriptions for split test step 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test...: 100%|| 164/164 [11:23<00:00,  4.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving final transcriptions for split test.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/20/2024 22:29:19 - INFO - __main__ - Eval wer: 3.4726443768996957 | Eval wer_ortho: 99.37728727175184 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5381936f601344f69fb88e99449d034e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/14 shards):   0%|          | 0/28539 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63993979655c4238beaed131caee2962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/4 shards):   0%|          | 0/2703 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c759e9d6591344bfbf02476a5ed2c7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/4 shards):   0%|          | 0/2620 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger.info(\"***** Running Labelling *****\")\n",
    "logger.info(\"  Instantaneous batch size per device =\" f\" {training_args.per_device_eval_batch_size}\")\n",
    "logger.info(\n",
    "    f\"  Total eval batch size (w. parallel & distributed) = {training_args.per_device_eval_batch_size * accelerator.num_processes}\"\n",
    ")\n",
    "logger.info(f\"  Predict labels with timestamps = {return_timestamps}\")\n",
    "logger.info(f\"  Decode labels to transcriptions = {data_args.decode_token_ids}\")\n",
    "for split in ['test']:#data_splits:\n",
    "    eval_preds = eval_step_with_save(split=split)\n",
    "    accelerator.wait_for_everyone()\n",
    "    if training_args.push_to_hub and accelerator.is_main_process:\n",
    "        repo.push_to_hub(\n",
    "            commit_message=f\"Saving final transcriptions for split {split.replace('.', '-').split('/')[-1]}\",\n",
    "            blocking=False,\n",
    "        )\n",
    "if not data_args.streaming and accelerator.is_main_process:\n",
    "    raw_datasets.save_to_disk(output_dir, num_proc=num_workers)\n",
    "    if training_args.push_to_hub:\n",
    "        raw_datasets.push_to_hub(repo_name, config_name=data_args.dataset_config_name)\n",
    "accelerator.end_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "116f8c908f1d42f9bee1525787dc60b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f5b8f35e56d492995c1ef3d824da234",
      "max": 28539,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1f7fd128e7ba4f2a8556a5a6997fd946",
      "value": 28539
     }
    },
    "17951ff284bc44cc8025a23d7403dfb5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bda516d2d99431ebe4694090fa5c8fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17951ff284bc44cc8025a23d7403dfb5",
      "max": 104014,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f8f7a9e8383f4dbba1199f8ae38c9de7",
      "value": 48474
     }
    },
    "1f7fd128e7ba4f2a8556a5a6997fd946": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "25eb176a19c340dda3b264a28e203cbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37a59b12c6d5445aa4266cea168f3a0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e8bd264b90b4b16a08d5ce3952f0561": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41fb328527f541afbc7c86e963f7ba21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f5b8f35e56d492995c1ef3d824da234": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a1b7e1a32494ac7bb671b7046d51c09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7732642b5f394f43b843346b9bb6300e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc514e78b8454182abd681ee7f196dd7",
      "placeholder": "",
      "style": "IPY_MODEL_fd01f17c91ff4fcc9c32fd3e674e52cf",
      "value": "preprocess dataset:  47%"
     }
    },
    "85230fee517245a1b9db2d19eb87a46f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ac4f7ff7d594defbe6a662f45affd3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7732642b5f394f43b843346b9bb6300e",
       "IPY_MODEL_1bda516d2d99431ebe4694090fa5c8fa",
       "IPY_MODEL_8b421cf642cd407491a002a3223fc00f"
      ],
      "layout": "IPY_MODEL_37a59b12c6d5445aa4266cea168f3a0f"
     }
    },
    "8b421cf642cd407491a002a3223fc00f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a1b7e1a32494ac7bb671b7046d51c09",
      "placeholder": "",
      "style": "IPY_MODEL_c02e564fec994102a5df7f2b8aac1af3",
      "value": " 48474/104014 [1:54:24&lt;1:51:28,  8.30 examples/s]"
     }
    },
    "a2b830af92a4492d89ea87e8280bf1b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b25f2d354f9c4ec3b1d81a8d1d039266": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25eb176a19c340dda3b264a28e203cbf",
      "placeholder": "",
      "style": "IPY_MODEL_3e8bd264b90b4b16a08d5ce3952f0561",
      "value": "preprocess dataset: 100%"
     }
    },
    "b50ac10536424294a4391bed34d4d101": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41fb328527f541afbc7c86e963f7ba21",
      "placeholder": "",
      "style": "IPY_MODEL_a2b830af92a4492d89ea87e8280bf1b7",
      "value": " 28539/28539 [1:05:38&lt;00:00, 10.22 examples/s]"
     }
    },
    "c02e564fec994102a5df7f2b8aac1af3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc514e78b8454182abd681ee7f196dd7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f66ef2a647a34ecda62ad1376ecc0787": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b25f2d354f9c4ec3b1d81a8d1d039266",
       "IPY_MODEL_116f8c908f1d42f9bee1525787dc60b0",
       "IPY_MODEL_b50ac10536424294a4391bed34d4d101"
      ],
      "layout": "IPY_MODEL_85230fee517245a1b9db2d19eb87a46f"
     }
    },
    "f8f7a9e8383f4dbba1199f8ae38c9de7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fd01f17c91ff4fcc9c32fd3e674e52cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
