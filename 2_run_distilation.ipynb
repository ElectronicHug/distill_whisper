{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0d2e02-792c-44ac-8d8c-b2e63f91292d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: read).\n",
      "Your token has been saved in your configured git credential helpers (manager,store).\n",
      "Your token has been saved to C:\\Users\\Zhenya\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='', add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e539b7b-1d1a-4c4e-9283-b5a837ed310a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from create_student_model import init_student_model_from_teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "765d97b6-fbe9-4855-a0ac-835a21c23c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from datasets import (\n",
    "    DatasetDict,\n",
    "    IterableDataset,\n",
    "    IterableDatasetDict,\n",
    "    concatenate_datasets,\n",
    "    interleave_datasets,\n",
    "    load_dataset,\n",
    ")\n",
    "from huggingface_hub import Repository, create_repo\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AddedToken,\n",
    "    HfArgumentParser,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    WhisperConfig,\n",
    "    WhisperFeatureExtractor,\n",
    "    WhisperForConditionalGeneration,\n",
    "    WhisperProcessor,\n",
    "    WhisperTokenizerFast,\n",
    "    get_scheduler,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer, EnglishTextNormalizer\n",
    "from transformers.utils import check_min_version\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "\n",
    "# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n",
    "check_min_version(\"4.34.0.dev0\")\n",
    "\n",
    "require_version(\"datasets>=2.14.6\", \"To fix: `pip install --upgrade datasets`\")\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "926b7b8b-ed85-49ec-81c0-9ade2a150550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from run_distillation import ModelArguments, DataTrainingArguments, DistillationTrainingArguments, DataCollatorSpeechSeq2SeqWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b46e36ab-2d1d-4f1d-a895-95beb18c5090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from run_distillation import log_metric, log_pred, convert_dataset_str_to_list, load_multiple_datasets, get_layers_to_supervise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b45b72c4-bfb6-43ec-96d1-649fa11d6332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from run_distillation import sorted_checkpoints, rotate_checkpoints, get_last_checkpoint, get_parameter_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16b6c9c7-5a59-4c7e-842d-66cd062faa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Parse input arguments\n",
    "# We keep distinct sets of args, for cleaner separation of model/data/training related args\n",
    "parser = HfArgumentParser((ModelArguments, DataTrainingArguments, DistillationTrainingArguments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "364ef027-253e-4b56-a685-0915746b5300",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_args = [\n",
    "    '--model_name_or_path=./student_model',\n",
    "    # '--teacher_model_name_or_path=openai/whisper-medium',\n",
    "    '--teacher_model_name_or_path=./local_whisper_medium',\n",
    "    '--train_dataset_name=./librespeach_labeled+./librespeach_labeled',\n",
    "    '--train_dataset_config_name=clean+clean',\n",
    "    '--train_split_name=train+validation',\n",
    "    '--text_column_name=text+text',\n",
    "    # '--train_dataset_samples=None',\n",
    "    '--eval_dataset_name=./librespeach_labeled',\n",
    "    '--eval_dataset_config_name=clean',\n",
    "    '--eval_split_name=test',\n",
    "    '--eval_text_column_name=text',\n",
    "    '--eval_steps=1000',\n",
    "    '--save_steps=1000',\n",
    "    '--warmup_steps=250',\n",
    "    '--learning_rate=0.00001',\n",
    "    '--lr_scheduler_type=constant_with_warmup',\n",
    "    '--logging_steps=25',\n",
    "    '--save_total_limit=3',\n",
    "    '--max_steps=10000',\n",
    "    # '--wer_threshold=None',\n",
    "    '--per_device_train_batch_size=32',\n",
    "    '--per_device_eval_batch_size=32',\n",
    "    '--dataloader_num_workers=4',\n",
    "    '--preprocessing_num_workers=4',\n",
    "    '--ddp_timeout=7200',\n",
    "    '--dtype=float16',\n",
    "\n",
    "    '--do_train=True',\n",
    "    '--do_eval=True',\n",
    "    '--gradient_checkpointing=True',\n",
    "    '--streaming=False',\n",
    "    '--cache_dir=./model_cache/',\n",
    "    '--dataset_cache_dir=./hug_libra_raw_dataset/cache/downloads',\n",
    "    '--overwrite_output_dir=True',\n",
    "    '--output_dir=./result_distiling',\n",
    "    '--freeze_encoder=True',\n",
    "    # '--=',\n",
    "    # '--=',\n",
    "]\n",
    "\n",
    "model_args, data_args, training_args = parser.parse_args_into_dataclasses(list_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8cffe8-8cf3-4e77-8912-5c23d323b9bf",
   "metadata": {},
   "source": [
    "    accelerate launch run_distillation.py \\\n",
    "      --model_name_or_path \"./distil-large-v2-init\" \\\n",
    "      --teacher_model_name_or_path \"openai/whisper-large-v2\" \\\n",
    "      --train_dataset_name \"../common_voice_13_0_hi_pseudo_labelled+../common_voice_13_0_hi_pseudo_labelled\" \\\n",
    "      --train_dataset_config_name \"hi+hi\" \\\n",
    "      --train_split_name \"train+validation\" \\\n",
    "      --text_column_name \"sentence+sentence\" \\\n",
    "      --train_dataset_samples \"10+5\" \\\n",
    "      --eval_dataset_name \"../common_voice_13_0_hi_pseudo_labelled\" \\\n",
    "      --eval_dataset_config_name \"hi\" \\\n",
    "      --eval_split_name \"test\" \\\n",
    "      --eval_text_column_name \"sentence\" \\\n",
    "      --eval_steps 1000 \\\n",
    "      --save_steps 1000 \\\n",
    "      --warmup_steps 50 \\\n",
    "      --learning_rate 0.0001 \\\n",
    "      --lr_scheduler_type \"constant_with_warmup\" \\\n",
    "      --logging_steps 25 \\\n",
    "      --save_total_limit 1 \\\n",
    "      --max_steps 5000 \\\n",
    "      --wer_threshold 10 \\\n",
    "      --per_device_train_batch_size 64 \\\n",
    "      --per_device_eval_batch_size 64 \\\n",
    "      --dataloader_num_workers 16 \\\n",
    "      --preprocessing_num_workers 16 \\\n",
    "      --ddp_timeout 7200 \\\n",
    "      --dtype \"bfloat16\" \\\n",
    "      --output_dir \"./\" \\\n",
    "      --do_train \\\n",
    "      --do_eval \\\n",
    "      --gradient_checkpointing \\\n",
    "      --overwrite_output_dir \\\n",
    "      --predict_with_generate \\\n",
    "      --freeze_encoder \\\n",
    "      --streaming False \\\n",
    "      --push_to_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "173692f2-afac-4f39-ac97-97e7a4c1b590",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzekamrozek\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>F:\\distiling_whisper_local\\wandb\\run-20240204_103033-49kay9oe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zekamrozek/distil-whisper/runs/49kay9oe' target=\"_blank\">grateful-moon-15</a></strong> to <a href='https://wandb.ai/zekamrozek/distil-whisper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/zekamrozek/distil-whisper' target=\"_blank\">https://wandb.ai/zekamrozek/distil-whisper</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/zekamrozek/distil-whisper/runs/49kay9oe' target=\"_blank\">https://wandb.ai/zekamrozek/distil-whisper/runs/49kay9oe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/04/2024 10:30:43 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "02/04/2024 10:30:43 - INFO - __main__ - Training/evaluation parameters DistillationTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=4,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=7200,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "dtype=float16,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=1000.0,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "freeze_encoder=True,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_config=None,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "kl_weight=1.0,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./result_distiling\\runs\\Feb04_10-30-29_DESKTOP-9H5C6TS,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=25,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant_with_warmup,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=10000,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "output_dir=./result_distiling,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=32,\n",
      "per_device_train_batch_size=32,\n",
      "predict_with_generate=False,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['wandb'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./result_distiling,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=True,\n",
      "save_steps=1000,\n",
      "save_strategy=steps,\n",
      "save_total_limit=3,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "split_batches=False,\n",
      "temperature=2.0,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=250,\n",
      "weight_decay=0.0,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 2. Initialize the accelerator\n",
    "# We will let the accelerator handle device placement for us in this example\n",
    "# We simply have to specify the training precision and any trackers being used\n",
    "# We'll use the same dtype arguments as our JAX/Flax training script and convert\n",
    "# it to accelerate format\n",
    "# The teacher model can safely be cast to the dtype of training since we don't\n",
    "# update the params\n",
    "if training_args.dtype == \"float16\":\n",
    "    mixed_precision = \"fp16\"\n",
    "    teacher_dtype = torch.float16\n",
    "elif training_args.dtype == \"bfloat16\":\n",
    "    mixed_precision = \"bf16\"\n",
    "    teacher_dtype = torch.bfloat16\n",
    "else:\n",
    "    mixed_precision = \"no\"\n",
    "    teacher_dtype = torch.float32\n",
    "\n",
    "accelerator = Accelerator(\n",
    "    gradient_accumulation_steps=training_args.gradient_accumulation_steps,\n",
    "    mixed_precision=mixed_precision,\n",
    "    log_with=training_args.report_to,\n",
    "    project_dir=training_args.output_dir,\n",
    ")\n",
    "\n",
    "accelerator.init_trackers(project_name=data_args.wandb_project)\n",
    "\n",
    "# 3. Set-up basic logging\n",
    "# Create one log on every process with the configuration for debugging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "# Log a small summary on each proces\n",
    "logger.warning(\n",
    "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}, \"\n",
    "    f\"distributed training: {training_args.parallel_mode.value == 'distributed'}, 16-bits training: {training_args.fp16}\"\n",
    ")\n",
    "\n",
    "# Set the verbosity to info of the Transformers logger (on main process only)\n",
    "if accelerator.is_local_main_process:\n",
    "    datasets.utils.logging.set_verbosity_warning()\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "else:\n",
    "    datasets.utils.logging.set_verbosity_error()\n",
    "    transformers.utils.logging.set_verbosity_error()\n",
    "logger.info(\"Training/evaluation parameters %s\", training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cef778b1-6b8e-4869-9d5e-826742fef631",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. Detecting last checkpoint and eventually continue from last checkpoint\n",
    "last_checkpoint = None\n",
    "if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n",
    "    last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "    if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "        raise ValueError(\n",
    "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "            \"Use --overwrite_output_dir to overcome.\"\n",
    "        )\n",
    "    elif last_checkpoint is not None and training_args.resume_from_checkpoint is None:\n",
    "        logger.info(\n",
    "            f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "            \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5335a96-b4d0-4198-827f-cba2ef4d94ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5. Handle the repository creation\n",
    "if accelerator.is_main_process:\n",
    "    if training_args.push_to_hub:\n",
    "        # Retrieve of infer repo_name\n",
    "        repo_name = training_args.hub_model_id\n",
    "        if repo_name is None:\n",
    "            repo_name = Path(training_args.output_dir).absolute().name\n",
    "        # Create repo and retrieve repo_id\n",
    "        repo_id = create_repo(repo_name, exist_ok=True, token=training_args.hub_token).repo_id\n",
    "        # Clone repo locally\n",
    "        repo = Repository(training_args.output_dir, clone_from=repo_id, token=training_args.hub_token)\n",
    "\n",
    "        with open(os.path.join(training_args.output_dir, \".gitignore\"), \"w+\") as gitignore:\n",
    "            if \"wandb\" not in gitignore:\n",
    "                gitignore.write(\"wandb\\n\")\n",
    "    elif training_args.output_dir is not None:\n",
    "        os.makedirs(training_args.output_dir, exist_ok=True)\n",
    "accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddf7754a-620a-449d-b2a0-cea788b1d3b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combining datasets...:   0%|                                                                     | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3a196b037448e1aefad12af01ec744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combining datasets...:  50%|██████████████████████████████▌                              | 1/2 [00:02<00:02,  2.53s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebed07913fd4792b1174d18c84ae92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combining datasets...: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# 6. Load dataset - either streaming or non-streaming (offline)\n",
    "raw_datasets = IterableDatasetDict() if data_args.streaming else DatasetDict()\n",
    "\n",
    "# set seed for determinism\n",
    "set_seed(training_args.seed)\n",
    "\n",
    "if training_args.do_train:\n",
    "    raw_datasets[\"train\"] = load_multiple_datasets(\n",
    "        data_args.train_dataset_name,\n",
    "        data_args.train_dataset_config_name,\n",
    "        splits=data_args.train_split_name,\n",
    "        text_column_names=data_args.text_column_name,\n",
    "        streaming=data_args.streaming,\n",
    "        dataset_samples=data_args.train_dataset_samples,\n",
    "        seed=training_args.seed,\n",
    "        accelerator=accelerator,\n",
    "        cache_dir=data_args.dataset_cache_dir,\n",
    "        token=model_args.token,\n",
    "    )\n",
    "    raw_datasets_train_features = list(raw_datasets[\"train\"].features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1270f4d0-0971-4ee9-85b3-7356067b83fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b306426f6a7841959f54ba4e59e6f8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training_args.do_eval:\n",
    "    dataset_names_dict = convert_dataset_str_to_list(\n",
    "        data_args.eval_dataset_name if data_args.eval_dataset_name else data_args.train_dataset_name,\n",
    "        data_args.eval_dataset_config_name\n",
    "        if data_args.eval_dataset_config_name\n",
    "        else data_args.train_dataset_config_name,\n",
    "        splits=data_args.eval_split_name,\n",
    "        text_column_names=data_args.eval_text_column_name,\n",
    "    )\n",
    "    all_eval_splits = []\n",
    "    if len(dataset_names_dict) == 1:\n",
    "        # load a single eval set\n",
    "        dataset_dict = dataset_names_dict[0]\n",
    "        all_eval_splits.append(\"eval\")\n",
    "        raw_datasets[\"eval\"] = load_dataset(\n",
    "            dataset_dict[\"name\"],\n",
    "            dataset_dict[\"config\"],\n",
    "            split=dataset_dict[\"split\"],\n",
    "            cache_dir=data_args.dataset_cache_dir,\n",
    "            token=model_args.token,\n",
    "            streaming=data_args.streaming,\n",
    "        )\n",
    "        if data_args.eval_text_column_name != \"text\":\n",
    "            raw_datasets[\"eval\"] = raw_datasets[\"eval\"].rename_column(data_args.eval_text_column_name, \"text\")\n",
    "    else:\n",
    "        # load multiple eval sets\n",
    "        for dataset_dict in dataset_names_dict:\n",
    "            if dataset_dict[\"name\"] == \"esb/diagnostic-dataset\":\n",
    "                # for the ESB diagnostic dataset, the dataset name is effectively the config\n",
    "                pretty_name = f\"{dataset_dict['config']}-diagnostic/{dataset_dict['split']}\"\n",
    "            else:\n",
    "                pretty_name = f\"{dataset_dict['name'].split('/')[-1]}/{dataset_dict['split'].replace('.', '-')}\"\n",
    "            all_eval_splits.append(pretty_name)\n",
    "            raw_datasets[pretty_name] = load_dataset(\n",
    "                dataset_dict[\"name\"],\n",
    "                dataset_dict[\"config\"],\n",
    "                split=dataset_dict[\"split\"],\n",
    "                cache_dir=data_args.dataset_cache_dir,\n",
    "                token=model_args.token,\n",
    "                streaming=data_args.streaming,\n",
    "            )\n",
    "            # make column names consistent (text, audio)\n",
    "            if dataset_dict[\"text_column_name\"] != \"text\":\n",
    "                raw_datasets[pretty_name] = raw_datasets[pretty_name].rename_column(\n",
    "                    dataset_dict[\"text_column_name\"], \"text\"\n",
    "                )\n",
    "            raw_datasets[pretty_name] = raw_datasets[pretty_name].remove_columns(\n",
    "                set(raw_datasets[pretty_name].features.keys()) - {\"audio\", \"text\"}\n",
    "            )\n",
    "\n",
    "if not training_args.do_train and not training_args.do_eval:\n",
    "    raise ValueError(\n",
    "        \"Cannot not train and not do evaluation. At least one of training or evaluation has to be performed.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eecf625-6143-4d42-ae37-7968aeef3664",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./student_model\\config.json\n",
      "Model config WhisperConfig {\n",
      "  \"_name_or_path\": \"openai/whisper-medium\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"apply_spec_augment\": false,\n",
      "  \"architectures\": [\n",
      "    \"WhisperForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50257\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 2,\n",
      "  \"decoder_start_token_id\": 50258,\n",
      "  \"dropout\": 0.0,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 24,\n",
      "  \"eos_token_id\": 50257,\n",
      "  \"forced_decoder_ids\": [\n",
      "    [\n",
      "      1,\n",
      "      50259\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      50359\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      50363\n",
      "    ]\n",
      "  ],\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"max_length\": 448,\n",
      "  \"max_source_positions\": 1500,\n",
      "  \"max_target_positions\": 448,\n",
      "  \"median_filter_width\": 7,\n",
      "  \"model_type\": \"whisper\",\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_mel_bins\": 80,\n",
      "  \"pad_token_id\": 50257,\n",
      "  \"scale_embedding\": false,\n",
      "  \"suppress_tokens\": [\n",
      "    1,\n",
      "    2,\n",
      "    7,\n",
      "    8,\n",
      "    9,\n",
      "    10,\n",
      "    14,\n",
      "    25,\n",
      "    26,\n",
      "    27,\n",
      "    28,\n",
      "    29,\n",
      "    31,\n",
      "    58,\n",
      "    59,\n",
      "    60,\n",
      "    61,\n",
      "    62,\n",
      "    63,\n",
      "    90,\n",
      "    91,\n",
      "    92,\n",
      "    93,\n",
      "    359,\n",
      "    503,\n",
      "    522,\n",
      "    542,\n",
      "    873,\n",
      "    893,\n",
      "    902,\n",
      "    918,\n",
      "    922,\n",
      "    931,\n",
      "    1350,\n",
      "    1853,\n",
      "    1982,\n",
      "    2460,\n",
      "    2627,\n",
      "    3246,\n",
      "    3253,\n",
      "    3268,\n",
      "    3536,\n",
      "    3846,\n",
      "    3961,\n",
      "    4183,\n",
      "    4667,\n",
      "    6585,\n",
      "    6647,\n",
      "    7273,\n",
      "    9061,\n",
      "    9383,\n",
      "    10428,\n",
      "    10929,\n",
      "    11938,\n",
      "    12033,\n",
      "    12331,\n",
      "    12562,\n",
      "    13793,\n",
      "    14157,\n",
      "    14635,\n",
      "    15265,\n",
      "    15618,\n",
      "    16553,\n",
      "    16604,\n",
      "    18362,\n",
      "    18956,\n",
      "    20075,\n",
      "    21675,\n",
      "    22520,\n",
      "    26130,\n",
      "    26161,\n",
      "    26435,\n",
      "    28279,\n",
      "    29464,\n",
      "    31650,\n",
      "    32302,\n",
      "    32470,\n",
      "    36865,\n",
      "    42863,\n",
      "    47425,\n",
      "    49870,\n",
      "    50254,\n",
      "    50258,\n",
      "    50358,\n",
      "    50359,\n",
      "    50360,\n",
      "    50361,\n",
      "    50362\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 51865\n",
      "}\n",
      "\n",
      "loading configuration file ./student_model\\preprocessor_config.json\n",
      "Feature extractor WhisperFeatureExtractor {\n",
      "  \"chunk_length\": 30,\n",
      "  \"feature_extractor_type\": \"WhisperFeatureExtractor\",\n",
      "  \"feature_size\": 80,\n",
      "  \"hop_length\": 160,\n",
      "  \"n_fft\": 400,\n",
      "  \"n_samples\": 480000,\n",
      "  \"nb_max_frames\": 3000,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0.0,\n",
      "  \"processor_class\": \"WhisperProcessor\",\n",
      "  \"return_attention_mask\": false,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "loading file vocab.json\n",
      "loading file tokenizer.json\n",
      "loading file merges.txt\n",
      "loading file normalizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Load pretrained model, tokenizer, and feature extractor\n",
    "config = WhisperConfig.from_pretrained(\n",
    "    (model_args.config_name if model_args.config_name else model_args.model_name_or_path),\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    token=model_args.token,\n",
    ")\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\n",
    "    (model_args.feature_extractor_name if model_args.feature_extractor_name else model_args.model_name_or_path),\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    token=model_args.token,\n",
    ")\n",
    "tokenizer = WhisperTokenizerFast.from_pretrained(\n",
    "    (model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path),\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    use_fast=model_args.use_fast_tokenizer,\n",
    "    revision=model_args.model_revision,\n",
    "    token=model_args.token,\n",
    ")\n",
    "\n",
    "# override timestamp tokens until tokenizer issues are fixed in transformers\n",
    "timestamps = [AddedToken(\"<|%.2f|>\" % (i * 0.02), lstrip=False, rstrip=False) for i in range(1500 + 1)]\n",
    "tokenizer.add_tokens(timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e94fae2c-324c-462f-bf2a-0703cedb9fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./local_whisper_medium\\config.json\n",
      "Model config WhisperConfig {\n",
      "  \"_name_or_path\": \"openai/whisper-medium\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"apply_spec_augment\": false,\n",
      "  \"architectures\": [\n",
      "    \"WhisperForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50257\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 24,\n",
      "  \"decoder_start_token_id\": 50258,\n",
      "  \"dropout\": 0.0,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 24,\n",
      "  \"eos_token_id\": 50257,\n",
      "  \"forced_decoder_ids\": [\n",
      "    [\n",
      "      1,\n",
      "      50259\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      50359\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      50363\n",
      "    ]\n",
      "  ],\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"max_length\": 448,\n",
      "  \"max_source_positions\": 1500,\n",
      "  \"max_target_positions\": 448,\n",
      "  \"median_filter_width\": 7,\n",
      "  \"model_type\": \"whisper\",\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_mel_bins\": 80,\n",
      "  \"pad_token_id\": 50257,\n",
      "  \"scale_embedding\": false,\n",
      "  \"suppress_tokens\": [\n",
      "    1,\n",
      "    2,\n",
      "    7,\n",
      "    8,\n",
      "    9,\n",
      "    10,\n",
      "    14,\n",
      "    25,\n",
      "    26,\n",
      "    27,\n",
      "    28,\n",
      "    29,\n",
      "    31,\n",
      "    58,\n",
      "    59,\n",
      "    60,\n",
      "    61,\n",
      "    62,\n",
      "    63,\n",
      "    90,\n",
      "    91,\n",
      "    92,\n",
      "    93,\n",
      "    359,\n",
      "    503,\n",
      "    522,\n",
      "    542,\n",
      "    873,\n",
      "    893,\n",
      "    902,\n",
      "    918,\n",
      "    922,\n",
      "    931,\n",
      "    1350,\n",
      "    1853,\n",
      "    1982,\n",
      "    2460,\n",
      "    2627,\n",
      "    3246,\n",
      "    3253,\n",
      "    3268,\n",
      "    3536,\n",
      "    3846,\n",
      "    3961,\n",
      "    4183,\n",
      "    4667,\n",
      "    6585,\n",
      "    6647,\n",
      "    7273,\n",
      "    9061,\n",
      "    9383,\n",
      "    10428,\n",
      "    10929,\n",
      "    11938,\n",
      "    12033,\n",
      "    12331,\n",
      "    12562,\n",
      "    13793,\n",
      "    14157,\n",
      "    14635,\n",
      "    15265,\n",
      "    15618,\n",
      "    16553,\n",
      "    16604,\n",
      "    18362,\n",
      "    18956,\n",
      "    20075,\n",
      "    21675,\n",
      "    22520,\n",
      "    26130,\n",
      "    26161,\n",
      "    26435,\n",
      "    28279,\n",
      "    29464,\n",
      "    31650,\n",
      "    32302,\n",
      "    32470,\n",
      "    36865,\n",
      "    42863,\n",
      "    47425,\n",
      "    49870,\n",
      "    50254,\n",
      "    50258,\n",
      "    50358,\n",
      "    50359,\n",
      "    50360,\n",
      "    50361,\n",
      "    50362\n",
      "  ],\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 51865\n",
      "}\n",
      "\n",
      "loading weights file ./local_whisper_medium\\model.safetensors\n",
      "Instantiating WhisperForConditionalGeneration model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50257\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"decoder_start_token_id\": 50258,\n",
      "  \"eos_token_id\": 50257,\n",
      "  \"forced_decoder_ids\": [\n",
      "    [\n",
      "      1,\n",
      "      50259\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      50359\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      50363\n",
      "    ]\n",
      "  ],\n",
      "  \"max_length\": 448,\n",
      "  \"pad_token_id\": 50257,\n",
      "  \"suppress_tokens\": [\n",
      "    1,\n",
      "    2,\n",
      "    7,\n",
      "    8,\n",
      "    9,\n",
      "    10,\n",
      "    14,\n",
      "    25,\n",
      "    26,\n",
      "    27,\n",
      "    28,\n",
      "    29,\n",
      "    31,\n",
      "    58,\n",
      "    59,\n",
      "    60,\n",
      "    61,\n",
      "    62,\n",
      "    63,\n",
      "    90,\n",
      "    91,\n",
      "    92,\n",
      "    93,\n",
      "    359,\n",
      "    503,\n",
      "    522,\n",
      "    542,\n",
      "    873,\n",
      "    893,\n",
      "    902,\n",
      "    918,\n",
      "    922,\n",
      "    931,\n",
      "    1350,\n",
      "    1853,\n",
      "    1982,\n",
      "    2460,\n",
      "    2627,\n",
      "    3246,\n",
      "    3253,\n",
      "    3268,\n",
      "    3536,\n",
      "    3846,\n",
      "    3961,\n",
      "    4183,\n",
      "    4667,\n",
      "    6585,\n",
      "    6647,\n",
      "    7273,\n",
      "    9061,\n",
      "    9383,\n",
      "    10428,\n",
      "    10929,\n",
      "    11938,\n",
      "    12033,\n",
      "    12331,\n",
      "    12562,\n",
      "    13793,\n",
      "    14157,\n",
      "    14635,\n",
      "    15265,\n",
      "    15618,\n",
      "    16553,\n",
      "    16604,\n",
      "    18362,\n",
      "    18956,\n",
      "    20075,\n",
      "    21675,\n",
      "    22520,\n",
      "    26130,\n",
      "    26161,\n",
      "    26435,\n",
      "    28279,\n",
      "    29464,\n",
      "    31650,\n",
      "    32302,\n",
      "    32470,\n",
      "    36865,\n",
      "    42863,\n",
      "    47425,\n",
      "    49870,\n",
      "    50254,\n",
      "    50258,\n",
      "    50358,\n",
      "    50359,\n",
      "    50360,\n",
      "    50361,\n",
      "    50362\n",
      "  ]\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing WhisperForConditionalGeneration.\n",
      "\n",
      "All the weights of WhisperForConditionalGeneration were initialized from the model checkpoint at ./local_whisper_medium.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use WhisperForConditionalGeneration for predictions without further training.\n",
      "loading configuration file ./local_whisper_medium\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"alignment_heads\": [\n",
      "    [\n",
      "      13,\n",
      "      15\n",
      "    ],\n",
      "    [\n",
      "      15,\n",
      "      4\n",
      "    ],\n",
      "    [\n",
      "      15,\n",
      "      15\n",
      "    ],\n",
      "    [\n",
      "      16,\n",
      "      1\n",
      "    ],\n",
      "    [\n",
      "      20,\n",
      "      0\n",
      "    ],\n",
      "    [\n",
      "      23,\n",
      "      4\n",
      "    ]\n",
      "  ],\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50257\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"decoder_start_token_id\": 50258,\n",
      "  \"eos_token_id\": 50257,\n",
      "  \"forced_decoder_ids\": [\n",
      "    [\n",
      "      1,\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      50359\n",
      "    ]\n",
      "  ],\n",
      "  \"is_multilingual\": true,\n",
      "  \"lang_to_id\": {\n",
      "    \"<|af|>\": 50327,\n",
      "    \"<|am|>\": 50334,\n",
      "    \"<|ar|>\": 50272,\n",
      "    \"<|as|>\": 50350,\n",
      "    \"<|az|>\": 50304,\n",
      "    \"<|ba|>\": 50355,\n",
      "    \"<|be|>\": 50330,\n",
      "    \"<|bg|>\": 50292,\n",
      "    \"<|bn|>\": 50302,\n",
      "    \"<|bo|>\": 50347,\n",
      "    \"<|br|>\": 50309,\n",
      "    \"<|bs|>\": 50315,\n",
      "    \"<|ca|>\": 50270,\n",
      "    \"<|cs|>\": 50283,\n",
      "    \"<|cy|>\": 50297,\n",
      "    \"<|da|>\": 50285,\n",
      "    \"<|de|>\": 50261,\n",
      "    \"<|el|>\": 50281,\n",
      "    \"<|en|>\": 50259,\n",
      "    \"<|es|>\": 50262,\n",
      "    \"<|et|>\": 50307,\n",
      "    \"<|eu|>\": 50310,\n",
      "    \"<|fa|>\": 50300,\n",
      "    \"<|fi|>\": 50277,\n",
      "    \"<|fo|>\": 50338,\n",
      "    \"<|fr|>\": 50265,\n",
      "    \"<|gl|>\": 50319,\n",
      "    \"<|gu|>\": 50333,\n",
      "    \"<|haw|>\": 50352,\n",
      "    \"<|ha|>\": 50354,\n",
      "    \"<|he|>\": 50279,\n",
      "    \"<|hi|>\": 50276,\n",
      "    \"<|hr|>\": 50291,\n",
      "    \"<|ht|>\": 50339,\n",
      "    \"<|hu|>\": 50286,\n",
      "    \"<|hy|>\": 50312,\n",
      "    \"<|id|>\": 50275,\n",
      "    \"<|is|>\": 50311,\n",
      "    \"<|it|>\": 50274,\n",
      "    \"<|ja|>\": 50266,\n",
      "    \"<|jw|>\": 50356,\n",
      "    \"<|ka|>\": 50329,\n",
      "    \"<|kk|>\": 50316,\n",
      "    \"<|km|>\": 50323,\n",
      "    \"<|kn|>\": 50306,\n",
      "    \"<|ko|>\": 50264,\n",
      "    \"<|la|>\": 50294,\n",
      "    \"<|lb|>\": 50345,\n",
      "    \"<|ln|>\": 50353,\n",
      "    \"<|lo|>\": 50336,\n",
      "    \"<|lt|>\": 50293,\n",
      "    \"<|lv|>\": 50301,\n",
      "    \"<|mg|>\": 50349,\n",
      "    \"<|mi|>\": 50295,\n",
      "    \"<|mk|>\": 50308,\n",
      "    \"<|ml|>\": 50296,\n",
      "    \"<|mn|>\": 50314,\n",
      "    \"<|mr|>\": 50320,\n",
      "    \"<|ms|>\": 50282,\n",
      "    \"<|mt|>\": 50343,\n",
      "    \"<|my|>\": 50346,\n",
      "    \"<|ne|>\": 50313,\n",
      "    \"<|nl|>\": 50271,\n",
      "    \"<|nn|>\": 50342,\n",
      "    \"<|no|>\": 50288,\n",
      "    \"<|oc|>\": 50328,\n",
      "    \"<|pa|>\": 50321,\n",
      "    \"<|pl|>\": 50269,\n",
      "    \"<|ps|>\": 50340,\n",
      "    \"<|pt|>\": 50267,\n",
      "    \"<|ro|>\": 50284,\n",
      "    \"<|ru|>\": 50263,\n",
      "    \"<|sa|>\": 50344,\n",
      "    \"<|sd|>\": 50332,\n",
      "    \"<|si|>\": 50322,\n",
      "    \"<|sk|>\": 50298,\n",
      "    \"<|sl|>\": 50305,\n",
      "    \"<|sn|>\": 50324,\n",
      "    \"<|so|>\": 50326,\n",
      "    \"<|sq|>\": 50317,\n",
      "    \"<|sr|>\": 50303,\n",
      "    \"<|su|>\": 50357,\n",
      "    \"<|sv|>\": 50273,\n",
      "    \"<|sw|>\": 50318,\n",
      "    \"<|ta|>\": 50287,\n",
      "    \"<|te|>\": 50299,\n",
      "    \"<|tg|>\": 50331,\n",
      "    \"<|th|>\": 50289,\n",
      "    \"<|tk|>\": 50341,\n",
      "    \"<|tl|>\": 50348,\n",
      "    \"<|tr|>\": 50268,\n",
      "    \"<|tt|>\": 50351,\n",
      "    \"<|uk|>\": 50280,\n",
      "    \"<|ur|>\": 50290,\n",
      "    \"<|uz|>\": 50337,\n",
      "    \"<|vi|>\": 50278,\n",
      "    \"<|yi|>\": 50335,\n",
      "    \"<|yo|>\": 50325,\n",
      "    \"<|zh|>\": 50260\n",
      "  },\n",
      "  \"max_initial_timestamp_index\": 50,\n",
      "  \"max_length\": 448,\n",
      "  \"no_timestamps_token_id\": 50363,\n",
      "  \"pad_token_id\": 50257,\n",
      "  \"prev_sot_token_id\": 50361,\n",
      "  \"return_timestamps\": false,\n",
      "  \"suppress_tokens\": [\n",
      "    1,\n",
      "    2,\n",
      "    7,\n",
      "    8,\n",
      "    9,\n",
      "    10,\n",
      "    14,\n",
      "    25,\n",
      "    26,\n",
      "    27,\n",
      "    28,\n",
      "    29,\n",
      "    31,\n",
      "    58,\n",
      "    59,\n",
      "    60,\n",
      "    61,\n",
      "    62,\n",
      "    63,\n",
      "    90,\n",
      "    91,\n",
      "    92,\n",
      "    93,\n",
      "    359,\n",
      "    503,\n",
      "    522,\n",
      "    542,\n",
      "    873,\n",
      "    893,\n",
      "    902,\n",
      "    918,\n",
      "    922,\n",
      "    931,\n",
      "    1350,\n",
      "    1853,\n",
      "    1982,\n",
      "    2460,\n",
      "    2627,\n",
      "    3246,\n",
      "    3253,\n",
      "    3268,\n",
      "    3536,\n",
      "    3846,\n",
      "    3961,\n",
      "    4183,\n",
      "    4667,\n",
      "    6585,\n",
      "    6647,\n",
      "    7273,\n",
      "    9061,\n",
      "    9383,\n",
      "    10428,\n",
      "    10929,\n",
      "    11938,\n",
      "    12033,\n",
      "    12331,\n",
      "    12562,\n",
      "    13793,\n",
      "    14157,\n",
      "    14635,\n",
      "    15265,\n",
      "    15618,\n",
      "    16553,\n",
      "    16604,\n",
      "    18362,\n",
      "    18956,\n",
      "    20075,\n",
      "    21675,\n",
      "    22520,\n",
      "    26130,\n",
      "    26161,\n",
      "    26435,\n",
      "    28279,\n",
      "    29464,\n",
      "    31650,\n",
      "    32302,\n",
      "    32470,\n",
      "    36865,\n",
      "    42863,\n",
      "    47425,\n",
      "    49870,\n",
      "    50254,\n",
      "    50258,\n",
      "    50358,\n",
      "    50359,\n",
      "    50360,\n",
      "    50361,\n",
      "    50362\n",
      "  ],\n",
      "  \"task_to_id\": {\n",
      "    \"transcribe\": 50359,\n",
      "    \"translate\": 50358\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teacher_model = WhisperForConditionalGeneration.from_pretrained(\n",
    "    model_args.teacher_model_name_or_path,\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    token=model_args.token,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=teacher_dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eab46b18-c45f-4887-81d7-c0a7b6654b99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# teacher_model.save_pretrained('./local_whisper_medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb611d22-0835-4147-8e74-5b653cff12dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file ./student_model\\model.safetensors\n",
      "Generate config GenerationConfig {\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50257\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"decoder_start_token_id\": 50258,\n",
      "  \"eos_token_id\": 50257,\n",
      "  \"forced_decoder_ids\": [\n",
      "    [\n",
      "      1,\n",
      "      50259\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      50359\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      50363\n",
      "    ]\n",
      "  ],\n",
      "  \"max_length\": 448,\n",
      "  \"pad_token_id\": 50257,\n",
      "  \"suppress_tokens\": [\n",
      "    1,\n",
      "    2,\n",
      "    7,\n",
      "    8,\n",
      "    9,\n",
      "    10,\n",
      "    14,\n",
      "    25,\n",
      "    26,\n",
      "    27,\n",
      "    28,\n",
      "    29,\n",
      "    31,\n",
      "    58,\n",
      "    59,\n",
      "    60,\n",
      "    61,\n",
      "    62,\n",
      "    63,\n",
      "    90,\n",
      "    91,\n",
      "    92,\n",
      "    93,\n",
      "    359,\n",
      "    503,\n",
      "    522,\n",
      "    542,\n",
      "    873,\n",
      "    893,\n",
      "    902,\n",
      "    918,\n",
      "    922,\n",
      "    931,\n",
      "    1350,\n",
      "    1853,\n",
      "    1982,\n",
      "    2460,\n",
      "    2627,\n",
      "    3246,\n",
      "    3253,\n",
      "    3268,\n",
      "    3536,\n",
      "    3846,\n",
      "    3961,\n",
      "    4183,\n",
      "    4667,\n",
      "    6585,\n",
      "    6647,\n",
      "    7273,\n",
      "    9061,\n",
      "    9383,\n",
      "    10428,\n",
      "    10929,\n",
      "    11938,\n",
      "    12033,\n",
      "    12331,\n",
      "    12562,\n",
      "    13793,\n",
      "    14157,\n",
      "    14635,\n",
      "    15265,\n",
      "    15618,\n",
      "    16553,\n",
      "    16604,\n",
      "    18362,\n",
      "    18956,\n",
      "    20075,\n",
      "    21675,\n",
      "    22520,\n",
      "    26130,\n",
      "    26161,\n",
      "    26435,\n",
      "    28279,\n",
      "    29464,\n",
      "    31650,\n",
      "    32302,\n",
      "    32470,\n",
      "    36865,\n",
      "    42863,\n",
      "    47425,\n",
      "    49870,\n",
      "    50254,\n",
      "    50258,\n",
      "    50358,\n",
      "    50359,\n",
      "    50360,\n",
      "    50361,\n",
      "    50362\n",
      "  ]\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing WhisperForConditionalGeneration.\n",
      "\n",
      "All the weights of WhisperForConditionalGeneration were initialized from the model checkpoint at ./student_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use WhisperForConditionalGeneration for predictions without further training.\n",
      "loading configuration file ./student_model\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"alignment_heads\": [\n",
      "    [\n",
      "      13,\n",
      "      15\n",
      "    ],\n",
      "    [\n",
      "      15,\n",
      "      4\n",
      "    ],\n",
      "    [\n",
      "      15,\n",
      "      15\n",
      "    ],\n",
      "    [\n",
      "      16,\n",
      "      1\n",
      "    ],\n",
      "    [\n",
      "      20,\n",
      "      0\n",
      "    ],\n",
      "    [\n",
      "      23,\n",
      "      4\n",
      "    ]\n",
      "  ],\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50257\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"decoder_start_token_id\": 50258,\n",
      "  \"eos_token_id\": 50257,\n",
      "  \"forced_decoder_ids\": [\n",
      "    [\n",
      "      1,\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      50359\n",
      "    ]\n",
      "  ],\n",
      "  \"is_multilingual\": true,\n",
      "  \"lang_to_id\": {\n",
      "    \"<|af|>\": 50327,\n",
      "    \"<|am|>\": 50334,\n",
      "    \"<|ar|>\": 50272,\n",
      "    \"<|as|>\": 50350,\n",
      "    \"<|az|>\": 50304,\n",
      "    \"<|ba|>\": 50355,\n",
      "    \"<|be|>\": 50330,\n",
      "    \"<|bg|>\": 50292,\n",
      "    \"<|bn|>\": 50302,\n",
      "    \"<|bo|>\": 50347,\n",
      "    \"<|br|>\": 50309,\n",
      "    \"<|bs|>\": 50315,\n",
      "    \"<|ca|>\": 50270,\n",
      "    \"<|cs|>\": 50283,\n",
      "    \"<|cy|>\": 50297,\n",
      "    \"<|da|>\": 50285,\n",
      "    \"<|de|>\": 50261,\n",
      "    \"<|el|>\": 50281,\n",
      "    \"<|en|>\": 50259,\n",
      "    \"<|es|>\": 50262,\n",
      "    \"<|et|>\": 50307,\n",
      "    \"<|eu|>\": 50310,\n",
      "    \"<|fa|>\": 50300,\n",
      "    \"<|fi|>\": 50277,\n",
      "    \"<|fo|>\": 50338,\n",
      "    \"<|fr|>\": 50265,\n",
      "    \"<|gl|>\": 50319,\n",
      "    \"<|gu|>\": 50333,\n",
      "    \"<|haw|>\": 50352,\n",
      "    \"<|ha|>\": 50354,\n",
      "    \"<|he|>\": 50279,\n",
      "    \"<|hi|>\": 50276,\n",
      "    \"<|hr|>\": 50291,\n",
      "    \"<|ht|>\": 50339,\n",
      "    \"<|hu|>\": 50286,\n",
      "    \"<|hy|>\": 50312,\n",
      "    \"<|id|>\": 50275,\n",
      "    \"<|is|>\": 50311,\n",
      "    \"<|it|>\": 50274,\n",
      "    \"<|ja|>\": 50266,\n",
      "    \"<|jw|>\": 50356,\n",
      "    \"<|ka|>\": 50329,\n",
      "    \"<|kk|>\": 50316,\n",
      "    \"<|km|>\": 50323,\n",
      "    \"<|kn|>\": 50306,\n",
      "    \"<|ko|>\": 50264,\n",
      "    \"<|la|>\": 50294,\n",
      "    \"<|lb|>\": 50345,\n",
      "    \"<|ln|>\": 50353,\n",
      "    \"<|lo|>\": 50336,\n",
      "    \"<|lt|>\": 50293,\n",
      "    \"<|lv|>\": 50301,\n",
      "    \"<|mg|>\": 50349,\n",
      "    \"<|mi|>\": 50295,\n",
      "    \"<|mk|>\": 50308,\n",
      "    \"<|ml|>\": 50296,\n",
      "    \"<|mn|>\": 50314,\n",
      "    \"<|mr|>\": 50320,\n",
      "    \"<|ms|>\": 50282,\n",
      "    \"<|mt|>\": 50343,\n",
      "    \"<|my|>\": 50346,\n",
      "    \"<|ne|>\": 50313,\n",
      "    \"<|nl|>\": 50271,\n",
      "    \"<|nn|>\": 50342,\n",
      "    \"<|no|>\": 50288,\n",
      "    \"<|oc|>\": 50328,\n",
      "    \"<|pa|>\": 50321,\n",
      "    \"<|pl|>\": 50269,\n",
      "    \"<|ps|>\": 50340,\n",
      "    \"<|pt|>\": 50267,\n",
      "    \"<|ro|>\": 50284,\n",
      "    \"<|ru|>\": 50263,\n",
      "    \"<|sa|>\": 50344,\n",
      "    \"<|sd|>\": 50332,\n",
      "    \"<|si|>\": 50322,\n",
      "    \"<|sk|>\": 50298,\n",
      "    \"<|sl|>\": 50305,\n",
      "    \"<|sn|>\": 50324,\n",
      "    \"<|so|>\": 50326,\n",
      "    \"<|sq|>\": 50317,\n",
      "    \"<|sr|>\": 50303,\n",
      "    \"<|su|>\": 50357,\n",
      "    \"<|sv|>\": 50273,\n",
      "    \"<|sw|>\": 50318,\n",
      "    \"<|ta|>\": 50287,\n",
      "    \"<|te|>\": 50299,\n",
      "    \"<|tg|>\": 50331,\n",
      "    \"<|th|>\": 50289,\n",
      "    \"<|tk|>\": 50341,\n",
      "    \"<|tl|>\": 50348,\n",
      "    \"<|tr|>\": 50268,\n",
      "    \"<|tt|>\": 50351,\n",
      "    \"<|uk|>\": 50280,\n",
      "    \"<|ur|>\": 50290,\n",
      "    \"<|uz|>\": 50337,\n",
      "    \"<|vi|>\": 50278,\n",
      "    \"<|yi|>\": 50335,\n",
      "    \"<|yo|>\": 50325,\n",
      "    \"<|zh|>\": 50260\n",
      "  },\n",
      "  \"max_initial_timestamp_index\": 1,\n",
      "  \"max_length\": 448,\n",
      "  \"no_timestamps_token_id\": 50363,\n",
      "  \"pad_token_id\": 50257,\n",
      "  \"return_timestamps\": false,\n",
      "  \"suppress_tokens\": [\n",
      "    1,\n",
      "    2,\n",
      "    7,\n",
      "    8,\n",
      "    9,\n",
      "    10,\n",
      "    14,\n",
      "    25,\n",
      "    26,\n",
      "    27,\n",
      "    28,\n",
      "    29,\n",
      "    31,\n",
      "    58,\n",
      "    59,\n",
      "    60,\n",
      "    61,\n",
      "    62,\n",
      "    63,\n",
      "    90,\n",
      "    91,\n",
      "    92,\n",
      "    93,\n",
      "    359,\n",
      "    503,\n",
      "    522,\n",
      "    542,\n",
      "    873,\n",
      "    893,\n",
      "    902,\n",
      "    918,\n",
      "    922,\n",
      "    931,\n",
      "    1350,\n",
      "    1853,\n",
      "    1982,\n",
      "    2460,\n",
      "    2627,\n",
      "    3246,\n",
      "    3253,\n",
      "    3268,\n",
      "    3536,\n",
      "    3846,\n",
      "    3961,\n",
      "    4183,\n",
      "    4667,\n",
      "    6585,\n",
      "    6647,\n",
      "    7273,\n",
      "    9061,\n",
      "    9383,\n",
      "    10428,\n",
      "    10929,\n",
      "    11938,\n",
      "    12033,\n",
      "    12331,\n",
      "    12562,\n",
      "    13793,\n",
      "    14157,\n",
      "    14635,\n",
      "    15265,\n",
      "    15618,\n",
      "    16553,\n",
      "    16604,\n",
      "    18362,\n",
      "    18956,\n",
      "    20075,\n",
      "    21675,\n",
      "    22520,\n",
      "    26130,\n",
      "    26161,\n",
      "    26435,\n",
      "    28279,\n",
      "    29464,\n",
      "    31650,\n",
      "    32302,\n",
      "    32470,\n",
      "    36865,\n",
      "    42863,\n",
      "    47425,\n",
      "    49870,\n",
      "    50254,\n",
      "    50258,\n",
      "    50358,\n",
      "    50359,\n",
      "    50360,\n",
      "    50361,\n",
      "    50362\n",
      "  ],\n",
      "  \"task_to_id\": {\n",
      "    \"transcribe\": 50359,\n",
      "    \"translate\": 50358\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "student_model = WhisperForConditionalGeneration.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    config=config,\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    subfolder=model_args.subfolder,\n",
    "    token=model_args.token,\n",
    "    low_cpu_mem_usage=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47e0f764-abca-497e-a0c0-b5a54d823a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if student_model.config.decoder_start_token_id is None or teacher_model.config.decoder_start_token_id is None:\n",
    "    raise ValueError(\n",
    "        f\"Make sure that `config.decoder_start_token_id` is correctly defined for both the \"\n",
    "        f\"student and teacher model. Got {student_model.config.decoder_start_token_id} for the \"\n",
    "        f\"student and {teacher_model.config.decoder_start_token_id} for the teacher.\"\n",
    "    )\n",
    "\n",
    "share_hidden_states = training_args.freeze_encoder and student_model.config.d_model == teacher_model.config.d_model\n",
    "\n",
    "# enable gradient checkpointing if necessary\n",
    "if training_args.gradient_checkpointing:\n",
    "    student_model.gradient_checkpointing_enable()\n",
    "\n",
    "# freeze student encoder if necessary\n",
    "if training_args.freeze_encoder:\n",
    "    student_model.freeze_encoder()\n",
    "    student_model.model.encoder.gradient_checkpointing = False\n",
    "\n",
    "# if share_hidden_states:\n",
    "# tie the weights for the student encoder if we're freezing it and it's the same as the teacher\n",
    "#    student_model.model.encoder = teacher_model.model.encoder\n",
    "\n",
    "if hasattr(teacher_model.generation_config, \"is_multilingual\") and teacher_model.generation_config.is_multilingual:\n",
    "    # We need to set the language and task ids for previously multilingual checkpoints\n",
    "    is_multilingual = True\n",
    "    tokenizer.set_prefix_tokens(language=data_args.language, task=data_args.task, predict_timestamps=False)\n",
    "    student_model.generation_config.update(\n",
    "        **{\n",
    "            \"language\": data_args.language,\n",
    "            \"task\": data_args.task,\n",
    "        }\n",
    "    )\n",
    "elif data_args.language is not None:\n",
    "    raise ValueError(\n",
    "        \"Setting language token for an English-only checkpoint is not permitted. The language argument should \"\n",
    "        \"only be set for multilingual checkpoints.\"\n",
    "    )\n",
    "else:\n",
    "    is_multilingual = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a33683d-4976-45ab-a540-c7681eb9774b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extractor saved in ./result_distiling\\preprocessor_config.json\n",
      "tokenizer config file saved in ./result_distiling\\tokenizer_config.json\n",
      "Special tokens file saved in ./result_distiling\\special_tokens_map.json\n",
      "Configuration saved in ./result_distiling\\config.json\n",
      "Configuration saved in ./result_distiling\\generation_config.json\n",
      "loading configuration file ./result_distiling\\preprocessor_config.json\n",
      "Feature extractor WhisperFeatureExtractor {\n",
      "  \"chunk_length\": 30,\n",
      "  \"feature_extractor_type\": \"WhisperFeatureExtractor\",\n",
      "  \"feature_size\": 80,\n",
      "  \"hop_length\": 160,\n",
      "  \"n_fft\": 400,\n",
      "  \"n_samples\": 480000,\n",
      "  \"nb_max_frames\": 3000,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0.0,\n",
      "  \"processor_class\": \"WhisperProcessor\",\n",
      "  \"return_attention_mask\": false,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "loading file vocab.json\n",
      "loading file tokenizer.json\n",
      "loading file merges.txt\n",
      "loading file normalizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# 8. Create a single speech processor - make sure all processes wait until data is saved\n",
    "if accelerator.is_main_process:\n",
    "    feature_extractor.save_pretrained(training_args.output_dir)\n",
    "    tokenizer.save_pretrained(training_args.output_dir)\n",
    "    # save the config and generation config as well\n",
    "    config.save_pretrained(training_args.output_dir)\n",
    "    student_model.generation_config.save_pretrained(training_args.output_dir)\n",
    "\n",
    "accelerator.wait_for_everyone()\n",
    "processor = WhisperProcessor.from_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "410b5932-8f58-47af-b4de-f13737e8d700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 9. Resample speech dataset: `datasets` takes care of automatically loading and resampling the audio,\n",
    "# so we just need to set the correct target sampling rate.\n",
    "sampling_rate = feature_extractor.sampling_rate\n",
    "raw_datasets = raw_datasets.cast_column(\n",
    "    data_args.audio_column_name,\n",
    "    datasets.features.Audio(sampling_rate=sampling_rate),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "589600c8-9014-41ca-8a2a-fc7516d51122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Preprocessing the datasets: we need to read the audio files as arrays and tokenize the targets.\n",
    "# 10.1: Define the pre-processing constants\n",
    "max_input_length = int(data_args.max_duration_in_seconds * sampling_rate)\n",
    "min_input_length = int(data_args.min_duration_in_seconds * sampling_rate)\n",
    "max_label_length = (\n",
    "    data_args.max_label_length if data_args.max_label_length is not None else student_model.config.max_length\n",
    ")\n",
    "\n",
    "timestamp_probability = data_args.timestamp_probability\n",
    "condition_on_prev_probability = data_args.condition_on_prev_probability\n",
    "return_timestamps = data_args.return_timestamps if timestamp_probability > 0 else False\n",
    "\n",
    "timestamp_ids = tokenizer.timestamp_ids()\n",
    "timestamp_begin = tokenizer.all_special_ids[-1]\n",
    "timestamp_position = 3 if is_multilingual else 1\n",
    "\n",
    "decoder_start_token_id = student_model.config.decoder_start_token_id  # <|startoftranscript|>\n",
    "decoder_prev_token_id = tokenizer.all_special_ids[-3]  # <|startofprev|>\n",
    "decoder_eot_token_id = tokenizer.eos_token_id\n",
    "\n",
    "language = data_args.language\n",
    "task = data_args.task\n",
    "\n",
    "num_workers = data_args.preprocessing_num_workers\n",
    "dataloader_num_workers = training_args.dataloader_num_workers\n",
    "\n",
    "metric = evaluate.load(\"wer\")\n",
    "normalizer = (\n",
    "    BasicTextNormalizer() if language is not None else EnglishTextNormalizer(tokenizer.english_spelling_normalizer)\n",
    ")\n",
    "wer_threshold = data_args.wer_threshold\n",
    "\n",
    "# 10.2: filter based on maximum number of training/evaluation samples\n",
    "if training_args.do_train and data_args.max_train_samples is not None:\n",
    "    raw_datasets[\"train\"] = (\n",
    "        raw_datasets[\"train\"].take(data_args.max_train_samples)\n",
    "        if data_args.streaming\n",
    "        else raw_datasets[\"train\"].select(range(data_args.max_train_samples))\n",
    "    )\n",
    "\n",
    "if training_args.do_eval and data_args.max_eval_samples is not None:\n",
    "    for eval_split in all_eval_splits:\n",
    "        raw_datasets[eval_split] = (\n",
    "            raw_datasets[eval_split].take(data_args.max_eval_samples)\n",
    "            if data_args.streaming\n",
    "            else raw_datasets[eval_split].select(range(data_args.max_eval_samples))\n",
    "        )\n",
    "\n",
    "# 10.3: filter training data based on WER threshold -> this is KEY to good distillation performance\n",
    "def is_wer_in_range(ground_truth, whisper_transcript):\n",
    "    norm_ground_truth = normalizer(ground_truth)\n",
    "    if (\n",
    "        isinstance(whisper_transcript, str)\n",
    "        and whisper_transcript.startswith(\"[\")\n",
    "        and whisper_transcript.endswith(\"]\")\n",
    "    ):\n",
    "        whisper_transcript = re.findall(r\"\\d+\", whisper_transcript)\n",
    "        whisper_transcript = [int(token) for token in whisper_transcript]\n",
    "    if isinstance(whisper_transcript, list):\n",
    "        whisper_transcript = tokenizer.decode(whisper_transcript, skip_special_tokens=True)\n",
    "    if len(norm_ground_truth) > 0 and whisper_transcript is not None:\n",
    "        norm_whisper_transcript = normalizer(whisper_transcript)\n",
    "        wer = 100 * metric.compute(predictions=[norm_whisper_transcript], references=[norm_ground_truth])\n",
    "        return wer < wer_threshold\n",
    "    else:\n",
    "        # filter automatically since we can't know the WER\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b6dae6c-60dc-44fe-ba50-75f9d296bc1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wer_threshold = 10.0#data_args.wer_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ee37ac3-514c-40c7-ae03-eeb89774b113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_by_wer_threshold = partial(\n",
    "    raw_datasets[\"train\"].filter,\n",
    "    function=is_wer_in_range,\n",
    "    input_columns=[\"text\", \"whisper_transcript\"],\n",
    ")\n",
    "\n",
    "if wer_threshold is not None:\n",
    "    raw_datasets[\"train\"] = (\n",
    "        filter_by_wer_threshold(num_proc=1, desc=\"filtering train dataset by wer\")\n",
    "        if not data_args.streaming\n",
    "        else filter_by_wer_threshold()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8ac6073-4540-4556-aeaa-69d9fcac072a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 10.4: pre-process training/evaluation datasets\n",
    "def has_timestamp_tokens(input_str):\n",
    "    \"\"\"\n",
    "    Identify whether the input string contains timestamp tokens, of the form <|0.00|>, by searching for\n",
    "    pairs of left and right-angle brackets.\n",
    "    \"\"\"\n",
    "    return bool(re.search(\"\\<[^\\>]*\\>\", input_str))\n",
    "\n",
    "def prepare_train_dataset(batch):\n",
    "    \"\"\"\n",
    "    Pre-process the raw dataset in a three stage process:\n",
    "        1. Convert the audio arrays to log-mel spectrogram inputs\n",
    "        2. Possibly filter the timestamp tokens from the token ids (depending on the timestamp probability)\n",
    "        3. Possibly add prompt tokens if conditioning on previous text (depending on the conditioning probability)\n",
    "    TODO(SG): see whether we can 'pack' the audio inputs closer to 30 second chunks\n",
    "    \"\"\"\n",
    "    # process audio input\n",
    "    audio = [sample[\"array\"] for sample in batch[\"audio\"]]\n",
    "    inputs = feature_extractor(audio, sampling_rate=sampling_rate)\n",
    "    batch[\"input_features\"] = inputs.input_features\n",
    "    batch[\"input_length\"] = [len(sample) for sample in audio]\n",
    "\n",
    "    # process text targets - for training these are the Whisper-generated pseudo-labels\n",
    "    input_str_batched = batch[\"whisper_transcript\"]\n",
    "\n",
    "    all_token_ids = []\n",
    "    all_token_ids_unprompted = []\n",
    "    for input_str in input_str_batched:\n",
    "        if isinstance(input_str, list):\n",
    "            # pseudo-labelled transcriptions have been retained as token ids (`decode_token_ids=False`)\n",
    "            token_ids = input_str\n",
    "        elif input_str[0].startswith(\"[\") and input_str[0].endswith(\"]\"):\n",
    "            token_ids = re.findall(r\"\\d+\", input_str)\n",
    "            token_ids = [int(token) for token in token_ids]\n",
    "        else:\n",
    "            token_ids = None\n",
    "\n",
    "        if token_ids is not None:\n",
    "            # remove the EOT tokens to get the 'true' token length\n",
    "            token_ids = [token for token in token_ids if token != decoder_eot_token_id]\n",
    "            token_ids = token_ids + [decoder_eot_token_id]\n",
    "            # check whether we have timestamps in the PLs and filter if required\n",
    "            has_timestamps = len(set(token_ids) & set(timestamp_ids)) > 0\n",
    "            if has_timestamps:\n",
    "                # sample from binomial distribution to get probability of training on timestamps\n",
    "                predict_timestamps = bool(np.random.binomial(1, timestamp_probability))\n",
    "                if not predict_timestamps:\n",
    "                    # filter timestamps and insert the <|notimestamps|> task token\n",
    "                    token_ids = [token for token in token_ids if token < timestamp_begin]\n",
    "                    token_ids.insert(timestamp_position, timestamp_begin)\n",
    "        else:\n",
    "            # pseudo-labelled transcriptions have been decoded to text (`decode_token_ids=True`)\n",
    "            has_timestamps = has_timestamp_tokens(input_str)\n",
    "\n",
    "            if has_timestamps:\n",
    "                predict_timestamps = bool(np.random.binomial(1, timestamp_probability))\n",
    "                if not predict_timestamps:\n",
    "                    # filter timestamp token ids if not part of the prediction task\n",
    "                    input_str = tokenizer._filter_timestamp_ids(input_str)\n",
    "            else:\n",
    "                predict_timestamps = False\n",
    "\n",
    "            tokenizer.set_prefix_tokens(language=language, task=task, predict_timestamps=predict_timestamps)\n",
    "            token_ids = tokenizer(input_str).input_ids\n",
    "\n",
    "        all_token_ids_unprompted.append(token_ids)\n",
    "        # check whether to condition on previous text - we do this with probability condition_on_prev_probability\n",
    "        condition_on_prev = bool(np.random.binomial(1, condition_on_prev_probability))\n",
    "        if condition_on_prev and len(all_token_ids_unprompted) > 1:\n",
    "            # prompt ids are the penultimate token ids in the batch\n",
    "            prompt_ids = all_token_ids_unprompted[-2]\n",
    "            # strip timestamp tokens from prompt\n",
    "            prompt_ids = [token for token in prompt_ids if token < timestamp_begin]\n",
    "            if len(prompt_ids) > 0:\n",
    "                # remove the standard task tokens and add the special <|startofprev|> token\n",
    "                prompt_ids = [decoder_prev_token_id] + prompt_ids[timestamp_position:-1]\n",
    "            if len(prompt_ids + token_ids) < max_label_length:\n",
    "                token_ids = prompt_ids + token_ids\n",
    "        all_token_ids.append(token_ids)\n",
    "\n",
    "    batch[\"labels\"] = all_token_ids\n",
    "    return batch\n",
    "\n",
    "def prepare_eval_dataset(batch):\n",
    "    # process audio input\n",
    "    sample = batch[\"audio\"]\n",
    "    inputs = feature_extractor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"])\n",
    "    batch[\"input_features\"] = inputs.input_features[0]\n",
    "    batch[\"input_length\"] = len(sample[\"array\"])\n",
    "\n",
    "    # process targets - for evaluation these are the ground-truth transcriptions\n",
    "    input_str = batch[\"text\"]\n",
    "    batch[\"labels\"] = tokenizer(input_str).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "566cc200-82ff-4e0a-86a2-e2c936bc9e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorized_datasets = IterableDatasetDict() if data_args.streaming else DatasetDict()\n",
    "if training_args.do_train:\n",
    "    # with streaming mode we can only have 1 worker, whereas with non-streaming\n",
    "    # we can use `num_workers` (which is much faster)\n",
    "    # We gate the pre-processing function accordingly\n",
    "    map_fn_train = partial(\n",
    "        raw_datasets[\"train\"].map,\n",
    "        function=prepare_train_dataset,\n",
    "        remove_columns=raw_datasets_train_features,\n",
    "        batched=True,\n",
    "        batch_size=max(training_args.per_device_train_batch_size // 4, 4),  # TODO(SG) make data prep bs configurable\n",
    "    )\n",
    "    vectorized_datasets[\"train\"] = (\n",
    "        map_fn_train(num_proc=1, desc=\"preprocess train dataset\")\n",
    "        if not data_args.streaming\n",
    "        else map_fn_train()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "033fa515-e73f-48b9-83fd-c180db3a5ace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if training_args.do_eval:\n",
    "    for eval_split in all_eval_splits:\n",
    "        raw_datasets_eval_features = list(raw_datasets[eval_split].features.keys())\n",
    "        map_fn_eval = partial(\n",
    "            raw_datasets[eval_split].map, function=prepare_eval_dataset, remove_columns=raw_datasets_eval_features\n",
    "        )\n",
    "        if accelerator.is_main_process:\n",
    "            vectorized_datasets[eval_split] = (\n",
    "                map_fn_eval(num_proc=1, desc=\"preprocess eval dataset\")\n",
    "                if not data_args.streaming\n",
    "                else map_fn_eval()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed788686-1409-4a04-a868-23200ed145db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 10.5: Filter training data with inputs longer than `max_input_length`\n",
    "def is_audio_in_length_range(length):\n",
    "    return min_input_length < length < max_input_length\n",
    "\n",
    "filter_by_audio_fn = partial(\n",
    "    vectorized_datasets.filter, function=is_audio_in_length_range, input_columns=[\"input_length\"]\n",
    ")\n",
    "vectorized_datasets = (\n",
    "    filter_by_audio_fn(num_proc=1, desc=\"filtering train dataset by audio length\")\n",
    "    if not data_args.streaming\n",
    "    else filter_by_audio_fn()\n",
    ")\n",
    "\n",
    "# 10.6: Filter training data with labels longer than `max_label_length`\n",
    "def is_labels_in_length_range(labels):\n",
    "    return 0 < len(labels) <= max_label_length\n",
    "\n",
    "filter_by_labels_fn = partial(\n",
    "    vectorized_datasets.filter, function=is_labels_in_length_range, input_columns=[\"labels\"]\n",
    ")\n",
    "vectorized_datasets = (\n",
    "    filter_by_labels_fn(num_proc=1, desc=\"filtering train dataset\")\n",
    "    if not data_args.streaming\n",
    "    else filter_by_labels_fn()\n",
    ")\n",
    "\n",
    "# Pre-processing complete!\n",
    "# For large datasets it is advised to run the preprocessing on a\n",
    "# single machine first with `--preprocessing_only` since there will mostly likely\n",
    "# be a timeout when running the script in distributed mode.\n",
    "# In a second step, `--preprocessing_only` can then be set to `False` to load the\n",
    "# cached dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c7beaf6-5e5a-423c-8d83-a7a30cbac35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_args.preprocessing_only:\n",
    "    if data_args.streaming:\n",
    "        raise ValueError(\n",
    "            \"When using streaming mode, dataset pre-processing is performed on the fly, hence there is no notion\"\n",
    "            \"of a cached pre-processed dataset. Remove the argument `--preprocessing_only` to run pre-processing \"\n",
    "            \"on the fly with streaming mode.\"\n",
    "        )\n",
    "    cache = {k: v.cache_files for k, v in vectorized_datasets.items()}\n",
    "    logger.info(f\"Data preprocessing finished. Files cached at {cache}.\")\n",
    "    # return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "614234ed-402c-4847-8406-fc2f1e4b8caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Define Evaluation Metrics\n",
    "def compute_metrics(preds, labels):\n",
    "    # replace padded labels by the padding token\n",
    "    for idx in range(len(labels)):\n",
    "        labels[idx][labels[idx] == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(preds, skip_special_tokens=True, decode_with_timestamps=return_timestamps)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    wer_ortho = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    # normalize everything and re-compute the WER\n",
    "    norm_pred_str = [normalizer(pred) for pred in pred_str]\n",
    "    norm_label_str = [normalizer(label) for label in label_str]\n",
    "    # for logging, we need the pred/labels to match the norm_pred/norm_labels, so discard any filtered samples here\n",
    "    pred_str = [pred_str[i] for i in range(len(norm_pred_str)) if len(norm_label_str[i]) > 0]\n",
    "    label_str = [label_str[i] for i in range(len(norm_label_str)) if len(norm_label_str[i]) > 0]\n",
    "    # filtering step to only evaluate the samples that correspond to non-zero normalized references:\n",
    "    norm_pred_str = [norm_pred_str[i] for i in range(len(norm_pred_str)) if len(norm_label_str[i]) > 0]\n",
    "    norm_label_str = [norm_label_str[i] for i in range(len(norm_label_str)) if len(norm_label_str[i]) > 0]\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=norm_pred_str, references=norm_label_str)\n",
    "    return {\"wer\": wer, \"wer_ortho\": wer_ortho}, pred_str, label_str, norm_pred_str, norm_label_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1854cb9b-8362-43c8-b824-a67e12386493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/04/2024 10:31:02 - INFO - __main__ - max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "# 12. Define Training Schedule\n",
    "# Store some constants\n",
    "per_device_train_batch_size = int(training_args.per_device_train_batch_size)\n",
    "train_batch_size = per_device_train_batch_size * accelerator.num_processes\n",
    "gradient_accumulation_steps = int(training_args.gradient_accumulation_steps)\n",
    "per_device_eval_batch_size = int(training_args.per_device_eval_batch_size)\n",
    "\n",
    "if not data_args.streaming and training_args.max_steps < 0:\n",
    "    num_epochs = int(training_args.num_train_epochs)\n",
    "    steps_per_epoch = len(vectorized_datasets[\"train\"]) // (train_batch_size * gradient_accumulation_steps)\n",
    "    total_train_steps = steps_per_epoch * num_epochs\n",
    "elif training_args.max_steps > 0:\n",
    "    logger.info(\"max_steps is given, it will override any value given in num_train_epochs\")\n",
    "    total_train_steps = int(training_args.max_steps)\n",
    "    # Setting a very large number of epochs so we go as many times as necessary over the iterator.\n",
    "    num_epochs = sys.maxsize\n",
    "    steps_per_epoch = total_train_steps\n",
    "else:\n",
    "    raise ValueError(\"max_steps must be specified when training with a streaming (iterable) dataset\")\n",
    "\n",
    "if training_args.eval_steps is None:\n",
    "    logger.info(\n",
    "        f\"eval_steps is not set, evaluating at the end of {'each epoch' if not data_args.streaming else 'training'}\"\n",
    "    )\n",
    "    eval_steps = steps_per_epoch\n",
    "else:\n",
    "    eval_steps = training_args.eval_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6f8ecd3-10b4-4f70-a8cc-44ac875ecc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Define optimizer, LR scheduler, collator\n",
    "decay_parameters = get_parameter_names(\n",
    "    student_model,\n",
    "    [nn.LayerNorm],\n",
    "    forbidden_module=[student_model.model.encoder] if training_args.freeze_encoder else None,\n",
    ")\n",
    "decay_parameters = [name for name in decay_parameters if \"bias\" not in name]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [param for name, param in student_model.named_parameters() if name in decay_parameters],\n",
    "        \"weight_decay\": training_args.weight_decay,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [param for name, param in student_model.named_parameters() if name not in decay_parameters],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=optimizer_grouped_parameters,\n",
    "    lr=training_args.learning_rate,\n",
    "    betas=(training_args.adam_beta1, training_args.adam_beta2),\n",
    "    eps=training_args.adam_epsilon,\n",
    ")\n",
    "\n",
    "# LR scheduler gets stepped by `num_processes` each time -> account for this in warmup / total steps\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=training_args.lr_scheduler_type,\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=training_args.warmup_steps * accelerator.num_processes,\n",
    "    num_training_steps=total_train_steps * accelerator.num_processes,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=decoder_start_token_id,\n",
    "    decoder_prev_token_id=decoder_prev_token_id,\n",
    "    input_padding=\"longest\",\n",
    "    target_padding=\"max_length\",\n",
    "    max_target_length=max_label_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c79087ec-db1e-47c6-939f-87384fb39fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Define generation arguments - we need to do this before we wrap the models in DDP\n",
    "# so that we can still access the configs\n",
    "num_beams = (\n",
    "    training_args.generation_num_beams\n",
    "    if training_args.generation_num_beams is not None\n",
    "    else getattr(student_model.generation_config, \"num_beams\", 1)\n",
    ")\n",
    "\n",
    "gen_kwargs = {\n",
    "    \"max_length\": max_label_length,\n",
    "    \"num_beams\": num_beams,\n",
    "    \"return_timestamps\": return_timestamps,\n",
    "}\n",
    "if hasattr(teacher_model.generation_config, \"is_multilingual\") and teacher_model.generation_config.is_multilingual:\n",
    "    # forcing the language and task tokens helps multilingual models in their generations\n",
    "    gen_kwargs.update(\n",
    "        {\n",
    "            \"language\": data_args.language,\n",
    "            \"task\": data_args.task,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91f94ce5-d385-486f-a0dd-cf7898e4c9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Prepare everything with accelerate\n",
    "student_model, teacher_model, optimizer, lr_scheduler = accelerator.prepare(\n",
    "    student_model, teacher_model, optimizer, lr_scheduler\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8027d324-ace5-4ca4-a886-2cbce2c42d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kl_divergence(target_distribution, log_predicted_distribution, labels):\n",
    "    kl_loss = nn.KLDivLoss(reduction=\"none\")\n",
    "    divergence = kl_loss(log_predicted_distribution, target_distribution)\n",
    "    # ignore padded tokens from divergence, i.e. where labels are not set to -100\n",
    "    padding_mask = labels >= 0\n",
    "    padding_mask = padding_mask.unsqueeze(-1)\n",
    "    divergence = divergence * padding_mask\n",
    "    # take the average over the mini-batch\n",
    "    divergence = divergence.sum() / padding_mask.sum()\n",
    "    return divergence\n",
    "\n",
    "# Define gradient update step fn\n",
    "def train_step(\n",
    "    batch,\n",
    "    temperature=2.0,\n",
    "):\n",
    "    student_model.train()\n",
    "    teacher_model.eval()\n",
    "\n",
    "    student_outputs = student_model(**batch)\n",
    "    with torch.no_grad():\n",
    "        if share_hidden_states:\n",
    "            # if the student and teacher share the same frozen encoder then we don't have to recompute the\n",
    "            # encoder hidden-states for the teacher model, we can just re-use from the student\n",
    "            encoder_outputs = BaseModelOutput(student_outputs.encoder_last_hidden_state)\n",
    "            teacher_outputs = teacher_model(encoder_outputs=encoder_outputs, labels=batch[\"labels\"])\n",
    "        else:\n",
    "            # do the full forward pass for the teacher model (encoder + decoder)\n",
    "            teacher_outputs = teacher_model(**batch)\n",
    "\n",
    "    # CE (data) loss\n",
    "    ce_loss = student_outputs.loss\n",
    "    # rescale distribution by temperature to ensure gradients scale correctly\n",
    "    teacher_distribution = nn.functional.softmax(teacher_outputs.logits / temperature, dim=-1)\n",
    "    # log softmax of student predictions for numerical stability\n",
    "    student_distribution = nn.functional.log_softmax(student_outputs.logits / temperature, dim=-1)\n",
    "    # KL-divergence loss (scaled by temperature)\n",
    "    kl_loss = kl_divergence(teacher_distribution, student_distribution, batch[\"labels\"]) * temperature**2\n",
    "\n",
    "    # use Distil-Whisper formulation (fix weight of CE loss and tune KL weight)\n",
    "    loss = 0.8 * ce_loss + training_args.kl_weight * kl_loss\n",
    "    metrics = {\"loss\": loss, \"ce_loss\": ce_loss, \"kl_loss\": kl_loss}\n",
    "    return loss, metrics\n",
    "\n",
    "# Define eval fn\n",
    "def eval_step(batch):\n",
    "    student_model.eval()\n",
    "    teacher_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        student_outputs = student_model(**batch)\n",
    "        if share_hidden_states:\n",
    "            encoder_outputs = BaseModelOutput(student_outputs.encoder_last_hidden_state)\n",
    "            teacher_outputs = teacher_model(encoder_outputs=encoder_outputs, labels=batch[\"labels\"])\n",
    "        else:\n",
    "            teacher_outputs = teacher_model(**batch)\n",
    "\n",
    "    # CE (data) loss\n",
    "    ce_loss = student_outputs.loss\n",
    "\n",
    "    # log softmax / softmax for numerical stability\n",
    "    student_distribution = nn.functional.log_softmax(student_outputs.logits, dim=-1)\n",
    "    teacher_distribution = nn.functional.softmax(teacher_outputs.logits, dim=-1)\n",
    "    # temperature is always 1 for eval\n",
    "    kl_loss = kl_divergence(teacher_distribution, student_distribution, batch[\"labels\"])\n",
    "\n",
    "    # use Distil-Whisper formulation (fix weight of CE loss and tune KL weight)\n",
    "    loss = 0.8 * ce_loss + training_args.kl_weight * kl_loss\n",
    "    metrics = {\"loss\": loss, \"ce_loss\": ce_loss, \"kl_loss\": kl_loss}\n",
    "    return metrics\n",
    "\n",
    "def generate_step(batch):\n",
    "    student_model.eval()\n",
    "    output_ids = accelerator.unwrap_model(student_model).generate(batch[\"input_features\"], **gen_kwargs)\n",
    "    output_ids = accelerator.pad_across_processes(output_ids, dim=1, pad_index=tokenizer.pad_token_id)\n",
    "    return output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e07bf3c-27b4-4f0a-a856-8da6cdb3a141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/04/2024 10:31:08 - INFO - __main__ - ***** Running training *****\n",
      "02/04/2024 10:31:08 - INFO - __main__ -   Num examples = 320000\n",
      "02/04/2024 10:31:08 - INFO - __main__ -   Instantaneous batch size per device = 32\n",
      "02/04/2024 10:31:08 - INFO - __main__ -   Gradient accumulation steps = 1\n",
      "02/04/2024 10:31:08 - INFO - __main__ -   Total train batch size (w. parallel & distributed) = 32\n",
      "02/04/2024 10:31:08 - INFO - __main__ -   Total optimization steps = 10000\n",
      "Train steps ... :   0%|                                                                      | 0/10000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(f\"  Num examples = {total_train_steps * train_batch_size * gradient_accumulation_steps}\")\n",
    "logger.info(\"  Instantaneous batch size per device =\" f\" {training_args.per_device_train_batch_size}\")\n",
    "logger.info(\"  Gradient accumulation steps =\" f\" {gradient_accumulation_steps}\")\n",
    "logger.info(\n",
    "    f\"  Total train batch size (w. parallel & distributed) = {train_batch_size * gradient_accumulation_steps}\"\n",
    ")\n",
    "logger.info(f\"  Total optimization steps = {total_train_steps}\")\n",
    "\n",
    "# ======================== Training ================================\n",
    "train_time = 0\n",
    "train_start = time.time()\n",
    "steps_trained_progress_bar = tqdm(\n",
    "    range(total_train_steps), desc=\"Train steps ... \", position=0, disable=not accelerator.is_local_main_process\n",
    ")\n",
    "continue_training = True\n",
    "epochs_trained = 0\n",
    "cur_step = 0\n",
    "\n",
    "checkpoint = None\n",
    "if training_args.resume_from_checkpoint is not None:\n",
    "    checkpoint = training_args.resume_from_checkpoint\n",
    "elif last_checkpoint is not None:\n",
    "    checkpoint = last_checkpoint\n",
    "\n",
    "if checkpoint is not None:\n",
    "    accelerator.load_state(checkpoint)\n",
    "    # Find num steps and epoch from saved state string pattern\n",
    "    pattern = r\"checkpoint-(\\d+)-epoch-(\\d+)\"\n",
    "    match = re.search(pattern, checkpoint)\n",
    "    cur_step = int(match.group(1))\n",
    "    epochs_trained = int(match.group(2))\n",
    "\n",
    "    logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
    "    logger.info(f\"  Continuing training from epoch {epochs_trained}\")\n",
    "    logger.info(f\"  Continuing training from global step {cur_step}\")\n",
    "\n",
    "    steps_trained_progress_bar.update(cur_step)\n",
    "\n",
    "    for epoch in range(0, epochs_trained):\n",
    "        vectorized_datasets[\"train\"] = vectorized_datasets[\"train\"].shuffle(training_args.seed)\n",
    "\n",
    "    if not data_args.streaming and training_args.max_steps < 0:\n",
    "        # we know exactly the number of steps per epoch, so can skip through the required number of batches\n",
    "        resume_step = (cur_step - epochs_trained * steps_per_epoch) * gradient_accumulation_steps\n",
    "    else:\n",
    "        # Currently we don't know how many steps we've taken in the current epoch\n",
    "        # So we just shuffle the dataset one extra time and start from a fresh epoch\n",
    "        # This is \"good enough\" for our purposes but not fully correct\n",
    "        resume_step = None\n",
    "        vectorized_datasets[\"train\"] = vectorized_datasets[\"train\"].shuffle(training_args.seed)\n",
    "else:\n",
    "    resume_step = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e02eb65-bc78-4408-8c30-3dc561d7d13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n",
      "F:\\anaconda\\envs\\disenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Train steps ... :   0%|▏                                                          | 25/10000 [02:10<6:22:48,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (25 / 10000 | Loss: 41.92710876464844, Learning Rate: 6.800000000000001e-07)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   0%|▎                                                          | 50/10000 [03:07<6:24:12,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (50 / 10000 | Loss: 15.329315185546875, Learning Rate: 1.6800000000000002e-06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   1%|▍                                                          | 75/10000 [04:05<6:24:12,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (75 / 10000 | Loss: 11.276897430419922, Learning Rate: 2.68e-06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   1%|▌                                                         | 100/10000 [05:04<6:24:20,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (100 / 10000 | Loss: 10.015430450439453, Learning Rate: 3.6800000000000003e-06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   1%|▋                                                         | 125/10000 [06:02<6:23:36,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (125 / 10000 | Loss: 9.321096420288086, Learning Rate: 4.680000000000001e-06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   2%|▊                                                         | 150/10000 [07:01<6:35:44,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (150 / 10000 | Loss: 9.095651626586914, Learning Rate: 5.68e-06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   2%|█                                                         | 175/10000 [07:59<6:22:07,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (175 / 10000 | Loss: 8.584434509277344, Learning Rate: 6.680000000000001e-06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   2%|█▏                                                        | 200/10000 [08:58<6:22:07,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (200 / 10000 | Loss: 8.269378662109375, Learning Rate: 7.680000000000001e-06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   2%|█▎                                                        | 225/10000 [09:56<6:22:19,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (225 / 10000 | Loss: 7.682929992675781, Learning Rate: 8.68e-06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   2%|█▍                                                        | 250/10000 [10:55<6:20:48,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (250 / 10000 | Loss: 7.638886451721191, Learning Rate: 9.68e-06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   3%|█▌                                                        | 275/10000 [11:54<6:20:38,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (275 / 10000 | Loss: 7.071961402893066, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   3%|█▋                                                        | 300/10000 [12:52<6:19:22,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (300 / 10000 | Loss: 7.152584552764893, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   3%|█▉                                                        | 325/10000 [13:51<6:18:57,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (325 / 10000 | Loss: 6.601200580596924, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   4%|██                                                        | 350/10000 [14:50<6:17:00,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (350 / 10000 | Loss: 6.5094122886657715, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   4%|██▏                                                       | 375/10000 [15:48<6:16:54,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (375 / 10000 | Loss: 6.489633560180664, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   4%|██▎                                                       | 400/10000 [16:47<6:15:47,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (400 / 10000 | Loss: 6.1864399909973145, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   4%|██▍                                                       | 425/10000 [17:46<6:15:00,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (425 / 10000 | Loss: 5.814679145812988, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   4%|██▌                                                       | 450/10000 [18:45<6:13:29,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (450 / 10000 | Loss: 5.723906517028809, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   5%|██▊                                                       | 475/10000 [19:43<6:13:27,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (475 / 10000 | Loss: 5.402843475341797, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   5%|██▉                                                       | 500/10000 [20:42<6:12:18,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (500 / 10000 | Loss: 5.569602012634277, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   5%|███                                                       | 525/10000 [21:41<6:11:46,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (525 / 10000 | Loss: 5.593596458435059, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   6%|███▏                                                      | 550/10000 [22:40<6:10:22,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (550 / 10000 | Loss: 5.162637233734131, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   6%|███▎                                                      | 575/10000 [23:39<6:09:59,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (575 / 10000 | Loss: 5.484014511108398, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   6%|███▍                                                      | 600/10000 [24:38<6:08:47,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (600 / 10000 | Loss: 5.152007102966309, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   6%|███▋                                                      | 625/10000 [25:36<6:07:16,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (625 / 10000 | Loss: 5.199711799621582, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   6%|███▊                                                      | 650/10000 [26:35<6:06:48,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (650 / 10000 | Loss: 4.90510892868042, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   7%|███▉                                                      | 675/10000 [27:34<6:06:03,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (675 / 10000 | Loss: 4.932914733886719, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   7%|████                                                      | 700/10000 [28:33<6:05:11,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (700 / 10000 | Loss: 4.795197010040283, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   7%|████▏                                                     | 725/10000 [29:32<6:03:07,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (725 / 10000 | Loss: 4.612682342529297, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   8%|████▎                                                     | 750/10000 [30:30<6:03:11,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (750 / 10000 | Loss: 4.644632339477539, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   8%|████▍                                                     | 775/10000 [31:29<6:02:25,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (775 / 10000 | Loss: 4.419835567474365, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   8%|████▋                                                     | 800/10000 [32:28<6:00:10,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (800 / 10000 | Loss: 4.044520378112793, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   8%|████▊                                                     | 825/10000 [33:27<5:59:54,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (825 / 10000 | Loss: 4.3427863121032715, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   8%|████▉                                                     | 850/10000 [34:26<5:58:56,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (850 / 10000 | Loss: 4.274497985839844, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   9%|█████                                                     | 875/10000 [35:25<5:57:23,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (875 / 10000 | Loss: 3.796510934829712, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   9%|█████▏                                                    | 900/10000 [36:23<5:56:39,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (900 / 10000 | Loss: 4.503262996673584, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :   9%|█████▎                                                    | 925/10000 [37:22<5:55:14,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (925 / 10000 | Loss: 4.044119358062744, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  10%|█████▌                                                    | 950/10000 [38:21<5:54:31,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (950 / 10000 | Loss: 4.548701286315918, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  10%|█████▋                                                    | 975/10000 [39:20<5:52:14,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (975 / 10000 | Loss: 4.218407154083252, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  10%|█████▋                                                   | 1000/10000 [41:47<5:49:00,  2.33s/it]02/04/2024 11:12:55 - INFO - accelerate.accelerator - Saving current state to ./result_distiling\\checkpoint-1000-epoch-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1000 / 10000 | Loss: 3.919229030609131, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/04/2024 11:12:56 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n",
      "02/04/2024 11:12:57 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-1000-epoch-1\\model.safetensors\n",
      "02/04/2024 11:12:57 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n",
      "02/04/2024 11:12:58 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-1000-epoch-1\\model_1.safetensors\n",
      "02/04/2024 11:13:00 - INFO - accelerate.checkpointing - Optimizer state saved in result_distiling\\checkpoint-1000-epoch-1\\optimizer.bin\n",
      "02/04/2024 11:13:00 - INFO - accelerate.checkpointing - Scheduler state saved in result_distiling\\checkpoint-1000-epoch-1\\scheduler.bin\n",
      "02/04/2024 11:13:00 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in result_distiling\\checkpoint-1000-epoch-1\\sampler.bin\n",
      "02/04/2024 11:13:00 - INFO - accelerate.checkpointing - Sampler state for dataloader 1 saved in result_distiling\\checkpoint-1000-epoch-1\\sampler_1.bin\n",
      "02/04/2024 11:13:00 - INFO - accelerate.checkpointing - Gradient scaler state saved in result_distiling\\checkpoint-1000-epoch-1\\scaler.pt\n",
      "02/04/2024 11:13:01 - INFO - accelerate.checkpointing - Random states saved in result_distiling\\checkpoint-1000-epoch-1\\random_states_0.pkl\n",
      "\n",
      "\n",
      "Evaluating eval...:   0%|                                                                       | 0/81 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   1%|▊                                                              | 1/81 [00:20<27:36, 20.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   2%|█▌                                                             | 2/81 [00:23<13:01,  9.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   4%|██▎                                                            | 3/81 [00:24<08:09,  6.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   5%|███                                                            | 4/81 [00:26<05:53,  4.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   6%|███▉                                                           | 5/81 [00:29<04:37,  3.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   7%|████▋                                                          | 6/81 [00:31<03:52,  3.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   9%|█████▍                                                         | 7/81 [00:33<03:23,  2.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  10%|██████▏                                                        | 8/81 [00:35<03:03,  2.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  11%|███████                                                        | 9/81 [00:37<02:49,  2.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  12%|███████▋                                                      | 10/81 [00:39<02:40,  2.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  14%|████████▍                                                     | 11/81 [00:41<02:32,  2.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  15%|█████████▏                                                    | 12/81 [00:43<02:27,  2.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  16%|█████████▉                                                    | 13/81 [00:45<02:22,  2.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  17%|██████████▋                                                   | 14/81 [00:47<02:19,  2.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  19%|███████████▍                                                  | 15/81 [00:49<02:17,  2.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  20%|████████████▏                                                 | 16/81 [00:51<02:13,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  21%|█████████████                                                 | 17/81 [00:53<02:10,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  22%|█████████████▊                                                | 18/81 [00:55<02:08,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  23%|██████████████▌                                               | 19/81 [00:57<02:06,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  25%|███████████████▎                                              | 20/81 [00:59<02:04,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  26%|████████████████                                              | 21/81 [01:01<02:02,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  27%|████████████████▊                                             | 22/81 [01:03<02:00,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  28%|█████████████████▌                                            | 23/81 [01:05<01:58,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  30%|██████████████████▎                                           | 24/81 [01:07<01:56,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  31%|███████████████████▏                                          | 25/81 [01:09<01:54,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  32%|███████████████████▉                                          | 26/81 [01:11<01:52,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  33%|████████████████████▋                                         | 27/81 [01:13<01:49,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  35%|█████████████████████▍                                        | 28/81 [01:15<01:47,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  36%|██████████████████████▏                                       | 29/81 [01:17<01:45,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  37%|██████████████████████▉                                       | 30/81 [01:19<01:43,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  38%|███████████████████████▋                                      | 31/81 [01:21<01:42,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  40%|████████████████████████▍                                     | 32/81 [01:23<01:39,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  41%|█████████████████████████▎                                    | 33/81 [01:25<01:37,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  42%|██████████████████████████                                    | 34/81 [01:27<01:35,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  43%|██████████████████████████▊                                   | 35/81 [01:30<01:35,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  44%|███████████████████████████▌                                  | 36/81 [01:32<01:31,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  46%|████████████████████████████▎                                 | 37/81 [01:34<01:29,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  47%|█████████████████████████████                                 | 38/81 [01:36<01:27,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  48%|█████████████████████████████▊                                | 39/81 [01:38<01:25,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  49%|██████████████████████████████▌                               | 40/81 [01:40<01:23,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  51%|███████████████████████████████▍                              | 41/81 [01:42<01:21,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  52%|████████████████████████████████▏                             | 42/81 [01:44<01:19,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  53%|████████████████████████████████▉                             | 43/81 [01:46<01:17,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  54%|█████████████████████████████████▋                            | 44/81 [01:48<01:15,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  56%|██████████████████████████████████▍                           | 45/81 [01:50<01:13,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  57%|███████████████████████████████████▏                          | 46/81 [01:52<01:11,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  58%|███████████████████████████████████▉                          | 47/81 [01:54<01:09,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  59%|████████████████████████████████████▋                         | 48/81 [01:56<01:07,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  60%|█████████████████████████████████████▌                        | 49/81 [01:58<01:05,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  62%|██████████████████████████████████████▎                       | 50/81 [02:00<01:03,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  63%|███████████████████████████████████████                       | 51/81 [02:02<01:01,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  64%|███████████████████████████████████████▊                      | 52/81 [02:04<00:59,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  65%|████████████████████████████████████████▌                     | 53/81 [02:06<00:57,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  67%|█████████████████████████████████████████▎                    | 54/81 [02:08<00:55,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  68%|██████████████████████████████████████████                    | 55/81 [02:11<00:53,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  69%|██████████████████████████████████████████▊                   | 56/81 [02:13<00:51,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  70%|███████████████████████████████████████████▋                  | 57/81 [02:15<00:49,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  72%|████████████████████████████████████████████▍                 | 58/81 [02:17<00:47,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  73%|█████████████████████████████████████████████▏                | 59/81 [02:19<00:46,  2.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  74%|█████████████████████████████████████████████▉                | 60/81 [02:21<00:42,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  75%|██████████████████████████████████████████████▋               | 61/81 [02:23<00:40,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  77%|███████████████████████████████████████████████▍              | 62/81 [02:25<00:38,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  78%|████████████████████████████████████████████████▏             | 63/81 [02:27<00:36,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  79%|████████████████████████████████████████████████▉             | 64/81 [02:29<00:34,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  80%|█████████████████████████████████████████████████▊            | 65/81 [02:31<00:32,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  81%|██████████████████████████████████████████████████▌           | 66/81 [02:33<00:30,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  83%|███████████████████████████████████████████████████▎          | 67/81 [02:35<00:28,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  84%|████████████████████████████████████████████████████          | 68/81 [02:37<00:26,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  85%|████████████████████████████████████████████████████▊         | 69/81 [02:39<00:24,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  86%|█████████████████████████████████████████████████████▌        | 70/81 [02:41<00:22,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  88%|██████████████████████████████████████████████████████▎       | 71/81 [02:43<00:20,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  89%|███████████████████████████████████████████████████████       | 72/81 [02:45<00:18,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  90%|███████████████████████████████████████████████████████▉      | 73/81 [02:47<00:16,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  91%|████████████████████████████████████████████████████████▋     | 74/81 [02:50<00:14,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  93%|█████████████████████████████████████████████████████████▍    | 75/81 [02:52<00:12,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  94%|██████████████████████████████████████████████████████████▏   | 76/81 [02:54<00:10,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  95%|██████████████████████████████████████████████████████████▉   | 77/81 [02:56<00:08,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  96%|███████████████████████████████████████████████████████████▋  | 78/81 [02:58<00:06,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  98%|████████████████████████████████████████████████████████████▍ | 79/81 [03:00<00:04,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  99%|█████████████████████████████████████████████████████████████▏| 80/81 [03:02<00:02,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...: 100%|██████████████████████████████████████████████████████████████| 81/81 [03:06<00:00,  2.30s/it]\u001b[A\u001b[A\n",
      "Train steps ... :  10%|█████▋                                                   | 1000/10000 [44:59<5:49:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval results for step (1000 / 10000 | Eval Loss: 18.555706024169922 | )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  10%|█████▊                                                   | 1025/10000 [45:57<5:52:16,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1025 / 10000 | Loss: 3.294250011444092, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  10%|█████▉                                                   | 1050/10000 [46:56<5:48:59,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1050 / 10000 | Loss: 3.667703151702881, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  11%|██████▏                                                  | 1075/10000 [47:54<5:48:13,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1075 / 10000 | Loss: 3.6837668418884277, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  11%|██████▎                                                  | 1100/10000 [48:53<5:47:50,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1100 / 10000 | Loss: 3.4214982986450195, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  11%|██████▍                                                  | 1125/10000 [49:52<5:46:23,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1125 / 10000 | Loss: 3.6799302101135254, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  12%|██████▌                                                  | 1150/10000 [50:50<5:46:11,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1150 / 10000 | Loss: 3.625852108001709, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  12%|██████▋                                                  | 1175/10000 [51:49<5:44:07,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1175 / 10000 | Loss: 3.134622097015381, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  12%|██████▊                                                  | 1200/10000 [52:47<5:43:19,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1200 / 10000 | Loss: 3.1182687282562256, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  12%|██████▉                                                  | 1225/10000 [53:46<5:42:48,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1225 / 10000 | Loss: 3.5096817016601562, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  12%|███████▏                                                 | 1250/10000 [54:44<5:41:11,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1250 / 10000 | Loss: 3.2685317993164062, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  13%|███████▎                                                 | 1275/10000 [55:43<5:40:35,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1275 / 10000 | Loss: 3.16740345954895, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  13%|███████▍                                                 | 1300/10000 [56:41<5:39:23,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1300 / 10000 | Loss: 3.351867198944092, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  13%|███████▌                                                 | 1325/10000 [57:40<5:38:31,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1325 / 10000 | Loss: 2.883328437805176, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  14%|███████▋                                                 | 1350/10000 [58:38<5:37:18,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1350 / 10000 | Loss: 3.1587815284729004, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  14%|███████▊                                                 | 1375/10000 [59:37<5:36:02,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1375 / 10000 | Loss: 2.8973097801208496, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  14%|███████▋                                               | 1400/10000 [1:00:36<5:35:02,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1400 / 10000 | Loss: 3.1235454082489014, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  14%|███████▊                                               | 1425/10000 [1:01:34<5:33:58,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1425 / 10000 | Loss: 3.006253480911255, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  14%|███████▉                                               | 1450/10000 [1:02:32<5:33:23,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1450 / 10000 | Loss: 2.823627471923828, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  15%|████████                                               | 1475/10000 [1:03:31<5:32:06,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1475 / 10000 | Loss: 2.8980860710144043, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  15%|████████▎                                              | 1500/10000 [1:04:29<5:31:16,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1500 / 10000 | Loss: 3.0283031463623047, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  15%|████████▍                                              | 1525/10000 [1:05:28<5:30:02,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1525 / 10000 | Loss: 2.868396520614624, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  16%|████████▌                                              | 1550/10000 [1:06:26<5:29:26,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1550 / 10000 | Loss: 2.915499210357666, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  16%|████████▋                                              | 1575/10000 [1:07:25<5:27:57,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1575 / 10000 | Loss: 2.943690776824951, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  16%|████████▊                                              | 1600/10000 [1:08:23<5:27:17,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1600 / 10000 | Loss: 2.930725574493408, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  16%|████████▉                                              | 1625/10000 [1:09:21<5:26:08,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1625 / 10000 | Loss: 2.886645793914795, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  16%|█████████                                              | 1650/10000 [1:10:20<5:25:28,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1650 / 10000 | Loss: 2.7525787353515625, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  17%|█████████▏                                             | 1675/10000 [1:11:18<5:24:21,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1675 / 10000 | Loss: 2.513803243637085, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  17%|█████████▎                                             | 1700/10000 [1:12:17<5:23:24,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1700 / 10000 | Loss: 2.7757949829101562, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  17%|█████████▍                                             | 1725/10000 [1:13:15<5:22:44,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1725 / 10000 | Loss: 2.5495078563690186, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  18%|█████████▋                                             | 1750/10000 [1:14:14<5:21:08,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1750 / 10000 | Loss: 2.93072772026062, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  18%|█████████▊                                             | 1775/10000 [1:15:12<5:19:55,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1775 / 10000 | Loss: 2.696345806121826, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  18%|█████████▉                                             | 1800/10000 [1:16:10<5:19:33,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1800 / 10000 | Loss: 2.7587647438049316, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  18%|██████████                                             | 1825/10000 [1:17:09<5:18:14,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1825 / 10000 | Loss: 2.648115634918213, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  18%|██████████▏                                            | 1850/10000 [1:18:07<5:16:59,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1850 / 10000 | Loss: 2.6981277465820312, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  19%|██████████▎                                            | 1875/10000 [1:19:06<5:16:40,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1875 / 10000 | Loss: 2.5675463676452637, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  19%|██████████▍                                            | 1900/10000 [1:20:04<5:15:07,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1900 / 10000 | Loss: 2.362399101257324, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  19%|██████████▌                                            | 1925/10000 [1:21:03<5:14:45,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1925 / 10000 | Loss: 2.578788995742798, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  20%|██████████▋                                            | 1950/10000 [1:22:01<5:13:41,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1950 / 10000 | Loss: 2.1877737045288086, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  20%|██████████▊                                            | 1975/10000 [1:23:58<5:10:58,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (1975 / 10000 | Loss: 2.466874599456787, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  20%|███████████                                            | 2000/10000 [1:24:56<5:11:05,  2.33s/it]02/04/2024 11:56:05 - INFO - accelerate.accelerator - Saving current state to ./result_distiling\\checkpoint-2000-epoch-2\n",
      "02/04/2024 11:56:05 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2000 / 10000 | Loss: 2.0437440872192383, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/04/2024 11:56:06 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-2000-epoch-2\\model.safetensors\n",
      "02/04/2024 11:56:06 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n",
      "02/04/2024 11:56:07 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-2000-epoch-2\\model_1.safetensors\n",
      "02/04/2024 11:56:08 - INFO - accelerate.checkpointing - Optimizer state saved in result_distiling\\checkpoint-2000-epoch-2\\optimizer.bin\n",
      "02/04/2024 11:56:08 - INFO - accelerate.checkpointing - Scheduler state saved in result_distiling\\checkpoint-2000-epoch-2\\scheduler.bin\n",
      "02/04/2024 11:56:08 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in result_distiling\\checkpoint-2000-epoch-2\\sampler.bin\n",
      "02/04/2024 11:56:08 - INFO - accelerate.checkpointing - Sampler state for dataloader 1 saved in result_distiling\\checkpoint-2000-epoch-2\\sampler_1.bin\n",
      "02/04/2024 11:56:08 - INFO - accelerate.checkpointing - Sampler state for dataloader 2 saved in result_distiling\\checkpoint-2000-epoch-2\\sampler_2.bin\n",
      "02/04/2024 11:56:08 - INFO - accelerate.checkpointing - Sampler state for dataloader 3 saved in result_distiling\\checkpoint-2000-epoch-2\\sampler_3.bin\n",
      "02/04/2024 11:56:08 - INFO - accelerate.checkpointing - Gradient scaler state saved in result_distiling\\checkpoint-2000-epoch-2\\scaler.pt\n",
      "02/04/2024 11:56:08 - INFO - accelerate.checkpointing - Random states saved in result_distiling\\checkpoint-2000-epoch-2\\random_states_0.pkl\n",
      "\n",
      "\n",
      "Evaluating eval...:   0%|                                                                       | 0/81 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   1%|▊                                                              | 1/81 [00:20<27:09, 20.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   2%|█▌                                                             | 2/81 [00:22<12:46,  9.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   4%|██▎                                                            | 3/81 [00:24<08:01,  6.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   5%|███                                                            | 4/81 [00:26<05:48,  4.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   6%|███▉                                                           | 5/81 [00:28<04:34,  3.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   7%|████▋                                                          | 6/81 [00:30<03:50,  3.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   9%|█████▍                                                         | 7/81 [00:32<03:21,  2.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  10%|██████▏                                                        | 8/81 [00:34<03:02,  2.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  11%|███████                                                        | 9/81 [00:36<02:49,  2.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  12%|███████▋                                                      | 10/81 [00:38<02:39,  2.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  14%|████████▍                                                     | 11/81 [00:40<02:32,  2.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  15%|█████████▏                                                    | 12/81 [00:42<02:27,  2.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  16%|█████████▉                                                    | 13/81 [00:44<02:22,  2.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  17%|██████████▋                                                   | 14/81 [00:46<02:19,  2.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  19%|███████████▍                                                  | 15/81 [00:48<02:16,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  20%|████████████▏                                                 | 16/81 [00:50<02:13,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  21%|█████████████                                                 | 17/81 [00:52<02:11,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  22%|█████████████▊                                                | 18/81 [00:54<02:08,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  23%|██████████████▌                                               | 19/81 [00:56<02:06,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  25%|███████████████▎                                              | 20/81 [00:58<02:04,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  26%|████████████████                                              | 21/81 [01:01<02:02,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  27%|████████████████▊                                             | 22/81 [01:03<02:00,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  28%|█████████████████▌                                            | 23/81 [01:05<01:58,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  30%|██████████████████▎                                           | 24/81 [01:07<01:56,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  31%|███████████████████▏                                          | 25/81 [01:09<01:54,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  32%|███████████████████▉                                          | 26/81 [01:11<01:52,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  33%|████████████████████▋                                         | 27/81 [01:13<01:50,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  35%|█████████████████████▍                                        | 28/81 [01:15<01:48,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  36%|██████████████████████▏                                       | 29/81 [01:17<01:46,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  37%|██████████████████████▉                                       | 30/81 [01:19<01:44,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  38%|███████████████████████▋                                      | 31/81 [01:21<01:42,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  40%|████████████████████████▍                                     | 32/81 [01:23<01:40,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  41%|█████████████████████████▎                                    | 33/81 [01:25<01:38,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  42%|██████████████████████████                                    | 34/81 [01:27<01:36,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  43%|██████████████████████████▊                                   | 35/81 [01:29<01:33,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  44%|███████████████████████████▌                                  | 36/81 [01:31<01:31,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  46%|████████████████████████████▎                                 | 37/81 [01:33<01:29,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  47%|█████████████████████████████                                 | 38/81 [01:35<01:27,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  48%|█████████████████████████████▊                                | 39/81 [01:37<01:25,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  49%|██████████████████████████████▌                               | 40/81 [01:39<01:23,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  51%|███████████████████████████████▍                              | 41/81 [01:41<01:21,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  52%|████████████████████████████████▏                             | 42/81 [01:43<01:19,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  53%|████████████████████████████████▉                             | 43/81 [01:45<01:17,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  54%|█████████████████████████████████▋                            | 44/81 [01:47<01:15,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  56%|██████████████████████████████████▍                           | 45/81 [01:50<01:13,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  57%|███████████████████████████████████▏                          | 46/81 [01:52<01:11,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  58%|███████████████████████████████████▉                          | 47/81 [01:54<01:09,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  59%|████████████████████████████████████▋                         | 48/81 [01:56<01:07,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  60%|█████████████████████████████████████▌                        | 49/81 [01:58<01:05,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  62%|██████████████████████████████████████▎                       | 50/81 [02:00<01:03,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  63%|███████████████████████████████████████                       | 51/81 [02:02<01:01,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  64%|███████████████████████████████████████▊                      | 52/81 [02:04<00:59,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  65%|████████████████████████████████████████▌                     | 53/81 [02:06<00:57,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  67%|█████████████████████████████████████████▎                    | 54/81 [02:08<00:55,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  68%|██████████████████████████████████████████                    | 55/81 [02:10<00:53,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  69%|██████████████████████████████████████████▊                   | 56/81 [02:12<00:51,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  70%|███████████████████████████████████████████▋                  | 57/81 [02:14<00:49,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  72%|████████████████████████████████████████████▍                 | 58/81 [02:16<00:47,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  73%|█████████████████████████████████████████████▏                | 59/81 [02:18<00:45,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  74%|█████████████████████████████████████████████▉                | 60/81 [02:20<00:42,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  75%|██████████████████████████████████████████████▋               | 61/81 [02:22<00:40,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  77%|███████████████████████████████████████████████▍              | 62/81 [02:24<00:38,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  78%|████████████████████████████████████████████████▏             | 63/81 [02:26<00:37,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  79%|████████████████████████████████████████████████▉             | 64/81 [02:28<00:34,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  80%|█████████████████████████████████████████████████▊            | 65/81 [02:31<00:32,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  81%|██████████████████████████████████████████████████▌           | 66/81 [02:33<00:30,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  83%|███████████████████████████████████████████████████▎          | 67/81 [02:35<00:28,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  84%|████████████████████████████████████████████████████          | 68/81 [02:37<00:26,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  85%|████████████████████████████████████████████████████▊         | 69/81 [02:39<00:24,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  86%|█████████████████████████████████████████████████████▌        | 70/81 [02:41<00:22,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  88%|██████████████████████████████████████████████████████▎       | 71/81 [02:43<00:20,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  89%|███████████████████████████████████████████████████████       | 72/81 [02:45<00:18,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  90%|███████████████████████████████████████████████████████▉      | 73/81 [02:47<00:16,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  91%|████████████████████████████████████████████████████████▋     | 74/81 [02:49<00:14,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  93%|█████████████████████████████████████████████████████████▍    | 75/81 [02:51<00:12,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  94%|██████████████████████████████████████████████████████████▏   | 76/81 [02:53<00:10,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  95%|██████████████████████████████████████████████████████████▉   | 77/81 [02:55<00:08,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  96%|███████████████████████████████████████████████████████████▋  | 78/81 [02:57<00:06,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  98%|████████████████████████████████████████████████████████████▍ | 79/81 [02:59<00:04,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  99%|█████████████████████████████████████████████████████████████▏| 80/81 [03:01<00:02,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...: 100%|██████████████████████████████████████████████████████████████| 81/81 [03:04<00:00,  2.28s/it]\u001b[A\u001b[A\n",
      "Train steps ... :  20%|███████████                                            | 2000/10000 [1:28:05<5:11:05,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval results for step (2000 / 10000 | Eval Loss: 18.937530517578125 | )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  20%|███████████▏                                           | 2025/10000 [1:29:04<5:12:13,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2025 / 10000 | Loss: 2.531928300857544, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  20%|███████████▎                                           | 2050/10000 [1:30:02<5:09:48,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2050 / 10000 | Loss: 1.8767412900924683, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  21%|███████████▍                                           | 2075/10000 [1:31:01<5:09:02,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2075 / 10000 | Loss: 2.283881187438965, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  21%|███████████▌                                           | 2100/10000 [1:31:59<5:07:57,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2100 / 10000 | Loss: 2.4022510051727295, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  21%|███████████▋                                           | 2125/10000 [1:32:57<5:06:49,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2125 / 10000 | Loss: 2.0552117824554443, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  22%|███████████▊                                           | 2150/10000 [1:33:56<5:05:53,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2150 / 10000 | Loss: 2.2520503997802734, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  22%|███████████▉                                           | 2175/10000 [1:34:54<5:04:47,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2175 / 10000 | Loss: 2.078822135925293, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  22%|████████████                                           | 2200/10000 [1:35:53<5:04:07,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2200 / 10000 | Loss: 2.004117012023926, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  22%|████████████▏                                          | 2225/10000 [1:36:51<5:02:54,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2225 / 10000 | Loss: 2.080848217010498, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  22%|████████████▍                                          | 2250/10000 [1:37:50<5:02:20,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2250 / 10000 | Loss: 1.9787659645080566, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  23%|████████████▌                                          | 2275/10000 [1:38:48<5:01:12,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2275 / 10000 | Loss: 2.0328547954559326, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  23%|████████████▋                                          | 2300/10000 [1:39:47<4:59:57,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2300 / 10000 | Loss: 1.830470323562622, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  23%|████████████▊                                          | 2325/10000 [1:40:45<4:59:25,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2325 / 10000 | Loss: 2.0538504123687744, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  24%|████████████▉                                          | 2350/10000 [1:41:44<4:58:16,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2350 / 10000 | Loss: 2.166574478149414, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  24%|█████████████                                          | 2375/10000 [1:42:42<4:57:13,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2375 / 10000 | Loss: 2.004638433456421, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  24%|█████████████▏                                         | 2400/10000 [1:43:41<4:56:17,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2400 / 10000 | Loss: 1.9034866094589233, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  24%|█████████████▎                                         | 2425/10000 [1:44:39<4:55:08,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2425 / 10000 | Loss: 1.9080796241760254, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  24%|█████████████▍                                         | 2450/10000 [1:45:37<4:54:27,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2450 / 10000 | Loss: 2.3489725589752197, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  25%|█████████████▌                                         | 2475/10000 [1:46:36<4:53:24,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2475 / 10000 | Loss: 2.0371553897857666, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  25%|█████████████▊                                         | 2500/10000 [1:47:34<4:51:46,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2500 / 10000 | Loss: 1.9481201171875, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  25%|█████████████▉                                         | 2525/10000 [1:48:33<4:51:33,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2525 / 10000 | Loss: 2.051893472671509, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  26%|██████████████                                         | 2550/10000 [1:49:31<4:50:20,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2550 / 10000 | Loss: 1.9779046773910522, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  26%|██████████████▏                                        | 2575/10000 [1:50:30<4:49:36,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2575 / 10000 | Loss: 1.992156982421875, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  26%|██████████████▎                                        | 2600/10000 [1:51:28<4:48:37,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2600 / 10000 | Loss: 2.0301976203918457, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  26%|██████████████▍                                        | 2625/10000 [1:52:27<4:47:37,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2625 / 10000 | Loss: 1.6297495365142822, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  26%|██████████████▌                                        | 2650/10000 [1:53:25<4:46:51,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2650 / 10000 | Loss: 1.6265285015106201, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  27%|██████████████▋                                        | 2675/10000 [1:54:24<4:45:37,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2675 / 10000 | Loss: 1.8873249292373657, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  27%|██████████████▊                                        | 2700/10000 [1:55:22<4:44:17,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2700 / 10000 | Loss: 1.721360445022583, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  27%|██████████████▉                                        | 2725/10000 [1:56:21<4:43:36,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2725 / 10000 | Loss: 1.6922671794891357, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  28%|███████████████▏                                       | 2750/10000 [1:57:19<4:42:55,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2750 / 10000 | Loss: 2.0333781242370605, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  28%|███████████████▎                                       | 2775/10000 [1:58:18<4:42:26,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2775 / 10000 | Loss: 1.717712640762329, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  28%|███████████████▍                                       | 2800/10000 [1:59:16<4:40:45,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2800 / 10000 | Loss: 1.773076057434082, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  28%|███████████████▌                                       | 2825/10000 [2:00:15<4:39:59,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2825 / 10000 | Loss: 1.6073188781738281, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  28%|███████████████▋                                       | 2850/10000 [2:01:13<4:38:43,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2850 / 10000 | Loss: 1.7285892963409424, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  29%|███████████████▊                                       | 2875/10000 [2:02:12<4:37:51,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2875 / 10000 | Loss: 1.8682483434677124, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  29%|███████████████▉                                       | 2900/10000 [2:03:10<4:37:03,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2900 / 10000 | Loss: 1.6950620412826538, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  29%|████████████████                                       | 2925/10000 [2:04:09<4:36:19,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2925 / 10000 | Loss: 1.7911977767944336, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  30%|████████████████▏                                      | 2950/10000 [2:06:18<4:32:31,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2950 / 10000 | Loss: 1.5979396104812622, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  30%|████████████████▎                                      | 2975/10000 [2:07:16<4:32:43,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (2975 / 10000 | Loss: 1.5366109609603882, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  30%|████████████████▌                                      | 3000/10000 [2:08:14<4:32:13,  2.33s/it]02/04/2024 12:39:23 - INFO - accelerate.accelerator - Saving current state to ./result_distiling\\checkpoint-3000-epoch-3\n",
      "02/04/2024 12:39:23 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3000 / 10000 | Loss: 1.591282844543457, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/04/2024 12:39:24 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-3000-epoch-3\\model.safetensors\n",
      "02/04/2024 12:39:24 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n",
      "02/04/2024 12:39:25 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-3000-epoch-3\\model_1.safetensors\n",
      "02/04/2024 12:39:25 - INFO - accelerate.checkpointing - Optimizer state saved in result_distiling\\checkpoint-3000-epoch-3\\optimizer.bin\n",
      "02/04/2024 12:39:25 - INFO - accelerate.checkpointing - Scheduler state saved in result_distiling\\checkpoint-3000-epoch-3\\scheduler.bin\n",
      "02/04/2024 12:39:25 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in result_distiling\\checkpoint-3000-epoch-3\\sampler.bin\n",
      "02/04/2024 12:39:25 - INFO - accelerate.checkpointing - Sampler state for dataloader 1 saved in result_distiling\\checkpoint-3000-epoch-3\\sampler_1.bin\n",
      "02/04/2024 12:39:25 - INFO - accelerate.checkpointing - Sampler state for dataloader 2 saved in result_distiling\\checkpoint-3000-epoch-3\\sampler_2.bin\n",
      "02/04/2024 12:39:25 - INFO - accelerate.checkpointing - Sampler state for dataloader 3 saved in result_distiling\\checkpoint-3000-epoch-3\\sampler_3.bin\n",
      "02/04/2024 12:39:25 - INFO - accelerate.checkpointing - Sampler state for dataloader 4 saved in result_distiling\\checkpoint-3000-epoch-3\\sampler_4.bin\n",
      "02/04/2024 12:39:26 - INFO - accelerate.checkpointing - Sampler state for dataloader 5 saved in result_distiling\\checkpoint-3000-epoch-3\\sampler_5.bin\n",
      "02/04/2024 12:39:26 - INFO - accelerate.checkpointing - Gradient scaler state saved in result_distiling\\checkpoint-3000-epoch-3\\scaler.pt\n",
      "02/04/2024 12:39:26 - INFO - accelerate.checkpointing - Random states saved in result_distiling\\checkpoint-3000-epoch-3\\random_states_0.pkl\n",
      "\n",
      "\n",
      "Evaluating eval...:   0%|                                                                       | 0/81 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   1%|▊                                                              | 1/81 [00:20<27:31, 20.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   2%|█▌                                                             | 2/81 [00:22<12:56,  9.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   4%|██▎                                                            | 3/81 [00:24<08:07,  6.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   5%|███                                                            | 4/81 [00:26<05:52,  4.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   6%|███▉                                                           | 5/81 [00:28<04:37,  3.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   7%|████▋                                                          | 6/81 [00:30<03:51,  3.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   9%|█████▍                                                         | 7/81 [00:32<03:22,  2.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  10%|██████▏                                                        | 8/81 [00:34<03:03,  2.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  11%|███████                                                        | 9/81 [00:36<02:49,  2.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  12%|███████▋                                                      | 10/81 [00:38<02:40,  2.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  14%|████████▍                                                     | 11/81 [00:41<02:32,  2.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  15%|█████████▏                                                    | 12/81 [00:43<02:27,  2.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  16%|█████████▉                                                    | 13/81 [00:45<02:23,  2.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  17%|██████████▋                                                   | 14/81 [00:47<02:19,  2.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  19%|███████████▍                                                  | 15/81 [00:49<02:16,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  20%|████████████▏                                                 | 16/81 [00:51<02:13,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  21%|█████████████                                                 | 17/81 [00:53<02:11,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  22%|█████████████▊                                                | 18/81 [00:55<02:08,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  23%|██████████████▌                                               | 19/81 [00:57<02:06,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  25%|███████████████▎                                              | 20/81 [00:59<02:04,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  26%|████████████████                                              | 21/81 [01:01<02:02,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  27%|████████████████▊                                             | 22/81 [01:03<02:00,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  28%|█████████████████▌                                            | 23/81 [01:05<01:58,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  30%|██████████████████▎                                           | 24/81 [01:07<01:56,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  31%|███████████████████▏                                          | 25/81 [01:09<01:54,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  32%|███████████████████▉                                          | 26/81 [01:11<01:52,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  33%|████████████████████▋                                         | 27/81 [01:13<01:50,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  35%|█████████████████████▍                                        | 28/81 [01:15<01:48,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  36%|██████████████████████▏                                       | 29/81 [01:17<01:46,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  37%|██████████████████████▉                                       | 30/81 [01:19<01:44,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  38%|███████████████████████▋                                      | 31/81 [01:21<01:42,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  40%|████████████████████████▍                                     | 32/81 [01:23<01:40,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  41%|█████████████████████████▎                                    | 33/81 [01:25<01:38,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  42%|██████████████████████████                                    | 34/81 [01:27<01:35,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  43%|██████████████████████████▊                                   | 35/81 [01:29<01:33,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  44%|███████████████████████████▌                                  | 36/81 [01:32<01:31,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  46%|████████████████████████████▎                                 | 37/81 [01:34<01:30,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  47%|█████████████████████████████                                 | 38/81 [01:36<01:28,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  48%|█████████████████████████████▊                                | 39/81 [01:38<01:25,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  49%|██████████████████████████████▌                               | 40/81 [01:40<01:23,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  51%|███████████████████████████████▍                              | 41/81 [01:42<01:22,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  52%|████████████████████████████████▏                             | 42/81 [01:44<01:19,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  53%|████████████████████████████████▉                             | 43/81 [01:46<01:17,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  54%|█████████████████████████████████▋                            | 44/81 [01:48<01:15,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  56%|██████████████████████████████████▍                           | 45/81 [01:50<01:13,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  57%|███████████████████████████████████▏                          | 46/81 [01:52<01:11,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  58%|███████████████████████████████████▉                          | 47/81 [01:54<01:09,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  59%|████████████████████████████████████▋                         | 48/81 [01:56<01:07,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  60%|█████████████████████████████████████▌                        | 49/81 [01:58<01:05,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  62%|██████████████████████████████████████▎                       | 50/81 [02:00<01:03,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  63%|███████████████████████████████████████                       | 51/81 [02:02<01:01,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  64%|███████████████████████████████████████▊                      | 52/81 [02:04<00:59,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  65%|████████████████████████████████████████▌                     | 53/81 [02:06<00:57,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  67%|█████████████████████████████████████████▎                    | 54/81 [02:08<00:55,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  68%|██████████████████████████████████████████                    | 55/81 [02:10<00:53,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  69%|██████████████████████████████████████████▊                   | 56/81 [02:13<00:51,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  70%|███████████████████████████████████████████▋                  | 57/81 [02:15<00:49,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  72%|████████████████████████████████████████████▍                 | 58/81 [02:17<00:47,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  73%|█████████████████████████████████████████████▏                | 59/81 [02:19<00:45,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  74%|█████████████████████████████████████████████▉                | 60/81 [02:21<00:42,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  75%|██████████████████████████████████████████████▋               | 61/81 [02:23<00:40,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  77%|███████████████████████████████████████████████▍              | 62/81 [02:25<00:38,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  78%|████████████████████████████████████████████████▏             | 63/81 [02:27<00:36,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  79%|████████████████████████████████████████████████▉             | 64/81 [02:29<00:34,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  80%|█████████████████████████████████████████████████▊            | 65/81 [02:31<00:32,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  81%|██████████████████████████████████████████████████▌           | 66/81 [02:33<00:30,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  83%|███████████████████████████████████████████████████▎          | 67/81 [02:35<00:28,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  84%|████████████████████████████████████████████████████          | 68/81 [02:37<00:26,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  85%|████████████████████████████████████████████████████▊         | 69/81 [02:39<00:24,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  86%|█████████████████████████████████████████████████████▌        | 70/81 [02:41<00:22,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  88%|██████████████████████████████████████████████████████▎       | 71/81 [02:43<00:20,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  89%|███████████████████████████████████████████████████████       | 72/81 [02:45<00:18,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  90%|███████████████████████████████████████████████████████▉      | 73/81 [02:47<00:16,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  91%|████████████████████████████████████████████████████████▋     | 74/81 [02:49<00:14,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  93%|█████████████████████████████████████████████████████████▍    | 75/81 [02:51<00:12,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  94%|██████████████████████████████████████████████████████████▏   | 76/81 [02:54<00:10,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  95%|██████████████████████████████████████████████████████████▉   | 77/81 [02:56<00:08,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  96%|███████████████████████████████████████████████████████████▋  | 78/81 [02:58<00:06,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  98%|████████████████████████████████████████████████████████████▍ | 79/81 [03:00<00:04,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  99%|█████████████████████████████████████████████████████████████▏| 80/81 [03:02<00:02,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...: 100%|██████████████████████████████████████████████████████████████| 81/81 [03:05<00:00,  2.28s/it]\u001b[A\u001b[A\n",
      "Train steps ... :  30%|████████████████▌                                      | 3000/10000 [2:11:23<4:32:13,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval results for step (3000 / 10000 | Eval Loss: 18.145727157592773 | )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  30%|████████████████▋                                      | 3025/10000 [2:12:22<4:33:11,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3025 / 10000 | Loss: 1.5717829465866089, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  30%|████████████████▊                                      | 3050/10000 [2:13:20<4:31:11,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3050 / 10000 | Loss: 1.6522600650787354, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  31%|████████████████▉                                      | 3075/10000 [2:14:19<4:29:56,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3075 / 10000 | Loss: 1.467746376991272, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  31%|█████████████████                                      | 3100/10000 [2:15:17<4:28:47,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3100 / 10000 | Loss: 1.5153450965881348, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  31%|█████████████████▏                                     | 3125/10000 [2:16:16<4:27:59,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3125 / 10000 | Loss: 1.5713030099868774, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  32%|█████████████████▎                                     | 3150/10000 [2:17:14<4:27:07,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3150 / 10000 | Loss: 1.554121971130371, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  32%|█████████████████▍                                     | 3175/10000 [2:18:12<4:26:19,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3175 / 10000 | Loss: 1.4046543836593628, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  32%|█████████████████▌                                     | 3200/10000 [2:19:11<4:25:14,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3200 / 10000 | Loss: 1.6961743831634521, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  32%|█████████████████▋                                     | 3225/10000 [2:20:09<4:24:20,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3225 / 10000 | Loss: 1.362473726272583, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  32%|█████████████████▉                                     | 3250/10000 [2:21:08<4:23:19,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3250 / 10000 | Loss: 1.643411636352539, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  33%|██████████████████                                     | 3275/10000 [2:22:07<4:22:14,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3275 / 10000 | Loss: 1.6296498775482178, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  33%|██████████████████▏                                    | 3300/10000 [2:23:05<4:21:14,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3300 / 10000 | Loss: 1.4845302104949951, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  33%|██████████████████▎                                    | 3325/10000 [2:24:04<4:20:09,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3325 / 10000 | Loss: 1.6819477081298828, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  34%|██████████████████▍                                    | 3350/10000 [2:25:02<4:18:22,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3350 / 10000 | Loss: 1.445961594581604, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  34%|██████████████████▌                                    | 3375/10000 [2:26:00<4:18:21,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3375 / 10000 | Loss: 1.445390224456787, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  34%|██████████████████▋                                    | 3400/10000 [2:26:59<4:17:10,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3400 / 10000 | Loss: 1.4814656972885132, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  34%|██████████████████▊                                    | 3425/10000 [2:27:57<4:15:33,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3425 / 10000 | Loss: 1.7464148998260498, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  34%|██████████████████▉                                    | 3450/10000 [2:28:56<4:15:06,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3450 / 10000 | Loss: 1.3376001119613647, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  35%|███████████████████                                    | 3475/10000 [2:29:54<4:14:30,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3475 / 10000 | Loss: 1.5825178623199463, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  35%|███████████████████▎                                   | 3500/10000 [2:30:52<4:13:16,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3500 / 10000 | Loss: 1.3745476007461548, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  35%|███████████████████▍                                   | 3525/10000 [2:31:51<4:12:20,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3525 / 10000 | Loss: 1.6022504568099976, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  36%|███████████████████▌                                   | 3550/10000 [2:32:49<4:11:17,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3550 / 10000 | Loss: 1.3896799087524414, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  36%|███████████████████▋                                   | 3575/10000 [2:33:48<4:10:30,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3575 / 10000 | Loss: 1.4868484735488892, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  36%|███████████████████▊                                   | 3600/10000 [2:34:46<4:09:19,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3600 / 10000 | Loss: 1.4761030673980713, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  36%|███████████████████▉                                   | 3625/10000 [2:35:45<4:08:24,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3625 / 10000 | Loss: 1.354827642440796, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  36%|████████████████████                                   | 3650/10000 [2:36:43<4:07:34,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3650 / 10000 | Loss: 1.4458155632019043, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  37%|████████████████████▏                                  | 3675/10000 [2:37:42<4:06:28,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3675 / 10000 | Loss: 1.343109130859375, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  37%|████████████████████▎                                  | 3700/10000 [2:38:40<4:05:41,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3700 / 10000 | Loss: 1.4337570667266846, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  37%|████████████████████▍                                  | 3725/10000 [2:39:39<4:04:37,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3725 / 10000 | Loss: 1.5027556419372559, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  38%|████████████████████▋                                  | 3750/10000 [2:40:37<4:03:28,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3750 / 10000 | Loss: 1.3225823640823364, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  38%|████████████████████▊                                  | 3775/10000 [2:41:36<4:02:35,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3775 / 10000 | Loss: 1.4059064388275146, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  38%|████████████████████▉                                  | 3800/10000 [2:42:34<4:01:38,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3800 / 10000 | Loss: 1.3820103406906128, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  38%|█████████████████████                                  | 3825/10000 [2:43:32<4:00:46,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3825 / 10000 | Loss: 1.481337070465088, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  38%|█████████████████████▏                                 | 3850/10000 [2:44:31<3:59:41,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3850 / 10000 | Loss: 1.2385764122009277, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  39%|█████████████████████▎                                 | 3875/10000 [2:45:29<3:58:39,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3875 / 10000 | Loss: 1.2548154592514038, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  39%|█████████████████████▍                                 | 3900/10000 [2:46:28<3:57:53,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3900 / 10000 | Loss: 1.3585245609283447, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  39%|█████████████████████▌                                 | 3925/10000 [2:48:34<3:55:30,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3925 / 10000 | Loss: 1.3085724115371704, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  40%|█████████████████████▋                                 | 3950/10000 [2:49:33<3:55:31,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3950 / 10000 | Loss: 1.206078052520752, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  40%|█████████████████████▊                                 | 3975/10000 [2:50:31<3:54:44,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (3975 / 10000 | Loss: 1.2291674613952637, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  40%|██████████████████████                                 | 4000/10000 [2:51:29<3:53:28,  2.33s/it]02/04/2024 13:22:38 - INFO - accelerate.accelerator - Saving current state to ./result_distiling\\checkpoint-4000-epoch-4\n",
      "02/04/2024 13:22:38 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4000 / 10000 | Loss: 1.1014372110366821, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/04/2024 13:22:39 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-4000-epoch-4\\model.safetensors\n",
      "02/04/2024 13:22:39 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n",
      "02/04/2024 13:22:40 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-4000-epoch-4\\model_1.safetensors\n",
      "02/04/2024 13:22:41 - INFO - accelerate.checkpointing - Optimizer state saved in result_distiling\\checkpoint-4000-epoch-4\\optimizer.bin\n",
      "02/04/2024 13:22:41 - INFO - accelerate.checkpointing - Scheduler state saved in result_distiling\\checkpoint-4000-epoch-4\\scheduler.bin\n",
      "02/04/2024 13:22:41 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in result_distiling\\checkpoint-4000-epoch-4\\sampler.bin\n",
      "02/04/2024 13:22:41 - INFO - accelerate.checkpointing - Sampler state for dataloader 1 saved in result_distiling\\checkpoint-4000-epoch-4\\sampler_1.bin\n",
      "02/04/2024 13:22:41 - INFO - accelerate.checkpointing - Sampler state for dataloader 2 saved in result_distiling\\checkpoint-4000-epoch-4\\sampler_2.bin\n",
      "02/04/2024 13:22:41 - INFO - accelerate.checkpointing - Sampler state for dataloader 3 saved in result_distiling\\checkpoint-4000-epoch-4\\sampler_3.bin\n",
      "02/04/2024 13:22:41 - INFO - accelerate.checkpointing - Sampler state for dataloader 4 saved in result_distiling\\checkpoint-4000-epoch-4\\sampler_4.bin\n",
      "02/04/2024 13:22:41 - INFO - accelerate.checkpointing - Sampler state for dataloader 5 saved in result_distiling\\checkpoint-4000-epoch-4\\sampler_5.bin\n",
      "02/04/2024 13:22:41 - INFO - accelerate.checkpointing - Sampler state for dataloader 6 saved in result_distiling\\checkpoint-4000-epoch-4\\sampler_6.bin\n",
      "02/04/2024 13:22:41 - INFO - accelerate.checkpointing - Sampler state for dataloader 7 saved in result_distiling\\checkpoint-4000-epoch-4\\sampler_7.bin\n",
      "02/04/2024 13:22:41 - INFO - accelerate.checkpointing - Gradient scaler state saved in result_distiling\\checkpoint-4000-epoch-4\\scaler.pt\n",
      "02/04/2024 13:22:41 - INFO - accelerate.checkpointing - Random states saved in result_distiling\\checkpoint-4000-epoch-4\\random_states_0.pkl\n",
      "02/04/2024 13:22:41 - INFO - run_distillation - Deleting older checkpoint [result_distiling\\checkpoint-1000-epoch-1] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Evaluating eval...:   0%|                                                                       | 0/81 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   1%|▊                                                              | 1/81 [00:20<27:19, 20.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   2%|█▌                                                             | 2/81 [00:22<12:52,  9.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   4%|██▎                                                            | 3/81 [00:24<08:05,  6.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   5%|███                                                            | 4/81 [00:26<05:51,  4.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   6%|███▉                                                           | 5/81 [00:28<04:36,  3.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   7%|████▋                                                          | 6/81 [00:30<03:51,  3.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   9%|█████▍                                                         | 7/81 [00:32<03:22,  2.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  10%|██████▏                                                        | 8/81 [00:34<03:03,  2.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  11%|███████                                                        | 9/81 [00:36<02:49,  2.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  12%|███████▋                                                      | 10/81 [00:38<02:39,  2.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  14%|████████▍                                                     | 11/81 [00:40<02:32,  2.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  15%|█████████▏                                                    | 12/81 [00:42<02:27,  2.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  16%|█████████▉                                                    | 13/81 [00:44<02:23,  2.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  17%|██████████▋                                                   | 14/81 [00:46<02:19,  2.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  19%|███████████▍                                                  | 15/81 [00:49<02:16,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  20%|████████████▏                                                 | 16/81 [00:51<02:13,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  21%|█████████████                                                 | 17/81 [00:53<02:11,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  22%|█████████████▊                                                | 18/81 [00:55<02:09,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  23%|██████████████▌                                               | 19/81 [00:57<02:06,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  25%|███████████████▎                                              | 20/81 [00:59<02:04,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  26%|████████████████                                              | 21/81 [01:01<02:02,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  27%|████████████████▊                                             | 22/81 [01:03<02:00,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  28%|█████████████████▌                                            | 23/81 [01:05<01:58,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  30%|██████████████████▎                                           | 24/81 [01:07<01:56,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  31%|███████████████████▏                                          | 25/81 [01:09<01:54,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  32%|███████████████████▉                                          | 26/81 [01:11<01:52,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  33%|████████████████████▋                                         | 27/81 [01:13<01:50,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  35%|█████████████████████▍                                        | 28/81 [01:15<01:48,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  36%|██████████████████████▏                                       | 29/81 [01:17<01:46,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  37%|██████████████████████▉                                       | 30/81 [01:19<01:44,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  38%|███████████████████████▋                                      | 31/81 [01:21<01:42,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  40%|████████████████████████▍                                     | 32/81 [01:23<01:40,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  41%|█████████████████████████▎                                    | 33/81 [01:25<01:38,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  42%|██████████████████████████                                    | 34/81 [01:27<01:36,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  43%|██████████████████████████▊                                   | 35/81 [01:29<01:33,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  44%|███████████████████████████▌                                  | 36/81 [01:31<01:31,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  46%|████████████████████████████▎                                 | 37/81 [01:33<01:29,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  47%|█████████████████████████████                                 | 38/81 [01:35<01:27,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  48%|█████████████████████████████▊                                | 39/81 [01:38<01:25,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  49%|██████████████████████████████▌                               | 40/81 [01:40<01:23,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  51%|███████████████████████████████▍                              | 41/81 [01:42<01:21,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  52%|████████████████████████████████▏                             | 42/81 [01:44<01:19,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  53%|████████████████████████████████▉                             | 43/81 [01:46<01:17,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  54%|█████████████████████████████████▋                            | 44/81 [01:48<01:15,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  56%|██████████████████████████████████▍                           | 45/81 [01:50<01:13,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  57%|███████████████████████████████████▏                          | 46/81 [01:52<01:11,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  58%|███████████████████████████████████▉                          | 47/81 [01:54<01:09,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  59%|████████████████████████████████████▋                         | 48/81 [01:56<01:07,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  60%|█████████████████████████████████████▌                        | 49/81 [01:58<01:05,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  62%|██████████████████████████████████████▎                       | 50/81 [02:00<01:03,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  63%|███████████████████████████████████████                       | 51/81 [02:02<01:01,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  64%|███████████████████████████████████████▊                      | 52/81 [02:04<00:59,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  65%|████████████████████████████████████████▌                     | 53/81 [02:06<00:57,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  67%|█████████████████████████████████████████▎                    | 54/81 [02:08<00:55,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  68%|██████████████████████████████████████████                    | 55/81 [02:10<00:53,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  69%|██████████████████████████████████████████▊                   | 56/81 [02:12<00:51,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  70%|███████████████████████████████████████████▋                  | 57/81 [02:14<00:49,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  72%|████████████████████████████████████████████▍                 | 58/81 [02:16<00:47,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  73%|█████████████████████████████████████████████▏                | 59/81 [02:19<00:45,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  74%|█████████████████████████████████████████████▉                | 60/81 [02:21<00:43,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  75%|██████████████████████████████████████████████▋               | 61/81 [02:23<00:41,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  77%|███████████████████████████████████████████████▍              | 62/81 [02:25<00:38,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  78%|████████████████████████████████████████████████▏             | 63/81 [02:27<00:36,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  79%|████████████████████████████████████████████████▉             | 64/81 [02:29<00:34,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  80%|█████████████████████████████████████████████████▊            | 65/81 [02:31<00:32,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  81%|██████████████████████████████████████████████████▌           | 66/81 [02:33<00:30,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  83%|███████████████████████████████████████████████████▎          | 67/81 [02:35<00:28,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  84%|████████████████████████████████████████████████████          | 68/81 [02:37<00:26,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  85%|████████████████████████████████████████████████████▊         | 69/81 [02:39<00:24,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  86%|█████████████████████████████████████████████████████▌        | 70/81 [02:41<00:22,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  88%|██████████████████████████████████████████████████████▎       | 71/81 [02:43<00:20,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  89%|███████████████████████████████████████████████████████       | 72/81 [02:45<00:18,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  90%|███████████████████████████████████████████████████████▉      | 73/81 [02:47<00:16,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  91%|████████████████████████████████████████████████████████▋     | 74/81 [02:49<00:14,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  93%|█████████████████████████████████████████████████████████▍    | 75/81 [02:51<00:12,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  94%|██████████████████████████████████████████████████████████▏   | 76/81 [02:53<00:10,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  95%|██████████████████████████████████████████████████████████▉   | 77/81 [02:55<00:08,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  96%|███████████████████████████████████████████████████████████▋  | 78/81 [02:57<00:06,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  98%|████████████████████████████████████████████████████████████▍ | 79/81 [03:00<00:04,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  99%|█████████████████████████████████████████████████████████████▏| 80/81 [03:02<00:02,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...: 100%|██████████████████████████████████████████████████████████████| 81/81 [03:04<00:00,  2.28s/it]\u001b[A\u001b[A\n",
      "Train steps ... :  40%|██████████████████████                                 | 4000/10000 [2:54:39<3:53:28,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval results for step (4000 / 10000 | Eval Loss: 18.078861236572266 | )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  40%|██████████████████████▏                                | 4025/10000 [2:55:37<3:54:10,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4025 / 10000 | Loss: 1.5154392719268799, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  40%|██████████████████████▎                                | 4050/10000 [2:56:36<3:51:52,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4050 / 10000 | Loss: 1.163419485092163, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  41%|██████████████████████▍                                | 4075/10000 [2:57:34<3:51:05,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4075 / 10000 | Loss: 1.2792352437973022, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  41%|██████████████████████▌                                | 4100/10000 [2:58:33<3:50:08,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4100 / 10000 | Loss: 1.3022990226745605, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  41%|██████████████████████▋                                | 4125/10000 [2:59:31<3:49:15,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4125 / 10000 | Loss: 1.4988603591918945, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  42%|██████████████████████▊                                | 4150/10000 [3:00:30<3:47:56,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4150 / 10000 | Loss: 1.3195726871490479, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  42%|██████████████████████▉                                | 4175/10000 [3:01:28<3:47:03,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4175 / 10000 | Loss: 1.2769482135772705, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  42%|███████████████████████                                | 4200/10000 [3:02:27<3:46:21,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4200 / 10000 | Loss: 1.1603325605392456, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  42%|███████████████████████▏                               | 4225/10000 [3:03:25<3:45:15,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4225 / 10000 | Loss: 1.3437402248382568, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  42%|███████████████████████▍                               | 4250/10000 [3:04:24<3:44:14,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4250 / 10000 | Loss: 1.1998902559280396, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  43%|███████████████████████▌                               | 4275/10000 [3:05:22<3:42:58,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4275 / 10000 | Loss: 1.272995948791504, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  43%|███████████████████████▋                               | 4300/10000 [3:06:21<3:42:11,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4300 / 10000 | Loss: 1.291999101638794, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  43%|███████████████████████▊                               | 4325/10000 [3:07:19<3:41:18,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4325 / 10000 | Loss: 1.1018460988998413, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  44%|███████████████████████▉                               | 4350/10000 [3:08:18<3:39:54,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4350 / 10000 | Loss: 1.101961374282837, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  44%|████████████████████████                               | 4375/10000 [3:09:16<3:39:35,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4375 / 10000 | Loss: 1.1413848400115967, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  44%|████████████████████████▏                              | 4400/10000 [3:10:15<3:37:54,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4400 / 10000 | Loss: 1.1946669816970825, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  44%|████████████████████████▎                              | 4425/10000 [3:11:13<3:37:21,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4425 / 10000 | Loss: 1.0980958938598633, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  44%|████████████████████████▍                              | 4450/10000 [3:12:12<3:36:03,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4450 / 10000 | Loss: 1.1171382665634155, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  45%|████████████████████████▌                              | 4475/10000 [3:13:10<3:35:49,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4475 / 10000 | Loss: 1.1374051570892334, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  45%|████████████████████████▊                              | 4500/10000 [3:14:09<3:34:24,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4500 / 10000 | Loss: 1.160219669342041, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  45%|████████████████████████▉                              | 4525/10000 [3:15:07<3:33:32,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4525 / 10000 | Loss: 1.0777864456176758, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  46%|█████████████████████████                              | 4550/10000 [3:16:06<3:32:41,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4550 / 10000 | Loss: 1.2512528896331787, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  46%|█████████████████████████▏                             | 4575/10000 [3:17:04<3:31:41,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4575 / 10000 | Loss: 1.2235580682754517, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  46%|█████████████████████████▎                             | 4600/10000 [3:18:03<3:30:38,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4600 / 10000 | Loss: 1.6105151176452637, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  46%|█████████████████████████▍                             | 4625/10000 [3:19:01<3:29:37,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4625 / 10000 | Loss: 1.087547779083252, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  46%|█████████████████████████▌                             | 4650/10000 [3:20:00<3:28:26,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4650 / 10000 | Loss: 1.178298830986023, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  47%|█████████████████████████▋                             | 4675/10000 [3:20:58<3:27:36,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4675 / 10000 | Loss: 1.1777653694152832, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  47%|█████████████████████████▊                             | 4700/10000 [3:21:57<3:26:33,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4700 / 10000 | Loss: 1.1763947010040283, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  47%|█████████████████████████▉                             | 4725/10000 [3:22:55<3:25:56,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4725 / 10000 | Loss: 1.3056652545928955, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  48%|██████████████████████████▏                            | 4750/10000 [3:23:54<3:24:45,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4750 / 10000 | Loss: 1.0982567071914673, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  48%|██████████████████████████▎                            | 4775/10000 [3:24:52<3:23:44,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4775 / 10000 | Loss: 1.165818691253662, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  48%|██████████████████████████▍                            | 4800/10000 [3:25:51<3:22:47,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4800 / 10000 | Loss: 1.2614672183990479, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  48%|██████████████████████████▌                            | 4825/10000 [3:26:49<3:22:01,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4825 / 10000 | Loss: 1.0357102155685425, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  48%|██████████████████████████▋                            | 4850/10000 [3:27:48<3:21:13,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4850 / 10000 | Loss: 1.1736526489257812, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  49%|██████████████████████████▊                            | 4875/10000 [3:28:46<3:19:43,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4875 / 10000 | Loss: 1.0527184009552002, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  49%|██████████████████████████▉                            | 4900/10000 [3:30:40<3:18:39,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4900 / 10000 | Loss: 1.0092533826828003, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  49%|███████████████████████████                            | 4925/10000 [3:31:39<3:17:19,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4925 / 10000 | Loss: 1.1870722770690918, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  50%|███████████████████████████▏                           | 4950/10000 [3:32:37<3:16:14,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4950 / 10000 | Loss: 0.9729606509208679, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  50%|███████████████████████████▎                           | 4975/10000 [3:33:35<3:16:25,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (4975 / 10000 | Loss: 1.1025300025939941, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  50%|███████████████████████████▌                           | 5000/10000 [3:34:34<3:15:06,  2.34s/it]02/04/2024 14:05:43 - INFO - accelerate.accelerator - Saving current state to ./result_distiling\\checkpoint-5000-epoch-5\n",
      "02/04/2024 14:05:43 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5000 / 10000 | Loss: 0.9674230813980103, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/04/2024 14:05:44 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-5000-epoch-5\\model.safetensors\n",
      "02/04/2024 14:05:44 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n",
      "02/04/2024 14:05:45 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-5000-epoch-5\\model_1.safetensors\n",
      "02/04/2024 14:05:46 - INFO - accelerate.checkpointing - Optimizer state saved in result_distiling\\checkpoint-5000-epoch-5\\optimizer.bin\n",
      "02/04/2024 14:05:46 - INFO - accelerate.checkpointing - Scheduler state saved in result_distiling\\checkpoint-5000-epoch-5\\scheduler.bin\n",
      "02/04/2024 14:05:46 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in result_distiling\\checkpoint-5000-epoch-5\\sampler.bin\n",
      "02/04/2024 14:05:46 - INFO - accelerate.checkpointing - Sampler state for dataloader 1 saved in result_distiling\\checkpoint-5000-epoch-5\\sampler_1.bin\n",
      "02/04/2024 14:05:46 - INFO - accelerate.checkpointing - Sampler state for dataloader 2 saved in result_distiling\\checkpoint-5000-epoch-5\\sampler_2.bin\n",
      "02/04/2024 14:05:46 - INFO - accelerate.checkpointing - Sampler state for dataloader 3 saved in result_distiling\\checkpoint-5000-epoch-5\\sampler_3.bin\n",
      "02/04/2024 14:05:46 - INFO - accelerate.checkpointing - Sampler state for dataloader 4 saved in result_distiling\\checkpoint-5000-epoch-5\\sampler_4.bin\n",
      "02/04/2024 14:05:46 - INFO - accelerate.checkpointing - Sampler state for dataloader 5 saved in result_distiling\\checkpoint-5000-epoch-5\\sampler_5.bin\n",
      "02/04/2024 14:05:46 - INFO - accelerate.checkpointing - Sampler state for dataloader 6 saved in result_distiling\\checkpoint-5000-epoch-5\\sampler_6.bin\n",
      "02/04/2024 14:05:46 - INFO - accelerate.checkpointing - Sampler state for dataloader 7 saved in result_distiling\\checkpoint-5000-epoch-5\\sampler_7.bin\n",
      "02/04/2024 14:05:46 - INFO - accelerate.checkpointing - Sampler state for dataloader 8 saved in result_distiling\\checkpoint-5000-epoch-5\\sampler_8.bin\n",
      "02/04/2024 14:05:46 - INFO - accelerate.checkpointing - Sampler state for dataloader 9 saved in result_distiling\\checkpoint-5000-epoch-5\\sampler_9.bin\n",
      "02/04/2024 14:05:46 - INFO - accelerate.checkpointing - Gradient scaler state saved in result_distiling\\checkpoint-5000-epoch-5\\scaler.pt\n",
      "02/04/2024 14:05:46 - INFO - accelerate.checkpointing - Random states saved in result_distiling\\checkpoint-5000-epoch-5\\random_states_0.pkl\n",
      "02/04/2024 14:05:46 - INFO - run_distillation - Deleting older checkpoint [result_distiling\\checkpoint-2000-epoch-2] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Evaluating eval...:   0%|                                                                       | 0/81 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   1%|▊                                                              | 1/81 [00:19<26:08, 19.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   2%|█▌                                                             | 2/81 [00:21<12:17,  9.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   4%|██▎                                                            | 3/81 [00:23<07:46,  5.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   5%|███                                                            | 4/81 [00:25<05:39,  4.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   6%|███▉                                                           | 5/81 [00:27<04:29,  3.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   7%|████▋                                                          | 6/81 [00:29<03:46,  3.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   9%|█████▍                                                         | 7/81 [00:31<03:19,  2.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  10%|██████▏                                                        | 8/81 [00:33<03:01,  2.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  11%|███████                                                        | 9/81 [00:35<02:48,  2.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  12%|███████▋                                                      | 10/81 [00:37<02:39,  2.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  14%|████████▍                                                     | 11/81 [00:39<02:32,  2.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  15%|█████████▏                                                    | 12/81 [00:41<02:27,  2.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  16%|█████████▉                                                    | 13/81 [00:43<02:22,  2.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  17%|██████████▋                                                   | 14/81 [00:46<02:19,  2.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  19%|███████████▍                                                  | 15/81 [00:48<02:16,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  20%|████████████▏                                                 | 16/81 [00:50<02:14,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  21%|█████████████                                                 | 17/81 [00:52<02:11,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  22%|█████████████▊                                                | 18/81 [00:54<02:09,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  23%|██████████████▌                                               | 19/81 [00:56<02:07,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  25%|███████████████▎                                              | 20/81 [00:58<02:05,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  26%|████████████████                                              | 21/81 [01:00<02:02,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  27%|████████████████▊                                             | 22/81 [01:02<02:00,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  28%|█████████████████▌                                            | 23/81 [01:04<01:58,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  30%|██████████████████▎                                           | 24/81 [01:06<01:56,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  31%|███████████████████▏                                          | 25/81 [01:08<01:54,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  32%|███████████████████▉                                          | 26/81 [01:10<01:52,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  33%|████████████████████▋                                         | 27/81 [01:12<01:50,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  35%|█████████████████████▍                                        | 28/81 [01:14<01:48,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  36%|██████████████████████▏                                       | 29/81 [01:16<01:46,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  37%|██████████████████████▉                                       | 30/81 [01:18<01:44,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  38%|███████████████████████▋                                      | 31/81 [01:20<01:42,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  40%|████████████████████████▍                                     | 32/81 [01:22<01:40,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  41%|█████████████████████████▎                                    | 33/81 [01:24<01:38,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  42%|██████████████████████████                                    | 34/81 [01:26<01:36,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  43%|██████████████████████████▊                                   | 35/81 [01:28<01:34,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  44%|███████████████████████████▌                                  | 36/81 [01:31<01:32,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  46%|████████████████████████████▎                                 | 37/81 [01:33<01:30,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  47%|█████████████████████████████                                 | 38/81 [01:35<01:28,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  48%|█████████████████████████████▊                                | 39/81 [01:37<01:26,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  49%|██████████████████████████████▌                               | 40/81 [01:39<01:24,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  51%|███████████████████████████████▍                              | 41/81 [01:41<01:22,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  52%|████████████████████████████████▏                             | 42/81 [01:43<01:20,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  53%|████████████████████████████████▉                             | 43/81 [01:45<01:18,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  54%|█████████████████████████████████▋                            | 44/81 [01:47<01:15,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  56%|██████████████████████████████████▍                           | 45/81 [01:49<01:13,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  57%|███████████████████████████████████▏                          | 46/81 [01:51<01:11,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  58%|███████████████████████████████████▉                          | 47/81 [01:53<01:09,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  59%|████████████████████████████████████▋                         | 48/81 [01:55<01:07,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  60%|█████████████████████████████████████▌                        | 49/81 [01:57<01:05,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  62%|██████████████████████████████████████▎                       | 50/81 [01:59<01:03,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  63%|███████████████████████████████████████                       | 51/81 [02:01<01:01,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  64%|███████████████████████████████████████▊                      | 52/81 [02:03<00:59,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  65%|████████████████████████████████████████▌                     | 53/81 [02:05<00:57,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  67%|█████████████████████████████████████████▎                    | 54/81 [02:07<00:55,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  68%|██████████████████████████████████████████                    | 55/81 [02:10<00:53,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  69%|██████████████████████████████████████████▊                   | 56/81 [02:12<00:51,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  70%|███████████████████████████████████████████▋                  | 57/81 [02:14<00:49,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  72%|████████████████████████████████████████████▍                 | 58/81 [02:16<00:47,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  73%|█████████████████████████████████████████████▏                | 59/81 [02:18<00:45,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  74%|█████████████████████████████████████████████▉                | 60/81 [02:20<00:43,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  75%|██████████████████████████████████████████████▋               | 61/81 [02:22<00:41,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  77%|███████████████████████████████████████████████▍              | 62/81 [02:24<00:39,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  78%|████████████████████████████████████████████████▏             | 63/81 [02:26<00:36,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  79%|████████████████████████████████████████████████▉             | 64/81 [02:28<00:34,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  80%|█████████████████████████████████████████████████▊            | 65/81 [02:30<00:32,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  81%|██████████████████████████████████████████████████▌           | 66/81 [02:32<00:30,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  83%|███████████████████████████████████████████████████▎          | 67/81 [02:34<00:28,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  84%|████████████████████████████████████████████████████          | 68/81 [02:36<00:26,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  85%|████████████████████████████████████████████████████▊         | 69/81 [02:38<00:24,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  86%|█████████████████████████████████████████████████████▌        | 70/81 [02:40<00:22,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  88%|██████████████████████████████████████████████████████▎       | 71/81 [02:42<00:20,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  89%|███████████████████████████████████████████████████████       | 72/81 [02:44<00:18,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  90%|███████████████████████████████████████████████████████▉      | 73/81 [02:47<00:16,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  91%|████████████████████████████████████████████████████████▋     | 74/81 [02:49<00:14,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  93%|█████████████████████████████████████████████████████████▍    | 75/81 [02:51<00:12,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  94%|██████████████████████████████████████████████████████████▏   | 76/81 [02:53<00:10,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  95%|██████████████████████████████████████████████████████████▉   | 77/81 [02:55<00:08,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  96%|███████████████████████████████████████████████████████████▋  | 78/81 [02:57<00:06,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  98%|████████████████████████████████████████████████████████████▍ | 79/81 [02:59<00:04,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  99%|█████████████████████████████████████████████████████████████▏| 80/81 [03:01<00:02,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...: 100%|██████████████████████████████████████████████████████████████| 81/81 [03:04<00:00,  2.27s/it]\u001b[A\u001b[A\n",
      "Train steps ... :  50%|███████████████████████████▌                           | 5000/10000 [3:37:43<3:15:06,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval results for step (5000 / 10000 | Eval Loss: 17.686080932617188 | )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  50%|███████████████████████████▋                           | 5025/10000 [3:38:41<3:14:55,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5025 / 10000 | Loss: 1.030433177947998, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  50%|███████████████████████████▊                           | 5050/10000 [3:39:40<3:12:41,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5050 / 10000 | Loss: 1.0715358257293701, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  51%|███████████████████████████▉                           | 5075/10000 [3:40:38<3:12:26,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5075 / 10000 | Loss: 0.9587994813919067, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  51%|████████████████████████████                           | 5100/10000 [3:41:37<3:11:20,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5100 / 10000 | Loss: 1.0560641288757324, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  51%|████████████████████████████▏                          | 5125/10000 [3:42:35<3:10:19,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5125 / 10000 | Loss: 0.9061750173568726, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  52%|████████████████████████████▎                          | 5150/10000 [3:43:34<3:09:17,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5150 / 10000 | Loss: 1.2319414615631104, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  52%|████████████████████████████▍                          | 5175/10000 [3:44:32<3:08:01,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5175 / 10000 | Loss: 1.0798786878585815, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  52%|████████████████████████████▌                          | 5200/10000 [3:45:31<3:07:31,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5200 / 10000 | Loss: 0.9267472624778748, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  52%|████████████████████████████▋                          | 5225/10000 [3:46:29<3:05:58,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5225 / 10000 | Loss: 1.1066452264785767, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  52%|████████████████████████████▉                          | 5250/10000 [3:47:28<3:05:29,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5250 / 10000 | Loss: 1.026441216468811, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  53%|█████████████████████████████                          | 5275/10000 [3:48:26<3:04:24,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5275 / 10000 | Loss: 1.1056915521621704, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  53%|█████████████████████████████▏                         | 5300/10000 [3:49:25<3:03:27,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5300 / 10000 | Loss: 1.0052663087844849, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  53%|█████████████████████████████▎                         | 5325/10000 [3:50:23<3:02:32,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5325 / 10000 | Loss: 1.1114205121994019, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  54%|█████████████████████████████▍                         | 5350/10000 [3:51:22<3:00:58,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5350 / 10000 | Loss: 1.1343098878860474, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  54%|█████████████████████████████▌                         | 5375/10000 [3:52:20<3:00:23,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5375 / 10000 | Loss: 0.9445814490318298, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  54%|█████████████████████████████▋                         | 5400/10000 [3:53:19<2:59:30,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5400 / 10000 | Loss: 0.9959555864334106, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  54%|█████████████████████████████▊                         | 5425/10000 [3:54:18<2:58:29,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5425 / 10000 | Loss: 0.9198506474494934, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  55%|█████████████████████████████▉                         | 5450/10000 [3:55:16<2:57:48,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5450 / 10000 | Loss: 0.9914866089820862, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  55%|██████████████████████████████                         | 5475/10000 [3:56:15<2:56:40,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5475 / 10000 | Loss: 1.055698275566101, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  55%|██████████████████████████████▎                        | 5500/10000 [3:57:13<2:55:53,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5500 / 10000 | Loss: 1.1012306213378906, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  55%|██████████████████████████████▍                        | 5525/10000 [3:58:12<2:54:27,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5525 / 10000 | Loss: 1.2453593015670776, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  56%|██████████████████████████████▌                        | 5550/10000 [3:59:11<2:53:45,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5550 / 10000 | Loss: 0.9824076890945435, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  56%|██████████████████████████████▋                        | 5575/10000 [4:00:09<2:52:52,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5575 / 10000 | Loss: 0.9306004047393799, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  56%|██████████████████████████████▊                        | 5600/10000 [4:01:08<2:51:59,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5600 / 10000 | Loss: 0.958972156047821, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  56%|██████████████████████████████▉                        | 5625/10000 [4:02:06<2:50:54,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5625 / 10000 | Loss: 0.9662346839904785, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  56%|███████████████████████████████                        | 5650/10000 [4:03:05<2:50:15,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5650 / 10000 | Loss: 1.2058942317962646, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  57%|███████████████████████████████▏                       | 5675/10000 [4:04:04<2:49:06,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5675 / 10000 | Loss: 1.1478670835494995, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  57%|███████████████████████████████▎                       | 5700/10000 [4:05:02<2:48:00,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5700 / 10000 | Loss: 0.943478524684906, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  57%|███████████████████████████████▍                       | 5725/10000 [4:06:01<2:47:11,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5725 / 10000 | Loss: 0.9077285528182983, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  57%|███████████████████████████████▌                       | 5750/10000 [4:07:00<2:46:17,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5750 / 10000 | Loss: 1.1137852668762207, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  58%|███████████████████████████████▊                       | 5775/10000 [4:07:58<2:45:18,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5775 / 10000 | Loss: 1.0586947202682495, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  58%|███████████████████████████████▉                       | 5800/10000 [4:08:57<2:44:09,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5800 / 10000 | Loss: 0.9523536562919617, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  58%|████████████████████████████████                       | 5825/10000 [4:09:56<2:43:26,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5825 / 10000 | Loss: 1.039750576019287, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  58%|████████████████████████████████▏                      | 5850/10000 [4:10:54<2:42:15,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5850 / 10000 | Loss: 0.9568492770195007, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  59%|████████████████████████████████▎                      | 5875/10000 [4:12:47<2:41:03,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5875 / 10000 | Loss: 1.1822620630264282, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  59%|████████████████████████████████▍                      | 5900/10000 [4:13:45<2:39:23,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5900 / 10000 | Loss: 0.8819845914840698, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  59%|████████████████████████████████▌                      | 5925/10000 [4:14:43<2:39:13,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5925 / 10000 | Loss: 0.8761067986488342, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  60%|████████████████████████████████▋                      | 5950/10000 [4:15:42<2:37:40,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5950 / 10000 | Loss: 0.8789134621620178, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  60%|████████████████████████████████▊                      | 5975/10000 [4:16:41<2:37:16,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (5975 / 10000 | Loss: 0.912126362323761, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  60%|█████████████████████████████████                      | 6000/10000 [4:17:39<2:36:09,  2.34s/it]02/04/2024 14:48:48 - INFO - accelerate.accelerator - Saving current state to ./result_distiling\\checkpoint-6000-epoch-6\n",
      "02/04/2024 14:48:48 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6000 / 10000 | Loss: 0.924704372882843, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/04/2024 14:48:49 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-6000-epoch-6\\model.safetensors\n",
      "02/04/2024 14:48:49 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n",
      "02/04/2024 14:48:50 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-6000-epoch-6\\model_1.safetensors\n",
      "02/04/2024 14:48:51 - INFO - accelerate.checkpointing - Optimizer state saved in result_distiling\\checkpoint-6000-epoch-6\\optimizer.bin\n",
      "02/04/2024 14:48:51 - INFO - accelerate.checkpointing - Scheduler state saved in result_distiling\\checkpoint-6000-epoch-6\\scheduler.bin\n",
      "02/04/2024 14:48:51 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in result_distiling\\checkpoint-6000-epoch-6\\sampler.bin\n",
      "02/04/2024 14:48:51 - INFO - accelerate.checkpointing - Sampler state for dataloader 1 saved in result_distiling\\checkpoint-6000-epoch-6\\sampler_1.bin\n",
      "02/04/2024 14:48:51 - INFO - accelerate.checkpointing - Sampler state for dataloader 2 saved in result_distiling\\checkpoint-6000-epoch-6\\sampler_2.bin\n",
      "02/04/2024 14:48:51 - INFO - accelerate.checkpointing - Sampler state for dataloader 3 saved in result_distiling\\checkpoint-6000-epoch-6\\sampler_3.bin\n",
      "02/04/2024 14:48:51 - INFO - accelerate.checkpointing - Sampler state for dataloader 4 saved in result_distiling\\checkpoint-6000-epoch-6\\sampler_4.bin\n",
      "02/04/2024 14:48:51 - INFO - accelerate.checkpointing - Sampler state for dataloader 5 saved in result_distiling\\checkpoint-6000-epoch-6\\sampler_5.bin\n",
      "02/04/2024 14:48:51 - INFO - accelerate.checkpointing - Sampler state for dataloader 6 saved in result_distiling\\checkpoint-6000-epoch-6\\sampler_6.bin\n",
      "02/04/2024 14:48:51 - INFO - accelerate.checkpointing - Sampler state for dataloader 7 saved in result_distiling\\checkpoint-6000-epoch-6\\sampler_7.bin\n",
      "02/04/2024 14:48:51 - INFO - accelerate.checkpointing - Sampler state for dataloader 8 saved in result_distiling\\checkpoint-6000-epoch-6\\sampler_8.bin\n",
      "02/04/2024 14:48:51 - INFO - accelerate.checkpointing - Sampler state for dataloader 9 saved in result_distiling\\checkpoint-6000-epoch-6\\sampler_9.bin\n",
      "02/04/2024 14:48:51 - INFO - accelerate.checkpointing - Sampler state for dataloader 10 saved in result_distiling\\checkpoint-6000-epoch-6\\sampler_10.bin\n",
      "02/04/2024 14:48:51 - INFO - accelerate.checkpointing - Sampler state for dataloader 11 saved in result_distiling\\checkpoint-6000-epoch-6\\sampler_11.bin\n",
      "02/04/2024 14:48:51 - INFO - accelerate.checkpointing - Gradient scaler state saved in result_distiling\\checkpoint-6000-epoch-6\\scaler.pt\n",
      "02/04/2024 14:48:51 - INFO - accelerate.checkpointing - Random states saved in result_distiling\\checkpoint-6000-epoch-6\\random_states_0.pkl\n",
      "02/04/2024 14:48:51 - INFO - run_distillation - Deleting older checkpoint [result_distiling\\checkpoint-3000-epoch-3] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Evaluating eval...:   0%|                                                                       | 0/81 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   1%|▊                                                              | 1/81 [00:20<26:44, 20.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   2%|█▌                                                             | 2/81 [00:22<12:38,  9.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   4%|██▎                                                            | 3/81 [00:24<07:57,  6.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   5%|███                                                            | 4/81 [00:26<05:46,  4.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   6%|███▉                                                           | 5/81 [00:28<04:33,  3.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   7%|████▋                                                          | 6/81 [00:30<03:50,  3.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   9%|█████▍                                                         | 7/81 [00:32<03:21,  2.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  10%|██████▏                                                        | 8/81 [00:34<03:02,  2.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  11%|███████                                                        | 9/81 [00:36<02:49,  2.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  12%|███████▋                                                      | 10/81 [00:38<02:39,  2.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  14%|████████▍                                                     | 11/81 [00:40<02:33,  2.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  15%|█████████▏                                                    | 12/81 [00:42<02:27,  2.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  16%|█████████▉                                                    | 13/81 [00:44<02:23,  2.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  17%|██████████▋                                                   | 14/81 [00:46<02:19,  2.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  19%|███████████▍                                                  | 15/81 [00:48<02:16,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  20%|████████████▏                                                 | 16/81 [00:50<02:14,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  21%|█████████████                                                 | 17/81 [00:52<02:11,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  22%|█████████████▊                                                | 18/81 [00:54<02:09,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  23%|██████████████▌                                               | 19/81 [00:56<02:07,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  25%|███████████████▎                                              | 20/81 [00:58<02:05,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  26%|████████████████                                              | 21/81 [01:00<02:03,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  27%|████████████████▊                                             | 22/81 [01:03<02:01,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  28%|█████████████████▌                                            | 23/81 [01:05<01:59,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  30%|██████████████████▎                                           | 24/81 [01:07<01:56,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  31%|███████████████████▏                                          | 25/81 [01:09<01:54,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  32%|███████████████████▉                                          | 26/81 [01:11<01:52,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  33%|████████████████████▋                                         | 27/81 [01:13<01:50,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  35%|█████████████████████▍                                        | 28/81 [01:15<01:48,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  36%|██████████████████████▏                                       | 29/81 [01:17<01:46,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  37%|██████████████████████▉                                       | 30/81 [01:19<01:44,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  38%|███████████████████████▋                                      | 31/81 [01:21<01:42,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  40%|████████████████████████▍                                     | 32/81 [01:23<01:40,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  41%|█████████████████████████▎                                    | 33/81 [01:25<01:38,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  42%|██████████████████████████                                    | 34/81 [01:27<01:36,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  43%|██████████████████████████▊                                   | 35/81 [01:29<01:34,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  44%|███████████████████████████▌                                  | 36/81 [01:31<01:32,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  46%|████████████████████████████▎                                 | 37/81 [01:33<01:30,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  47%|█████████████████████████████                                 | 38/81 [01:35<01:28,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  48%|█████████████████████████████▊                                | 39/81 [01:37<01:26,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  49%|██████████████████████████████▌                               | 40/81 [01:40<01:24,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  51%|███████████████████████████████▍                              | 41/81 [01:42<01:22,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  52%|████████████████████████████████▏                             | 42/81 [01:44<01:20,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  53%|████████████████████████████████▉                             | 43/81 [01:46<01:18,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  54%|█████████████████████████████████▋                            | 44/81 [01:48<01:16,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  56%|██████████████████████████████████▍                           | 45/81 [01:50<01:14,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  57%|███████████████████████████████████▏                          | 46/81 [01:52<01:12,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  58%|███████████████████████████████████▉                          | 47/81 [01:54<01:09,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  59%|████████████████████████████████████▋                         | 48/81 [01:56<01:07,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  60%|█████████████████████████████████████▌                        | 49/81 [01:58<01:05,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  62%|██████████████████████████████████████▎                       | 50/81 [02:00<01:03,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  63%|███████████████████████████████████████                       | 51/81 [02:02<01:01,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  64%|███████████████████████████████████████▊                      | 52/81 [02:04<00:59,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  65%|████████████████████████████████████████▌                     | 53/81 [02:06<00:57,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  67%|█████████████████████████████████████████▎                    | 54/81 [02:08<00:55,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  68%|██████████████████████████████████████████                    | 55/81 [02:10<00:53,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  69%|██████████████████████████████████████████▊                   | 56/81 [02:12<00:51,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  70%|███████████████████████████████████████████▋                  | 57/81 [02:14<00:49,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  72%|████████████████████████████████████████████▍                 | 58/81 [02:17<00:47,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  73%|█████████████████████████████████████████████▏                | 59/81 [02:19<00:45,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  74%|█████████████████████████████████████████████▉                | 60/81 [02:21<00:43,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  75%|██████████████████████████████████████████████▋               | 61/81 [02:23<00:41,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  77%|███████████████████████████████████████████████▍              | 62/81 [02:25<00:39,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  78%|████████████████████████████████████████████████▏             | 63/81 [02:27<00:37,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  79%|████████████████████████████████████████████████▉             | 64/81 [02:29<00:35,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  80%|█████████████████████████████████████████████████▊            | 65/81 [02:31<00:33,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  81%|██████████████████████████████████████████████████▌           | 66/81 [02:33<00:30,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  83%|███████████████████████████████████████████████████▎          | 67/81 [02:35<00:28,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  84%|████████████████████████████████████████████████████          | 68/81 [02:37<00:26,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  85%|████████████████████████████████████████████████████▊         | 69/81 [02:39<00:24,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  86%|█████████████████████████████████████████████████████▌        | 70/81 [02:41<00:22,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  88%|██████████████████████████████████████████████████████▎       | 71/81 [02:43<00:20,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  89%|███████████████████████████████████████████████████████       | 72/81 [02:45<00:18,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  90%|███████████████████████████████████████████████████████▉      | 73/81 [02:47<00:16,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  91%|████████████████████████████████████████████████████████▋     | 74/81 [02:50<00:14,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  93%|█████████████████████████████████████████████████████████▍    | 75/81 [02:52<00:12,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  94%|██████████████████████████████████████████████████████████▏   | 76/81 [02:54<00:10,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  95%|██████████████████████████████████████████████████████████▉   | 77/81 [02:56<00:08,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  96%|███████████████████████████████████████████████████████████▋  | 78/81 [02:58<00:06,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  98%|████████████████████████████████████████████████████████████▍ | 79/81 [03:00<00:04,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  99%|█████████████████████████████████████████████████████████████▏| 80/81 [03:02<00:02,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...: 100%|██████████████████████████████████████████████████████████████| 81/81 [03:05<00:00,  2.29s/it]\u001b[A\u001b[A\n",
      "Train steps ... :  60%|█████████████████████████████████                      | 6000/10000 [4:20:49<2:36:09,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval results for step (6000 / 10000 | Eval Loss: 17.488649368286133 | )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  60%|█████████████████████████████████▏                     | 6025/10000 [4:21:48<2:36:15,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6025 / 10000 | Loss: 1.1000375747680664, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  60%|█████████████████████████████████▎                     | 6050/10000 [4:22:46<2:34:14,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6050 / 10000 | Loss: 0.8554847240447998, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  61%|█████████████████████████████████▍                     | 6075/10000 [4:23:45<2:33:23,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6075 / 10000 | Loss: 0.8656204342842102, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  61%|█████████████████████████████████▌                     | 6100/10000 [4:24:43<2:32:30,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6100 / 10000 | Loss: 0.9246616959571838, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  61%|█████████████████████████████████▋                     | 6125/10000 [4:25:42<2:30:55,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6125 / 10000 | Loss: 0.8430646657943726, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  62%|█████████████████████████████████▊                     | 6150/10000 [4:26:41<2:30:38,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6150 / 10000 | Loss: 0.8946877717971802, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  62%|█████████████████████████████████▉                     | 6175/10000 [4:27:39<2:29:16,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6175 / 10000 | Loss: 0.9142367839813232, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  62%|██████████████████████████████████                     | 6200/10000 [4:28:38<2:28:09,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6200 / 10000 | Loss: 0.8690928220748901, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  62%|██████████████████████████████████▏                    | 6225/10000 [4:29:36<2:27:23,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6225 / 10000 | Loss: 0.9286497235298157, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  62%|██████████████████████████████████▍                    | 6250/10000 [4:30:35<2:26:32,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6250 / 10000 | Loss: 1.0247814655303955, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  63%|██████████████████████████████████▌                    | 6275/10000 [4:31:33<2:25:34,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6275 / 10000 | Loss: 0.8621876239776611, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  63%|██████████████████████████████████▋                    | 6300/10000 [4:32:32<2:24:13,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6300 / 10000 | Loss: 1.0870281457901, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  63%|██████████████████████████████████▊                    | 6325/10000 [4:33:31<2:23:35,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6325 / 10000 | Loss: 0.800069272518158, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  64%|██████████████████████████████████▉                    | 6350/10000 [4:34:29<2:22:37,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6350 / 10000 | Loss: 0.7998272180557251, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  64%|███████████████████████████████████                    | 6375/10000 [4:35:28<2:21:41,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6375 / 10000 | Loss: 0.8375637531280518, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  64%|███████████████████████████████████▏                   | 6400/10000 [4:36:26<2:20:42,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6400 / 10000 | Loss: 0.8828831911087036, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  64%|███████████████████████████████████▎                   | 6425/10000 [4:37:25<2:19:19,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6425 / 10000 | Loss: 0.8036766052246094, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  64%|███████████████████████████████████▍                   | 6450/10000 [4:38:24<2:18:40,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6450 / 10000 | Loss: 0.995826005935669, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  65%|███████████████████████████████████▌                   | 6475/10000 [4:39:22<2:17:34,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6475 / 10000 | Loss: 1.2546498775482178, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  65%|███████████████████████████████████▊                   | 6500/10000 [4:40:21<2:16:59,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6500 / 10000 | Loss: 0.9009677171707153, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  65%|███████████████████████████████████▉                   | 6525/10000 [4:41:19<2:15:34,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6525 / 10000 | Loss: 0.8776696920394897, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  66%|████████████████████████████████████                   | 6550/10000 [4:42:18<2:14:48,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6550 / 10000 | Loss: 0.8177801370620728, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  66%|████████████████████████████████████▏                  | 6575/10000 [4:43:17<2:13:41,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6575 / 10000 | Loss: 0.8530597686767578, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  66%|████████████████████████████████████▎                  | 6600/10000 [4:44:15<2:12:58,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6600 / 10000 | Loss: 0.8793672919273376, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  66%|████████████████████████████████████▍                  | 6625/10000 [4:45:14<2:11:43,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6625 / 10000 | Loss: 0.9362707138061523, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  66%|████████████████████████████████████▌                  | 6650/10000 [4:46:12<2:10:23,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6650 / 10000 | Loss: 0.8266850709915161, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  67%|████████████████████████████████████▋                  | 6675/10000 [4:47:11<2:09:48,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6675 / 10000 | Loss: 1.1101717948913574, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  67%|████████████████████████████████████▊                  | 6700/10000 [4:48:09<2:08:41,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6700 / 10000 | Loss: 1.3271428346633911, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  67%|████████████████████████████████████▉                  | 6725/10000 [4:49:08<2:07:49,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6725 / 10000 | Loss: 0.8962666392326355, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  68%|█████████████████████████████████████▏                 | 6750/10000 [4:50:07<2:07:02,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6750 / 10000 | Loss: 0.8496870994567871, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  68%|█████████████████████████████████████▎                 | 6775/10000 [4:51:05<2:05:56,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6775 / 10000 | Loss: 0.8677952289581299, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  68%|█████████████████████████████████████▍                 | 6800/10000 [4:52:04<2:04:53,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6800 / 10000 | Loss: 0.8898068070411682, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  68%|█████████████████████████████████████▌                 | 6825/10000 [4:53:02<2:03:44,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6825 / 10000 | Loss: 0.8448197245597839, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  68%|█████████████████████████████████████▋                 | 6850/10000 [4:55:09<2:03:31,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6850 / 10000 | Loss: 0.8052240014076233, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  69%|█████████████████████████████████████▊                 | 6875/10000 [4:56:07<2:01:33,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6875 / 10000 | Loss: 0.8105142712593079, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  69%|█████████████████████████████████████▉                 | 6900/10000 [4:57:05<2:00:41,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6900 / 10000 | Loss: 0.8628576993942261, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  69%|██████████████████████████████████████                 | 6925/10000 [4:58:04<2:00:08,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6925 / 10000 | Loss: 0.7661523818969727, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  70%|██████████████████████████████████████▏                | 6950/10000 [4:59:02<1:59:13,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6950 / 10000 | Loss: 0.7547834515571594, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  70%|██████████████████████████████████████▎                | 6975/10000 [5:00:01<1:58:16,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (6975 / 10000 | Loss: 0.7231242656707764, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  70%|██████████████████████████████████████▌                | 7000/10000 [5:01:00<1:56:58,  2.34s/it]02/04/2024 15:32:08 - INFO - accelerate.accelerator - Saving current state to ./result_distiling\\checkpoint-7000-epoch-7\n",
      "02/04/2024 15:32:08 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7000 / 10000 | Loss: 0.7938138246536255, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/04/2024 15:32:09 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-7000-epoch-7\\model.safetensors\n",
      "02/04/2024 15:32:09 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n",
      "02/04/2024 15:32:11 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-7000-epoch-7\\model_1.safetensors\n",
      "02/04/2024 15:32:12 - INFO - accelerate.checkpointing - Optimizer state saved in result_distiling\\checkpoint-7000-epoch-7\\optimizer.bin\n",
      "02/04/2024 15:32:12 - INFO - accelerate.checkpointing - Scheduler state saved in result_distiling\\checkpoint-7000-epoch-7\\scheduler.bin\n",
      "02/04/2024 15:32:12 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in result_distiling\\checkpoint-7000-epoch-7\\sampler.bin\n",
      "02/04/2024 15:32:12 - INFO - accelerate.checkpointing - Sampler state for dataloader 1 saved in result_distiling\\checkpoint-7000-epoch-7\\sampler_1.bin\n",
      "02/04/2024 15:32:12 - INFO - accelerate.checkpointing - Sampler state for dataloader 2 saved in result_distiling\\checkpoint-7000-epoch-7\\sampler_2.bin\n",
      "02/04/2024 15:32:12 - INFO - accelerate.checkpointing - Sampler state for dataloader 3 saved in result_distiling\\checkpoint-7000-epoch-7\\sampler_3.bin\n",
      "02/04/2024 15:32:12 - INFO - accelerate.checkpointing - Sampler state for dataloader 4 saved in result_distiling\\checkpoint-7000-epoch-7\\sampler_4.bin\n",
      "02/04/2024 15:32:12 - INFO - accelerate.checkpointing - Sampler state for dataloader 5 saved in result_distiling\\checkpoint-7000-epoch-7\\sampler_5.bin\n",
      "02/04/2024 15:32:12 - INFO - accelerate.checkpointing - Sampler state for dataloader 6 saved in result_distiling\\checkpoint-7000-epoch-7\\sampler_6.bin\n",
      "02/04/2024 15:32:12 - INFO - accelerate.checkpointing - Sampler state for dataloader 7 saved in result_distiling\\checkpoint-7000-epoch-7\\sampler_7.bin\n",
      "02/04/2024 15:32:12 - INFO - accelerate.checkpointing - Sampler state for dataloader 8 saved in result_distiling\\checkpoint-7000-epoch-7\\sampler_8.bin\n",
      "02/04/2024 15:32:12 - INFO - accelerate.checkpointing - Sampler state for dataloader 9 saved in result_distiling\\checkpoint-7000-epoch-7\\sampler_9.bin\n",
      "02/04/2024 15:32:12 - INFO - accelerate.checkpointing - Sampler state for dataloader 10 saved in result_distiling\\checkpoint-7000-epoch-7\\sampler_10.bin\n",
      "02/04/2024 15:32:12 - INFO - accelerate.checkpointing - Sampler state for dataloader 11 saved in result_distiling\\checkpoint-7000-epoch-7\\sampler_11.bin\n",
      "02/04/2024 15:32:12 - INFO - accelerate.checkpointing - Sampler state for dataloader 12 saved in result_distiling\\checkpoint-7000-epoch-7\\sampler_12.bin\n",
      "02/04/2024 15:32:12 - INFO - accelerate.checkpointing - Sampler state for dataloader 13 saved in result_distiling\\checkpoint-7000-epoch-7\\sampler_13.bin\n",
      "02/04/2024 15:32:12 - INFO - accelerate.checkpointing - Gradient scaler state saved in result_distiling\\checkpoint-7000-epoch-7\\scaler.pt\n",
      "02/04/2024 15:32:12 - INFO - accelerate.checkpointing - Random states saved in result_distiling\\checkpoint-7000-epoch-7\\random_states_0.pkl\n",
      "02/04/2024 15:32:12 - INFO - run_distillation - Deleting older checkpoint [result_distiling\\checkpoint-4000-epoch-4] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Evaluating eval...:   0%|                                                                       | 0/81 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   1%|▊                                                              | 1/81 [00:20<27:01, 20.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   2%|█▌                                                             | 2/81 [00:22<12:40,  9.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   4%|██▎                                                            | 3/81 [00:24<07:59,  6.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   5%|███                                                            | 4/81 [00:26<05:47,  4.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   6%|███▉                                                           | 5/81 [00:28<04:34,  3.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   7%|████▋                                                          | 6/81 [00:30<03:49,  3.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   9%|█████▍                                                         | 7/81 [00:32<03:21,  2.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  10%|██████▏                                                        | 8/81 [00:34<03:02,  2.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  11%|███████                                                        | 9/81 [00:36<02:49,  2.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  12%|███████▋                                                      | 10/81 [00:38<02:39,  2.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  14%|████████▍                                                     | 11/81 [00:40<02:32,  2.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  15%|█████████▏                                                    | 12/81 [00:42<02:27,  2.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  16%|█████████▉                                                    | 13/81 [00:44<02:23,  2.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  17%|██████████▋                                                   | 14/81 [00:46<02:19,  2.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  19%|███████████▍                                                  | 15/81 [00:48<02:16,  2.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  20%|████████████▏                                                 | 16/81 [00:50<02:14,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  21%|█████████████                                                 | 17/81 [00:52<02:12,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  22%|█████████████▊                                                | 18/81 [00:54<02:09,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  23%|██████████████▌                                               | 19/81 [00:56<02:07,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  25%|███████████████▎                                              | 20/81 [00:59<02:05,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  26%|████████████████                                              | 21/81 [01:01<02:02,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  27%|████████████████▊                                             | 22/81 [01:03<02:00,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  28%|█████████████████▌                                            | 23/81 [01:05<01:58,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  30%|██████████████████▎                                           | 24/81 [01:07<01:56,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  31%|███████████████████▏                                          | 25/81 [01:09<01:54,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  32%|███████████████████▉                                          | 26/81 [01:11<01:52,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  33%|████████████████████▋                                         | 27/81 [01:13<01:50,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  35%|█████████████████████▍                                        | 28/81 [01:15<01:48,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  36%|██████████████████████▏                                       | 29/81 [01:17<01:46,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  37%|██████████████████████▉                                       | 30/81 [01:19<01:44,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  38%|███████████████████████▋                                      | 31/81 [01:21<01:42,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  40%|████████████████████████▍                                     | 32/81 [01:23<01:40,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  41%|█████████████████████████▎                                    | 33/81 [01:25<01:38,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  42%|██████████████████████████                                    | 34/81 [01:27<01:36,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  43%|██████████████████████████▊                                   | 35/81 [01:29<01:34,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  44%|███████████████████████████▌                                  | 36/81 [01:31<01:32,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  46%|████████████████████████████▎                                 | 37/81 [01:33<01:30,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  47%|█████████████████████████████                                 | 38/81 [01:35<01:28,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  48%|█████████████████████████████▊                                | 39/81 [01:37<01:26,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  49%|██████████████████████████████▌                               | 40/81 [01:40<01:24,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  51%|███████████████████████████████▍                              | 41/81 [01:42<01:22,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  52%|████████████████████████████████▏                             | 42/81 [01:44<01:20,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  53%|████████████████████████████████▉                             | 43/81 [01:46<01:17,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  54%|█████████████████████████████████▋                            | 44/81 [01:48<01:15,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  56%|██████████████████████████████████▍                           | 45/81 [01:50<01:13,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  57%|███████████████████████████████████▏                          | 46/81 [01:52<01:11,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  58%|███████████████████████████████████▉                          | 47/81 [01:54<01:09,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  59%|████████████████████████████████████▋                         | 48/81 [01:56<01:07,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  60%|█████████████████████████████████████▌                        | 49/81 [01:58<01:05,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  62%|██████████████████████████████████████▎                       | 50/81 [02:00<01:03,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  63%|███████████████████████████████████████                       | 51/81 [02:02<01:01,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  64%|███████████████████████████████████████▊                      | 52/81 [02:04<00:59,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  65%|████████████████████████████████████████▌                     | 53/81 [02:06<00:57,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  67%|█████████████████████████████████████████▎                    | 54/81 [02:08<00:55,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  68%|██████████████████████████████████████████                    | 55/81 [02:10<00:53,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  69%|██████████████████████████████████████████▊                   | 56/81 [02:12<00:51,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  70%|███████████████████████████████████████████▋                  | 57/81 [02:15<00:49,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  72%|████████████████████████████████████████████▍                 | 58/81 [02:17<00:47,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  73%|█████████████████████████████████████████████▏                | 59/81 [02:19<00:45,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  74%|█████████████████████████████████████████████▉                | 60/81 [02:21<00:43,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  75%|██████████████████████████████████████████████▋               | 61/81 [02:23<00:41,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  77%|███████████████████████████████████████████████▍              | 62/81 [02:25<00:39,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  78%|████████████████████████████████████████████████▏             | 63/81 [02:27<00:37,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  79%|████████████████████████████████████████████████▉             | 64/81 [02:29<00:34,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  80%|█████████████████████████████████████████████████▊            | 65/81 [02:31<00:32,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  81%|██████████████████████████████████████████████████▌           | 66/81 [02:33<00:30,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  83%|███████████████████████████████████████████████████▎          | 67/81 [02:35<00:28,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  84%|████████████████████████████████████████████████████          | 68/81 [02:37<00:26,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  85%|████████████████████████████████████████████████████▊         | 69/81 [02:39<00:24,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  86%|█████████████████████████████████████████████████████▌        | 70/81 [02:41<00:22,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  88%|██████████████████████████████████████████████████████▎       | 71/81 [02:43<00:20,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  89%|███████████████████████████████████████████████████████       | 72/81 [02:45<00:18,  2.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  90%|███████████████████████████████████████████████████████▉      | 73/81 [02:47<00:16,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  91%|████████████████████████████████████████████████████████▋     | 74/81 [02:50<00:14,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  93%|█████████████████████████████████████████████████████████▍    | 75/81 [02:52<00:12,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  94%|██████████████████████████████████████████████████████████▏   | 76/81 [02:54<00:10,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  95%|██████████████████████████████████████████████████████████▉   | 77/81 [02:56<00:08,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  96%|███████████████████████████████████████████████████████████▋  | 78/81 [02:58<00:06,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  98%|████████████████████████████████████████████████████████████▍ | 79/81 [03:00<00:04,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  99%|█████████████████████████████████████████████████████████████▏| 80/81 [03:02<00:02,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...: 100%|██████████████████████████████████████████████████████████████| 81/81 [03:05<00:00,  2.29s/it]\u001b[A\u001b[A\n",
      "Train steps ... :  70%|██████████████████████████████████████▌                | 7000/10000 [5:04:09<1:56:58,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval results for step (7000 / 10000 | Eval Loss: 16.865427017211914 | )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  70%|██████████████████████████████████████▋                | 7025/10000 [5:05:08<1:56:42,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7025 / 10000 | Loss: 1.0468120574951172, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  70%|██████████████████████████████████████▊                | 7050/10000 [5:06:07<1:55:18,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7050 / 10000 | Loss: 0.7348576784133911, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  71%|██████████████████████████████████████▉                | 7075/10000 [5:07:05<1:54:24,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7075 / 10000 | Loss: 0.7680048942565918, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  71%|███████████████████████████████████████                | 7100/10000 [5:08:04<1:53:25,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7100 / 10000 | Loss: 0.7587027549743652, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  71%|███████████████████████████████████████▏               | 7125/10000 [5:09:02<1:52:29,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7125 / 10000 | Loss: 0.806114912033081, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  72%|███████████████████████████████████████▎               | 7150/10000 [5:10:01<1:51:25,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7150 / 10000 | Loss: 0.9236928820610046, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  72%|███████████████████████████████████████▍               | 7175/10000 [5:11:00<1:50:03,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7175 / 10000 | Loss: 0.7350970506668091, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  72%|███████████████████████████████████████▌               | 7200/10000 [5:11:58<1:49:19,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7200 / 10000 | Loss: 0.801490068435669, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  72%|███████████████████████████████████████▋               | 7225/10000 [5:12:57<1:48:29,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7225 / 10000 | Loss: 0.8397310972213745, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  72%|███████████████████████████████████████▉               | 7250/10000 [5:13:56<1:47:28,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7250 / 10000 | Loss: 0.8272190093994141, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  73%|████████████████████████████████████████               | 7275/10000 [5:14:54<1:46:28,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7275 / 10000 | Loss: 0.8400817513465881, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  73%|████████████████████████████████████████▏              | 7300/10000 [5:15:53<1:45:36,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7300 / 10000 | Loss: 0.7475038170814514, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  73%|████████████████████████████████████████▎              | 7325/10000 [5:16:51<1:44:34,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7325 / 10000 | Loss: 0.75298672914505, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  74%|████████████████████████████████████████▍              | 7350/10000 [5:17:50<1:43:36,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7350 / 10000 | Loss: 0.8188158273696899, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  74%|████████████████████████████████████████▌              | 7375/10000 [5:18:49<1:42:31,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7375 / 10000 | Loss: 0.7962761521339417, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  74%|████████████████████████████████████████▋              | 7400/10000 [5:19:47<1:41:26,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7400 / 10000 | Loss: 0.7647857069969177, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  74%|████████████████████████████████████████▊              | 7425/10000 [5:20:46<1:40:46,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7425 / 10000 | Loss: 0.7773386836051941, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  74%|████████████████████████████████████████▉              | 7450/10000 [5:21:44<1:39:44,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7450 / 10000 | Loss: 0.806819498538971, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  75%|█████████████████████████████████████████              | 7475/10000 [5:22:43<1:38:44,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7475 / 10000 | Loss: 0.7801212072372437, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  75%|█████████████████████████████████████████▎             | 7500/10000 [5:23:42<1:37:42,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7500 / 10000 | Loss: 1.000954270362854, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  75%|█████████████████████████████████████████▍             | 7525/10000 [5:24:40<1:36:48,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7525 / 10000 | Loss: 0.8899285793304443, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  76%|█████████████████████████████████████████▌             | 7550/10000 [5:25:39<1:35:44,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7550 / 10000 | Loss: 0.7257997393608093, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  76%|█████████████████████████████████████████▋             | 7575/10000 [5:26:37<1:34:48,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7575 / 10000 | Loss: 0.7184075117111206, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  76%|█████████████████████████████████████████▊             | 7600/10000 [5:27:36<1:33:53,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7600 / 10000 | Loss: 1.0052798986434937, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  76%|█████████████████████████████████████████▉             | 7625/10000 [5:28:35<1:32:44,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7625 / 10000 | Loss: 0.8919435739517212, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  76%|██████████████████████████████████████████             | 7650/10000 [5:29:33<1:31:42,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7650 / 10000 | Loss: 0.7824331521987915, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  77%|██████████████████████████████████████████▏            | 7675/10000 [5:30:32<1:30:42,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7675 / 10000 | Loss: 0.77376389503479, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  77%|██████████████████████████████████████████▎            | 7700/10000 [5:31:31<1:29:59,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7700 / 10000 | Loss: 0.7612375617027283, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  77%|██████████████████████████████████████████▍            | 7725/10000 [5:32:29<1:28:52,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7725 / 10000 | Loss: 0.8093616366386414, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  78%|██████████████████████████████████████████▋            | 7750/10000 [5:33:28<1:28:00,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7750 / 10000 | Loss: 0.7551229596138, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  78%|██████████████████████████████████████████▊            | 7775/10000 [5:34:26<1:27:02,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7775 / 10000 | Loss: 0.8213188648223877, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  78%|██████████████████████████████████████████▉            | 7800/10000 [5:35:25<1:25:55,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7800 / 10000 | Loss: 0.7786438465118408, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  78%|███████████████████████████████████████████            | 7825/10000 [5:37:26<1:26:01,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7825 / 10000 | Loss: 0.7288559079170227, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  78%|███████████████████████████████████████████▏           | 7850/10000 [5:38:25<1:24:04,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7850 / 10000 | Loss: 0.7679166793823242, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  79%|███████████████████████████████████████████▎           | 7875/10000 [5:39:24<1:23:19,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7875 / 10000 | Loss: 0.7232886552810669, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  79%|███████████████████████████████████████████▍           | 7900/10000 [5:40:23<1:22:19,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7900 / 10000 | Loss: 0.7563900351524353, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  79%|███████████████████████████████████████████▌           | 7925/10000 [5:41:22<1:21:20,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7925 / 10000 | Loss: 0.7102510333061218, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  80%|███████████████████████████████████████████▋           | 7950/10000 [5:42:21<1:20:27,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7950 / 10000 | Loss: 0.746153712272644, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  80%|███████████████████████████████████████████▊           | 7975/10000 [5:43:20<1:19:20,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (7975 / 10000 | Loss: 0.7915511727333069, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  80%|████████████████████████████████████████████           | 8000/10000 [5:44:18<1:18:25,  2.35s/it]02/04/2024 16:15:27 - INFO - accelerate.accelerator - Saving current state to ./result_distiling\\checkpoint-8000-epoch-8\n",
      "02/04/2024 16:15:27 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8000 / 10000 | Loss: 0.751891016960144, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/04/2024 16:15:28 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-8000-epoch-8\\model.safetensors\n",
      "02/04/2024 16:15:28 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n",
      "02/04/2024 16:15:29 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-8000-epoch-8\\model_1.safetensors\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Optimizer state saved in result_distiling\\checkpoint-8000-epoch-8\\optimizer.bin\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Scheduler state saved in result_distiling\\checkpoint-8000-epoch-8\\scheduler.bin\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in result_distiling\\checkpoint-8000-epoch-8\\sampler.bin\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Sampler state for dataloader 1 saved in result_distiling\\checkpoint-8000-epoch-8\\sampler_1.bin\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Sampler state for dataloader 2 saved in result_distiling\\checkpoint-8000-epoch-8\\sampler_2.bin\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Sampler state for dataloader 3 saved in result_distiling\\checkpoint-8000-epoch-8\\sampler_3.bin\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Sampler state for dataloader 4 saved in result_distiling\\checkpoint-8000-epoch-8\\sampler_4.bin\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Sampler state for dataloader 5 saved in result_distiling\\checkpoint-8000-epoch-8\\sampler_5.bin\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Sampler state for dataloader 6 saved in result_distiling\\checkpoint-8000-epoch-8\\sampler_6.bin\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Sampler state for dataloader 7 saved in result_distiling\\checkpoint-8000-epoch-8\\sampler_7.bin\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Sampler state for dataloader 8 saved in result_distiling\\checkpoint-8000-epoch-8\\sampler_8.bin\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Sampler state for dataloader 9 saved in result_distiling\\checkpoint-8000-epoch-8\\sampler_9.bin\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Sampler state for dataloader 10 saved in result_distiling\\checkpoint-8000-epoch-8\\sampler_10.bin\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Sampler state for dataloader 11 saved in result_distiling\\checkpoint-8000-epoch-8\\sampler_11.bin\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Sampler state for dataloader 12 saved in result_distiling\\checkpoint-8000-epoch-8\\sampler_12.bin\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Sampler state for dataloader 13 saved in result_distiling\\checkpoint-8000-epoch-8\\sampler_13.bin\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Sampler state for dataloader 14 saved in result_distiling\\checkpoint-8000-epoch-8\\sampler_14.bin\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Sampler state for dataloader 15 saved in result_distiling\\checkpoint-8000-epoch-8\\sampler_15.bin\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Gradient scaler state saved in result_distiling\\checkpoint-8000-epoch-8\\scaler.pt\n",
      "02/04/2024 16:15:30 - INFO - accelerate.checkpointing - Random states saved in result_distiling\\checkpoint-8000-epoch-8\\random_states_0.pkl\n",
      "02/04/2024 16:15:30 - INFO - run_distillation - Deleting older checkpoint [result_distiling\\checkpoint-5000-epoch-5] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Evaluating eval...:   0%|                                                                       | 0/81 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   1%|▊                                                              | 1/81 [00:19<26:13, 19.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   2%|█▌                                                             | 2/81 [00:21<12:22,  9.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   4%|██▎                                                            | 3/81 [00:23<07:49,  6.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   5%|███                                                            | 4/81 [00:25<05:41,  4.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   6%|███▉                                                           | 5/81 [00:27<04:30,  3.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   7%|████▋                                                          | 6/81 [00:29<03:48,  3.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   9%|█████▍                                                         | 7/81 [00:31<03:20,  2.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  10%|██████▏                                                        | 8/81 [00:33<03:01,  2.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  11%|███████                                                        | 9/81 [00:36<02:49,  2.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  12%|███████▋                                                      | 10/81 [00:38<02:39,  2.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  14%|████████▍                                                     | 11/81 [00:40<02:33,  2.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  15%|█████████▏                                                    | 12/81 [00:42<02:28,  2.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  16%|█████████▉                                                    | 13/81 [00:44<02:24,  2.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  17%|██████████▋                                                   | 14/81 [00:46<02:20,  2.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  19%|███████████▍                                                  | 15/81 [00:48<02:17,  2.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  20%|████████████▏                                                 | 16/81 [00:50<02:14,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  21%|█████████████                                                 | 17/81 [00:52<02:12,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  22%|█████████████▊                                                | 18/81 [00:54<02:10,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  23%|██████████████▌                                               | 19/81 [00:56<02:07,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  25%|███████████████▎                                              | 20/81 [00:58<02:05,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  26%|████████████████                                              | 21/81 [01:00<02:03,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  27%|████████████████▊                                             | 22/81 [01:02<02:01,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  28%|█████████████████▌                                            | 23/81 [01:04<01:59,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  30%|██████████████████▎                                           | 24/81 [01:06<01:57,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  31%|███████████████████▏                                          | 25/81 [01:08<01:55,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  32%|███████████████████▉                                          | 26/81 [01:10<01:52,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  33%|████████████████████▋                                         | 27/81 [01:12<01:50,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  35%|█████████████████████▍                                        | 28/81 [01:15<01:48,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  36%|██████████████████████▏                                       | 29/81 [01:17<01:46,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  37%|██████████████████████▉                                       | 30/81 [01:19<01:44,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  38%|███████████████████████▋                                      | 31/81 [01:21<01:42,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  40%|████████████████████████▍                                     | 32/81 [01:23<01:40,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  41%|█████████████████████████▎                                    | 33/81 [01:25<01:38,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  42%|██████████████████████████                                    | 34/81 [01:27<01:36,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  43%|██████████████████████████▊                                   | 35/81 [01:29<01:34,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  44%|███████████████████████████▌                                  | 36/81 [01:31<01:32,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  46%|████████████████████████████▎                                 | 37/81 [01:33<01:30,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  47%|█████████████████████████████                                 | 38/81 [01:35<01:28,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  48%|█████████████████████████████▊                                | 39/81 [01:37<01:26,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  49%|██████████████████████████████▌                               | 40/81 [01:39<01:24,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  51%|███████████████████████████████▍                              | 41/81 [01:41<01:22,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  52%|████████████████████████████████▏                             | 42/81 [01:43<01:20,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  53%|████████████████████████████████▉                             | 43/81 [01:45<01:18,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  54%|█████████████████████████████████▋                            | 44/81 [01:47<01:16,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  56%|██████████████████████████████████▍                           | 45/81 [01:49<01:14,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  57%|███████████████████████████████████▏                          | 46/81 [01:52<01:11,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  58%|███████████████████████████████████▉                          | 47/81 [01:54<01:10,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  59%|████████████████████████████████████▋                         | 48/81 [01:56<01:08,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  60%|█████████████████████████████████████▌                        | 49/81 [01:58<01:05,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  62%|██████████████████████████████████████▎                       | 50/81 [02:00<01:03,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  63%|███████████████████████████████████████                       | 51/81 [02:02<01:01,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  64%|███████████████████████████████████████▊                      | 52/81 [02:04<00:59,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  65%|████████████████████████████████████████▌                     | 53/81 [02:06<00:57,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  67%|█████████████████████████████████████████▎                    | 54/81 [02:08<00:55,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  68%|██████████████████████████████████████████                    | 55/81 [02:10<00:53,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  69%|██████████████████████████████████████████▊                   | 56/81 [02:12<00:51,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  70%|███████████████████████████████████████████▋                  | 57/81 [02:14<00:49,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  72%|████████████████████████████████████████████▍                 | 58/81 [02:16<00:47,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  73%|█████████████████████████████████████████████▏                | 59/81 [02:18<00:45,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  74%|█████████████████████████████████████████████▉                | 60/81 [02:20<00:43,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  75%|██████████████████████████████████████████████▋               | 61/81 [02:22<00:41,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  77%|███████████████████████████████████████████████▍              | 62/81 [02:25<00:39,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  78%|████████████████████████████████████████████████▏             | 63/81 [02:27<00:37,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  79%|████████████████████████████████████████████████▉             | 64/81 [02:29<00:35,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  80%|█████████████████████████████████████████████████▊            | 65/81 [02:31<00:33,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  81%|██████████████████████████████████████████████████▌           | 66/81 [02:33<00:30,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  83%|███████████████████████████████████████████████████▎          | 67/81 [02:35<00:28,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  84%|████████████████████████████████████████████████████          | 68/81 [02:37<00:26,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  85%|████████████████████████████████████████████████████▊         | 69/81 [02:39<00:24,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  86%|█████████████████████████████████████████████████████▌        | 70/81 [02:41<00:22,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  88%|██████████████████████████████████████████████████████▎       | 71/81 [02:43<00:20,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  89%|███████████████████████████████████████████████████████       | 72/81 [02:45<00:18,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  90%|███████████████████████████████████████████████████████▉      | 73/81 [02:47<00:16,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  91%|████████████████████████████████████████████████████████▋     | 74/81 [02:49<00:14,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  93%|█████████████████████████████████████████████████████████▍    | 75/81 [02:51<00:12,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  94%|██████████████████████████████████████████████████████████▏   | 76/81 [02:53<00:10,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  95%|██████████████████████████████████████████████████████████▉   | 77/81 [02:56<00:08,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  96%|███████████████████████████████████████████████████████████▋  | 78/81 [02:58<00:06,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  98%|████████████████████████████████████████████████████████████▍ | 79/81 [03:00<00:04,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  99%|█████████████████████████████████████████████████████████████▏| 80/81 [03:02<00:02,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...: 100%|██████████████████████████████████████████████████████████████| 81/81 [03:05<00:00,  2.28s/it]\u001b[A\u001b[A\n",
      "Train steps ... :  80%|████████████████████████████████████████████           | 8000/10000 [5:47:27<1:18:25,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval results for step (8000 / 10000 | Eval Loss: 16.696014404296875 | )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  80%|████████████████████████████████████████████▏          | 8025/10000 [5:48:26<1:17:42,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8025 / 10000 | Loss: 0.6936849355697632, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  80%|████████████████████████████████████████████▎          | 8050/10000 [5:49:25<1:16:18,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8050 / 10000 | Loss: 0.6942686438560486, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  81%|████████████████████████████████████████████▍          | 8075/10000 [5:50:24<1:15:23,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8075 / 10000 | Loss: 0.722148597240448, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  81%|████████████████████████████████████████████▌          | 8100/10000 [5:51:22<1:14:22,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8100 / 10000 | Loss: 0.7412663698196411, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  81%|████████████████████████████████████████████▋          | 8125/10000 [5:52:21<1:13:32,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8125 / 10000 | Loss: 0.7084075808525085, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  82%|████████████████████████████████████████████▊          | 8150/10000 [5:53:20<1:12:19,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8150 / 10000 | Loss: 0.7763449549674988, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  82%|████████████████████████████████████████████▉          | 8175/10000 [5:54:19<1:11:23,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8175 / 10000 | Loss: 0.7256192564964294, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  82%|█████████████████████████████████████████████          | 8200/10000 [5:55:17<1:10:13,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8200 / 10000 | Loss: 0.7164705395698547, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  82%|█████████████████████████████████████████████▏         | 8225/10000 [5:56:16<1:09:25,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8225 / 10000 | Loss: 0.687846302986145, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  82%|█████████████████████████████████████████████▍         | 8250/10000 [5:57:14<1:08:20,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8250 / 10000 | Loss: 0.713402271270752, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  83%|█████████████████████████████████████████████▌         | 8275/10000 [5:58:13<1:07:20,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8275 / 10000 | Loss: 0.6880909204483032, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  83%|█████████████████████████████████████████████▋         | 8300/10000 [5:59:12<1:06:23,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8300 / 10000 | Loss: 0.7639225125312805, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  83%|█████████████████████████████████████████████▊         | 8325/10000 [6:00:11<1:06:16,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8325 / 10000 | Loss: 0.7607693076133728, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  84%|█████████████████████████████████████████████▉         | 8350/10000 [6:01:11<1:07:57,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8350 / 10000 | Loss: 0.6414285898208618, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  84%|██████████████████████████████████████████████         | 8375/10000 [6:02:11<1:05:02,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8375 / 10000 | Loss: 0.7546856999397278, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  84%|██████████████████████████████████████████████▏        | 8400/10000 [6:03:11<1:03:58,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8400 / 10000 | Loss: 0.7719925045967102, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  84%|██████████████████████████████████████████████▎        | 8425/10000 [6:04:11<1:03:08,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8425 / 10000 | Loss: 0.6899296045303345, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  84%|██████████████████████████████████████████████▍        | 8450/10000 [6:05:11<1:02:00,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8450 / 10000 | Loss: 0.7327277660369873, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  85%|██████████████████████████████████████████████▌        | 8475/10000 [6:06:11<1:01:02,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8475 / 10000 | Loss: 0.7713548541069031, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  85%|██████████████████████████████████████████████▊        | 8500/10000 [6:07:11<1:00:00,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8500 / 10000 | Loss: 0.6402847170829773, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  85%|████████████████████████████████████████████████▌        | 8525/10000 [6:08:11<58:59,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8525 / 10000 | Loss: 0.725202739238739, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  86%|████████████████████████████████████████████████▋        | 8550/10000 [6:09:11<57:52,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8550 / 10000 | Loss: 0.7236497402191162, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  86%|████████████████████████████████████████████████▉        | 8575/10000 [6:10:11<56:48,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8575 / 10000 | Loss: 0.8249596953392029, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  86%|█████████████████████████████████████████████████        | 8600/10000 [6:11:11<55:55,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8600 / 10000 | Loss: 0.7302780747413635, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  86%|█████████████████████████████████████████████████▏       | 8625/10000 [6:12:11<54:58,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8625 / 10000 | Loss: 0.7324738502502441, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  86%|█████████████████████████████████████████████████▎       | 8650/10000 [6:13:11<53:53,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8650 / 10000 | Loss: 0.7788748145103455, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  87%|█████████████████████████████████████████████████▍       | 8675/10000 [6:14:11<52:53,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8675 / 10000 | Loss: 0.8059096932411194, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  87%|█████████████████████████████████████████████████▌       | 8700/10000 [6:15:10<51:51,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8700 / 10000 | Loss: 0.7085276246070862, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  87%|█████████████████████████████████████████████████▋       | 8725/10000 [6:16:10<50:58,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8725 / 10000 | Loss: 0.7586166858673096, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  88%|█████████████████████████████████████████████████▉       | 8750/10000 [6:17:09<48:37,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8750 / 10000 | Loss: 0.8495801687240601, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  88%|██████████████████████████████████████████████████       | 8775/10000 [6:18:08<47:46,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8775 / 10000 | Loss: 0.7590239644050598, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  88%|██████████████████████████████████████████████████▏      | 8800/10000 [6:19:56<47:36,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8800 / 10000 | Loss: 0.6569372415542603, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  88%|██████████████████████████████████████████████████▎      | 8825/10000 [6:20:54<45:31,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8825 / 10000 | Loss: 0.7021905183792114, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  88%|██████████████████████████████████████████████████▍      | 8850/10000 [6:21:53<44:44,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8850 / 10000 | Loss: 0.6403361558914185, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  89%|██████████████████████████████████████████████████▌      | 8875/10000 [6:22:51<43:50,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8875 / 10000 | Loss: 0.8018456697463989, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  89%|██████████████████████████████████████████████████▋      | 8900/10000 [6:23:49<42:46,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8900 / 10000 | Loss: 0.6483400464057922, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  89%|██████████████████████████████████████████████████▊      | 8925/10000 [6:24:48<41:52,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8925 / 10000 | Loss: 0.6501366496086121, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  90%|███████████████████████████████████████████████████      | 8950/10000 [6:25:46<40:53,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8950 / 10000 | Loss: 0.6841417551040649, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  90%|███████████████████████████████████████████████████▏     | 8975/10000 [6:26:45<39:51,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (8975 / 10000 | Loss: 0.6807866096496582, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  90%|███████████████████████████████████████████████████▎     | 9000/10000 [6:27:43<38:58,  2.34s/it]02/04/2024 16:58:52 - INFO - accelerate.accelerator - Saving current state to ./result_distiling\\checkpoint-9000-epoch-9\n",
      "02/04/2024 16:58:52 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9000 / 10000 | Loss: 0.6444998383522034, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/04/2024 16:58:53 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-9000-epoch-9\\model.safetensors\n",
      "02/04/2024 16:58:53 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n",
      "02/04/2024 16:58:54 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-9000-epoch-9\\model_1.safetensors\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Optimizer state saved in result_distiling\\checkpoint-9000-epoch-9\\optimizer.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Scheduler state saved in result_distiling\\checkpoint-9000-epoch-9\\scheduler.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in result_distiling\\checkpoint-9000-epoch-9\\sampler.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 1 saved in result_distiling\\checkpoint-9000-epoch-9\\sampler_1.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 2 saved in result_distiling\\checkpoint-9000-epoch-9\\sampler_2.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 3 saved in result_distiling\\checkpoint-9000-epoch-9\\sampler_3.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 4 saved in result_distiling\\checkpoint-9000-epoch-9\\sampler_4.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 5 saved in result_distiling\\checkpoint-9000-epoch-9\\sampler_5.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 6 saved in result_distiling\\checkpoint-9000-epoch-9\\sampler_6.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 7 saved in result_distiling\\checkpoint-9000-epoch-9\\sampler_7.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 8 saved in result_distiling\\checkpoint-9000-epoch-9\\sampler_8.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 9 saved in result_distiling\\checkpoint-9000-epoch-9\\sampler_9.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 10 saved in result_distiling\\checkpoint-9000-epoch-9\\sampler_10.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 11 saved in result_distiling\\checkpoint-9000-epoch-9\\sampler_11.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 12 saved in result_distiling\\checkpoint-9000-epoch-9\\sampler_12.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 13 saved in result_distiling\\checkpoint-9000-epoch-9\\sampler_13.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 14 saved in result_distiling\\checkpoint-9000-epoch-9\\sampler_14.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 15 saved in result_distiling\\checkpoint-9000-epoch-9\\sampler_15.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 16 saved in result_distiling\\checkpoint-9000-epoch-9\\sampler_16.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 17 saved in result_distiling\\checkpoint-9000-epoch-9\\sampler_17.bin\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Gradient scaler state saved in result_distiling\\checkpoint-9000-epoch-9\\scaler.pt\n",
      "02/04/2024 16:58:55 - INFO - accelerate.checkpointing - Random states saved in result_distiling\\checkpoint-9000-epoch-9\\random_states_0.pkl\n",
      "02/04/2024 16:58:55 - INFO - run_distillation - Deleting older checkpoint [result_distiling\\checkpoint-6000-epoch-6] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Evaluating eval...:   0%|                                                                       | 0/81 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   1%|▊                                                              | 1/81 [00:20<26:59, 20.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   2%|█▌                                                             | 2/81 [00:22<12:44,  9.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   4%|██▎                                                            | 3/81 [00:24<08:00,  6.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   5%|███                                                            | 4/81 [00:26<05:48,  4.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   6%|███▉                                                           | 5/81 [00:28<04:34,  3.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   7%|████▋                                                          | 6/81 [00:30<03:50,  3.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   9%|█████▍                                                         | 7/81 [00:32<03:21,  2.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  10%|██████▏                                                        | 8/81 [00:34<03:02,  2.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  11%|███████                                                        | 9/81 [00:36<02:49,  2.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  12%|███████▋                                                      | 10/81 [00:38<02:39,  2.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  14%|████████▍                                                     | 11/81 [00:40<02:32,  2.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  15%|█████████▏                                                    | 12/81 [00:42<02:26,  2.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  16%|█████████▉                                                    | 13/81 [00:44<02:22,  2.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  17%|██████████▋                                                   | 14/81 [00:46<02:18,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  19%|███████████▍                                                  | 15/81 [00:48<02:16,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  20%|████████████▏                                                 | 16/81 [00:50<02:13,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  21%|█████████████                                                 | 17/81 [00:52<02:11,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  22%|█████████████▊                                                | 18/81 [00:54<02:08,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  23%|██████████████▌                                               | 19/81 [00:56<02:06,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  25%|███████████████▎                                              | 20/81 [00:58<02:04,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  26%|████████████████                                              | 21/81 [01:00<02:02,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  27%|████████████████▊                                             | 22/81 [01:02<02:00,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  28%|█████████████████▌                                            | 23/81 [01:05<01:58,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  30%|██████████████████▎                                           | 24/81 [01:07<01:56,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  31%|███████████████████▏                                          | 25/81 [01:09<01:54,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  32%|███████████████████▉                                          | 26/81 [01:11<01:52,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  33%|████████████████████▋                                         | 27/81 [01:13<01:50,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  35%|█████████████████████▍                                        | 28/81 [01:15<01:48,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  36%|██████████████████████▏                                       | 29/81 [01:17<01:46,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  37%|██████████████████████▉                                       | 30/81 [01:19<01:44,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  38%|███████████████████████▋                                      | 31/81 [01:21<01:41,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  40%|████████████████████████▍                                     | 32/81 [01:23<01:39,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  41%|█████████████████████████▎                                    | 33/81 [01:25<01:37,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  42%|██████████████████████████                                    | 34/81 [01:27<01:35,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  43%|██████████████████████████▊                                   | 35/81 [01:29<01:34,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  44%|███████████████████████████▌                                  | 36/81 [01:31<01:31,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  46%|████████████████████████████▎                                 | 37/81 [01:33<01:30,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  47%|█████████████████████████████                                 | 38/81 [01:35<01:27,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  48%|█████████████████████████████▊                                | 39/81 [01:37<01:25,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  49%|██████████████████████████████▌                               | 40/81 [01:39<01:23,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  51%|███████████████████████████████▍                              | 41/81 [01:41<01:21,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  52%|████████████████████████████████▏                             | 42/81 [01:43<01:19,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  53%|████████████████████████████████▉                             | 43/81 [01:45<01:17,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  54%|█████████████████████████████████▋                            | 44/81 [01:47<01:15,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  56%|██████████████████████████████████▍                           | 45/81 [01:49<01:13,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  57%|███████████████████████████████████▏                          | 46/81 [01:52<01:11,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  58%|███████████████████████████████████▉                          | 47/81 [01:54<01:09,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  59%|████████████████████████████████████▋                         | 48/81 [01:56<01:07,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  60%|█████████████████████████████████████▌                        | 49/81 [01:58<01:05,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  62%|██████████████████████████████████████▎                       | 50/81 [02:00<01:03,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  63%|███████████████████████████████████████                       | 51/81 [02:02<01:01,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  64%|███████████████████████████████████████▊                      | 52/81 [02:04<00:59,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  65%|████████████████████████████████████████▌                     | 53/81 [02:06<00:57,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  67%|█████████████████████████████████████████▎                    | 54/81 [02:08<00:55,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  68%|██████████████████████████████████████████                    | 55/81 [02:10<00:53,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  69%|██████████████████████████████████████████▊                   | 56/81 [02:12<00:51,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  70%|███████████████████████████████████████████▋                  | 57/81 [02:14<00:49,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  72%|████████████████████████████████████████████▍                 | 58/81 [02:16<00:47,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  73%|█████████████████████████████████████████████▏                | 59/81 [02:18<00:45,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  74%|█████████████████████████████████████████████▉                | 60/81 [02:20<00:43,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  75%|██████████████████████████████████████████████▋               | 61/81 [02:22<00:40,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  77%|███████████████████████████████████████████████▍              | 62/81 [02:24<00:38,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  78%|████████████████████████████████████████████████▏             | 63/81 [02:26<00:36,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  79%|████████████████████████████████████████████████▉             | 64/81 [02:28<00:34,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  80%|█████████████████████████████████████████████████▊            | 65/81 [02:30<00:32,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  81%|██████████████████████████████████████████████████▌           | 66/81 [02:32<00:30,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  83%|███████████████████████████████████████████████████▎          | 67/81 [02:35<00:28,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  84%|████████████████████████████████████████████████████          | 68/81 [02:37<00:26,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  85%|████████████████████████████████████████████████████▊         | 69/81 [02:39<00:24,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  86%|█████████████████████████████████████████████████████▌        | 70/81 [02:41<00:22,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  88%|██████████████████████████████████████████████████████▎       | 71/81 [02:43<00:20,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  89%|███████████████████████████████████████████████████████       | 72/81 [02:45<00:18,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  90%|███████████████████████████████████████████████████████▉      | 73/81 [02:47<00:16,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  91%|████████████████████████████████████████████████████████▋     | 74/81 [02:49<00:14,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  93%|█████████████████████████████████████████████████████████▍    | 75/81 [02:51<00:12,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  94%|██████████████████████████████████████████████████████████▏   | 76/81 [02:53<00:10,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  95%|██████████████████████████████████████████████████████████▉   | 77/81 [02:55<00:08,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  96%|███████████████████████████████████████████████████████████▋  | 78/81 [02:57<00:06,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  98%|████████████████████████████████████████████████████████████▍ | 79/81 [02:59<00:04,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  99%|█████████████████████████████████████████████████████████████▏| 80/81 [03:01<00:02,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...: 100%|██████████████████████████████████████████████████████████████| 81/81 [03:04<00:00,  2.28s/it]\u001b[A\u001b[A\n",
      "Train steps ... :  90%|███████████████████████████████████████████████████▎     | 9000/10000 [6:30:52<38:58,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval results for step (9000 / 10000 | Eval Loss: 16.791120529174805 | )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  90%|███████████████████████████████████████████████████▍     | 9025/10000 [6:31:50<38:09,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9025 / 10000 | Loss: 0.688440203666687, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  90%|███████████████████████████████████████████████████▌     | 9050/10000 [6:32:49<36:55,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9050 / 10000 | Loss: 0.712874174118042, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  91%|███████████████████████████████████████████████████▋     | 9075/10000 [6:33:47<35:57,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9075 / 10000 | Loss: 0.6362898945808411, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  91%|███████████████████████████████████████████████████▊     | 9100/10000 [6:34:45<35:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9100 / 10000 | Loss: 0.652896523475647, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  91%|████████████████████████████████████████████████████     | 9125/10000 [6:35:44<34:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9125 / 10000 | Loss: 0.6809937953948975, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  92%|████████████████████████████████████████████████████▏    | 9150/10000 [6:36:42<32:59,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9150 / 10000 | Loss: 0.7148226499557495, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  92%|████████████████████████████████████████████████████▎    | 9175/10000 [6:37:40<32:06,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9175 / 10000 | Loss: 0.6862367987632751, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  92%|████████████████████████████████████████████████████▍    | 9200/10000 [6:38:41<31:52,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9200 / 10000 | Loss: 0.6542056202888489, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  92%|████████████████████████████████████████████████████▌    | 9225/10000 [6:39:41<30:52,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9225 / 10000 | Loss: 0.7430133819580078, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  92%|████████████████████████████████████████████████████▋    | 9250/10000 [6:40:41<29:51,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9250 / 10000 | Loss: 0.612546980381012, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  93%|████████████████████████████████████████████████████▊    | 9275/10000 [6:41:40<28:55,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9275 / 10000 | Loss: 0.6911808252334595, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  93%|█████████████████████████████████████████████████████    | 9300/10000 [6:42:40<27:54,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9300 / 10000 | Loss: 0.647619903087616, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  93%|█████████████████████████████████████████████████████▏   | 9325/10000 [6:43:40<26:52,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9325 / 10000 | Loss: 0.657987654209137, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  94%|█████████████████████████████████████████████████████▎   | 9350/10000 [6:44:40<25:49,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9350 / 10000 | Loss: 0.6368395686149597, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  94%|█████████████████████████████████████████████████████▍   | 9375/10000 [6:45:39<24:50,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9375 / 10000 | Loss: 0.6398841142654419, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  94%|█████████████████████████████████████████████████████▌   | 9400/10000 [6:46:39<23:51,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9400 / 10000 | Loss: 0.6389195919036865, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  94%|█████████████████████████████████████████████████████▋   | 9425/10000 [6:47:39<22:53,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9425 / 10000 | Loss: 0.6177122592926025, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  94%|█████████████████████████████████████████████████████▊   | 9450/10000 [6:48:39<21:53,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9450 / 10000 | Loss: 0.6439050436019897, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  95%|██████████████████████████████████████████████████████   | 9475/10000 [6:49:38<20:53,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9475 / 10000 | Loss: 0.7332008481025696, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  95%|██████████████████████████████████████████████████████▏  | 9500/10000 [6:50:37<19:35,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9500 / 10000 | Loss: 0.6034331321716309, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  95%|██████████████████████████████████████████████████████▎  | 9525/10000 [6:51:36<18:35,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9525 / 10000 | Loss: 0.6398487091064453, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  96%|██████████████████████████████████████████████████████▍  | 9550/10000 [6:52:35<17:34,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9550 / 10000 | Loss: 0.7713631987571716, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  96%|██████████████████████████████████████████████████████▌  | 9575/10000 [6:53:33<16:31,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9575 / 10000 | Loss: 0.7577720284461975, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  96%|██████████████████████████████████████████████████████▋  | 9600/10000 [6:54:32<15:34,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9600 / 10000 | Loss: 0.6609716415405273, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  96%|██████████████████████████████████████████████████████▊  | 9625/10000 [6:55:30<14:34,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9625 / 10000 | Loss: 0.6650068759918213, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  96%|███████████████████████████████████████████████████████  | 9650/10000 [6:56:28<13:35,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9650 / 10000 | Loss: 0.7432970404624939, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  97%|███████████████████████████████████████████████████████▏ | 9675/10000 [6:57:27<12:37,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9675 / 10000 | Loss: 0.7329119443893433, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  97%|███████████████████████████████████████████████████████▎ | 9700/10000 [6:58:25<11:39,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9700 / 10000 | Loss: 0.6956475973129272, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  97%|███████████████████████████████████████████████████████▍ | 9725/10000 [6:59:23<10:41,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9725 / 10000 | Loss: 0.729266881942749, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  98%|███████████████████████████████████████████████████████▌ | 9750/10000 [7:00:21<09:42,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9750 / 10000 | Loss: 0.6543254852294922, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  98%|███████████████████████████████████████████████████████▋ | 9775/10000 [7:02:10<09:00,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9775 / 10000 | Loss: 0.6326680183410645, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  98%|███████████████████████████████████████████████████████▊ | 9800/10000 [7:03:08<07:44,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9800 / 10000 | Loss: 0.6216059327125549, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  98%|████████████████████████████████████████████████████████ | 9825/10000 [7:04:06<06:47,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9825 / 10000 | Loss: 0.6225340366363525, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  98%|████████████████████████████████████████████████████████▏| 9850/10000 [7:05:05<05:48,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9850 / 10000 | Loss: 0.8914443850517273, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  99%|████████████████████████████████████████████████████████▎| 9875/10000 [7:06:03<04:51,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9875 / 10000 | Loss: 0.5823811292648315, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  99%|████████████████████████████████████████████████████████▍| 9900/10000 [7:07:01<03:52,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9900 / 10000 | Loss: 0.7284350991249084, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... :  99%|████████████████████████████████████████████████████████▌| 9925/10000 [7:07:59<02:54,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9925 / 10000 | Loss: 0.672045886516571, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... : 100%|████████████████████████████████████████████████████████▋| 9950/10000 [7:08:58<01:56,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9950 / 10000 | Loss: 0.6660736799240112, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... : 100%|████████████████████████████████████████████████████████▊| 9975/10000 [7:09:56<00:58,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (9975 / 10000 | Loss: 0.6229323148727417, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train steps ... : 100%|████████████████████████████████████████████████████████| 10000/10000 [7:10:54<00:00,  2.33s/it]02/04/2024 17:42:03 - INFO - accelerate.accelerator - Saving current state to ./result_distiling\\checkpoint-10000-epoch-10\n",
      "02/04/2024 17:42:03 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step... (10000 / 10000 | Loss: 0.6160104274749756, Learning Rate: 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/04/2024 17:42:04 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-10000-epoch-10\\model.safetensors\n",
      "02/04/2024 17:42:04 - WARNING - accelerate.utils.other - Removed shared tensor {'proj_out.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n",
      "02/04/2024 17:42:05 - INFO - accelerate.checkpointing - Model weights saved in result_distiling\\checkpoint-10000-epoch-10\\model_1.safetensors\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Optimizer state saved in result_distiling\\checkpoint-10000-epoch-10\\optimizer.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Scheduler state saved in result_distiling\\checkpoint-10000-epoch-10\\scheduler.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 1 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler_1.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 2 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler_2.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 3 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler_3.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 4 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler_4.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 5 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler_5.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 6 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler_6.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 7 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler_7.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 8 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler_8.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 9 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler_9.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 10 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler_10.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 11 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler_11.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 12 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler_12.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 13 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler_13.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 14 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler_14.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 15 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler_15.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 16 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler_16.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 17 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler_17.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 18 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler_18.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 19 saved in result_distiling\\checkpoint-10000-epoch-10\\sampler_19.bin\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Gradient scaler state saved in result_distiling\\checkpoint-10000-epoch-10\\scaler.pt\n",
      "02/04/2024 17:42:06 - INFO - accelerate.checkpointing - Random states saved in result_distiling\\checkpoint-10000-epoch-10\\random_states_0.pkl\n",
      "02/04/2024 17:42:06 - INFO - run_distillation - Deleting older checkpoint [result_distiling\\checkpoint-7000-epoch-7] due to args.save_total_limit\n",
      "Configuration saved in ./result_distiling\\config.json\n",
      "Configuration saved in ./result_distiling\\generation_config.json\n",
      "Model weights saved in ./result_distiling\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Evaluating eval...:   0%|                                                                       | 0/81 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   1%|▊                                                              | 1/81 [00:20<27:25, 20.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   2%|█▌                                                             | 2/81 [00:22<12:48,  9.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   4%|██▎                                                            | 3/81 [00:24<08:02,  6.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   5%|███                                                            | 4/81 [00:26<05:49,  4.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   6%|███▉                                                           | 5/81 [00:28<04:34,  3.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   7%|████▋                                                          | 6/81 [00:30<03:50,  3.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:   9%|█████▍                                                         | 7/81 [00:32<03:21,  2.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  10%|██████▏                                                        | 8/81 [00:34<03:02,  2.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  11%|███████                                                        | 9/81 [00:36<02:49,  2.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  12%|███████▋                                                      | 10/81 [00:38<02:39,  2.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  14%|████████▍                                                     | 11/81 [00:40<02:32,  2.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  15%|█████████▏                                                    | 12/81 [00:42<02:26,  2.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  16%|█████████▉                                                    | 13/81 [00:44<02:22,  2.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  17%|██████████▋                                                   | 14/81 [00:46<02:18,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  19%|███████████▍                                                  | 15/81 [00:48<02:15,  2.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  20%|████████████▏                                                 | 16/81 [00:50<02:13,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  21%|█████████████                                                 | 17/81 [00:52<02:10,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  22%|█████████████▊                                                | 18/81 [00:54<02:08,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  23%|██████████████▌                                               | 19/81 [00:56<02:05,  2.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  25%|███████████████▎                                              | 20/81 [00:58<02:04,  2.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  26%|████████████████                                              | 21/81 [01:01<02:01,  2.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  27%|████████████████▊                                             | 22/81 [01:03<01:59,  2.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  28%|█████████████████▌                                            | 23/81 [01:05<01:57,  2.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  30%|██████████████████▎                                           | 24/81 [01:07<01:55,  2.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  31%|███████████████████▏                                          | 25/81 [01:09<01:53,  2.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  32%|███████████████████▉                                          | 26/81 [01:11<01:51,  2.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  33%|████████████████████▋                                         | 27/81 [01:13<01:49,  2.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  35%|█████████████████████▍                                        | 28/81 [01:15<01:47,  2.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  36%|██████████████████████▏                                       | 29/81 [01:17<01:45,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  37%|██████████████████████▉                                       | 30/81 [01:19<01:43,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  38%|███████████████████████▋                                      | 31/81 [01:21<01:41,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  40%|████████████████████████▍                                     | 32/81 [01:23<01:39,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  41%|█████████████████████████▎                                    | 33/81 [01:25<01:37,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  42%|██████████████████████████                                    | 34/81 [01:27<01:35,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  43%|██████████████████████████▊                                   | 35/81 [01:29<01:33,  2.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  44%|███████████████████████████▌                                  | 36/81 [01:31<01:31,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  46%|████████████████████████████▎                                 | 37/81 [01:33<01:29,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  47%|█████████████████████████████                                 | 38/81 [01:35<01:27,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  48%|█████████████████████████████▊                                | 39/81 [01:37<01:25,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  49%|██████████████████████████████▌                               | 40/81 [01:39<01:23,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  51%|███████████████████████████████▍                              | 41/81 [01:41<01:21,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  52%|████████████████████████████████▏                             | 42/81 [01:43<01:19,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  53%|████████████████████████████████▉                             | 43/81 [01:45<01:17,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  54%|█████████████████████████████████▋                            | 44/81 [01:47<01:15,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  56%|██████████████████████████████████▍                           | 45/81 [01:49<01:13,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  57%|███████████████████████████████████▏                          | 46/81 [01:51<01:11,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  58%|███████████████████████████████████▉                          | 47/81 [01:53<01:09,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  59%|████████████████████████████████████▋                         | 48/81 [01:55<01:07,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  60%|█████████████████████████████████████▌                        | 49/81 [01:58<01:05,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  62%|██████████████████████████████████████▎                       | 50/81 [02:00<01:03,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  63%|███████████████████████████████████████                       | 51/81 [02:02<01:01,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  64%|███████████████████████████████████████▊                      | 52/81 [02:04<00:59,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  65%|████████████████████████████████████████▌                     | 53/81 [02:06<00:57,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  67%|█████████████████████████████████████████▎                    | 54/81 [02:08<00:55,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  68%|██████████████████████████████████████████                    | 55/81 [02:10<00:53,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  69%|██████████████████████████████████████████▊                   | 56/81 [02:12<00:51,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  70%|███████████████████████████████████████████▋                  | 57/81 [02:14<00:49,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  72%|████████████████████████████████████████████▍                 | 58/81 [02:16<00:46,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  73%|█████████████████████████████████████████████▏                | 59/81 [02:18<00:44,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  74%|█████████████████████████████████████████████▉                | 60/81 [02:20<00:42,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  75%|██████████████████████████████████████████████▋               | 61/81 [02:22<00:40,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  77%|███████████████████████████████████████████████▍              | 62/81 [02:24<00:38,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  78%|████████████████████████████████████████████████▏             | 63/81 [02:26<00:36,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  79%|████████████████████████████████████████████████▉             | 64/81 [02:28<00:34,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  80%|█████████████████████████████████████████████████▊            | 65/81 [02:30<00:32,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  81%|██████████████████████████████████████████████████▌           | 66/81 [02:32<00:30,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  83%|███████████████████████████████████████████████████▎          | 67/81 [02:34<00:28,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  84%|████████████████████████████████████████████████████          | 68/81 [02:36<00:26,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  85%|████████████████████████████████████████████████████▊         | 69/81 [02:38<00:24,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  86%|█████████████████████████████████████████████████████▌        | 70/81 [02:40<00:22,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  88%|██████████████████████████████████████████████████████▎       | 71/81 [02:42<00:20,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  89%|███████████████████████████████████████████████████████       | 72/81 [02:44<00:18,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  90%|███████████████████████████████████████████████████████▉      | 73/81 [02:47<00:16,  2.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  91%|████████████████████████████████████████████████████████▋     | 74/81 [02:49<00:14,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  93%|█████████████████████████████████████████████████████████▍    | 75/81 [02:51<00:12,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  94%|██████████████████████████████████████████████████████████▏   | 76/81 [02:53<00:10,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  95%|██████████████████████████████████████████████████████████▉   | 77/81 [02:55<00:08,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  96%|███████████████████████████████████████████████████████████▋  | 78/81 [02:57<00:06,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  98%|████████████████████████████████████████████████████████████▍ | 79/81 [02:59<00:04,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...:  99%|█████████████████████████████████████████████████████████████▏| 80/81 [03:01<00:02,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating eval...: 100%|██████████████████████████████████████████████████████████████| 81/81 [03:04<00:00,  2.27s/it]\u001b[A\u001b[A\n",
      "Train steps ... : 100%|████████████████████████████████████████████████████████| 10000/10000 [7:14:04<00:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval results for step (10000 / 10000 | Eval Loss: 16.062931060791016 | )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/ce_loss</td><td>██▆▆▅▄▃▂▂▁</td></tr><tr><td>eval/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>eval/kl_loss</td><td>▅█▆▆▅▅▃▃▃▁</td></tr><tr><td>eval/loss</td><td>▇█▆▆▅▄▃▃▃▁</td></tr><tr><td>eval/time</td><td>█▂▄▃▁▄▄▄▂▁</td></tr><tr><td>train/ce_loss</td><td>█▆▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>train/kl_loss</td><td>█▆▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/loss</td><td>█▆▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/time</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/ce_loss</td><td>10.00577</td></tr><tr><td>eval/epoch</td><td>10</td></tr><tr><td>eval/kl_loss</td><td>8.05832</td></tr><tr><td>eval/loss</td><td>16.06293</td></tr><tr><td>eval/time</td><td>184.15798</td></tr><tr><td>train/ce_loss</td><td>0.1374</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/kl_loss</td><td>0.50609</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.61601</td></tr><tr><td>train/time</td><td>24178.96756</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">grateful-moon-15</strong> at: <a href='https://wandb.ai/zekamrozek/distil-whisper/runs/49kay9oe' target=\"_blank\">https://wandb.ai/zekamrozek/distil-whisper/runs/49kay9oe</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240204_103033-49kay9oe\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(epochs_trained, num_epochs):\n",
    "    vectorized_datasets[\"train\"] = vectorized_datasets[\"train\"].shuffle(training_args.seed)\n",
    "    train_dataloader = DataLoader(\n",
    "        vectorized_datasets[\"train\"],\n",
    "        collate_fn=data_collator,\n",
    "        batch_size=per_device_train_batch_size,\n",
    "        num_workers=dataloader_num_workers,\n",
    "        pin_memory=training_args.dataloader_pin_memory,\n",
    "    )\n",
    "    train_dataloader = accelerator.prepare(train_dataloader)\n",
    "    if hasattr(train_dataloader, \"dataset\") and isinstance(train_dataloader.dataset, IterableDataset):\n",
    "        train_dataloader.dataset.set_epoch(epoch)\n",
    "\n",
    "    if resume_step is not None:\n",
    "        # Skip the first N batches in the dataloader when resuming from a checkpoint\n",
    "        train_dataloader = accelerator.skip_first_batches(train_dataloader, resume_step)\n",
    "        resume_step = None\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        with accelerator.accumulate(student_model):\n",
    "            loss, train_metric = train_step(batch, temperature=training_args.temperature)\n",
    "            accelerator.backward(loss)\n",
    "            if accelerator.sync_gradients:\n",
    "                accelerator.clip_grad_norm_(student_model.parameters(), training_args.max_grad_norm)\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Check if the accelerator has performed an optimization step behind the scenes\n",
    "        if accelerator.sync_gradients:\n",
    "            steps_trained_progress_bar.update(1)\n",
    "            cur_step += 1\n",
    "\n",
    "            if cur_step % training_args.logging_steps == 0:\n",
    "                steps_trained_progress_bar.write(\n",
    "                    f\"Step... ({cur_step} / {total_train_steps} | Loss:\"\n",
    "                    f\" {train_metric['loss']}, Learning Rate:\"\n",
    "                    f\" {lr_scheduler.get_last_lr()[0]})\"\n",
    "                )\n",
    "                log_metric(\n",
    "                    accelerator,\n",
    "                    metrics=train_metric,\n",
    "                    learning_rate=lr_scheduler.get_last_lr()[0],\n",
    "                    train_time=train_time + time.time() - train_start,\n",
    "                    step=cur_step,\n",
    "                    epoch=epoch,\n",
    "                    prefix=\"train\",\n",
    "                )\n",
    "\n",
    "            # save checkpoint and weights after each save_steps and at the end of training\n",
    "            if (cur_step % training_args.save_steps == 0) or cur_step == total_train_steps:\n",
    "                intermediate_dir = os.path.join(training_args.output_dir, f\"checkpoint-{cur_step}-epoch-{epoch}\")\n",
    "                accelerator.save_state(output_dir=intermediate_dir)\n",
    "                accelerator.wait_for_everyone()\n",
    "                if accelerator.is_main_process:\n",
    "                    rotate_checkpoints(training_args.save_total_limit, output_dir=training_args.output_dir)\n",
    "\n",
    "                    if cur_step == total_train_steps:\n",
    "                        student_model = accelerator.unwrap_model(student_model)\n",
    "                        student_model.save_pretrained(training_args.output_dir)\n",
    "\n",
    "                    if training_args.push_to_hub:\n",
    "                        repo.push_to_hub(\n",
    "                            commit_message=f\"Saving train state of step {cur_step}\",\n",
    "                            blocking=False,\n",
    "                        )\n",
    "\n",
    "            if training_args.do_eval and (cur_step % eval_steps == 0 or cur_step == total_train_steps):\n",
    "                train_time += time.time() - train_start\n",
    "                student_model.eval()\n",
    "                # ======================== Evaluating ==============================\n",
    "                for eval_split in all_eval_splits:\n",
    "                    eval_metrics = []\n",
    "                    eval_preds = []\n",
    "                    eval_labels = []\n",
    "                    eval_start = time.time()\n",
    "\n",
    "                    validation_dataloader = DataLoader(\n",
    "                        vectorized_datasets[eval_split],\n",
    "                        collate_fn=data_collator,\n",
    "                        batch_size=per_device_eval_batch_size,\n",
    "                        drop_last=False,\n",
    "                        num_workers=dataloader_num_workers,\n",
    "                        pin_memory=training_args.dataloader_pin_memory,\n",
    "                    )\n",
    "                    validation_dataloader = accelerator.prepare(validation_dataloader)\n",
    "\n",
    "                    for batch in tqdm(\n",
    "                        validation_dataloader,\n",
    "                        desc=f\"Evaluating {eval_split}...\",\n",
    "                        position=2,\n",
    "                        disable=not accelerator.is_local_main_process,\n",
    "                    ):\n",
    "                        # Model forward\n",
    "                        eval_metric = eval_step(batch)\n",
    "                        eval_metric = accelerator.gather_for_metrics(eval_metric)\n",
    "                        eval_metrics.append(eval_metric)\n",
    "\n",
    "                        # generation\n",
    "                        if training_args.predict_with_generate:\n",
    "                            generated_ids = generate_step(batch)\n",
    "                            # Gather all predictions and targets\n",
    "                            generated_ids, labels = accelerator.gather_for_metrics(\n",
    "                                (generated_ids, batch[\"labels\"])\n",
    "                            )\n",
    "                            eval_preds.extend(generated_ids)\n",
    "                            eval_labels.extend(labels)\n",
    "\n",
    "                    eval_time = time.time() - eval_start\n",
    "                    # normalize eval metrics\n",
    "                    eval_metrics = {\n",
    "                        key: torch.mean(torch.stack([d[key] for d in eval_metrics])) for key in eval_metrics[0]\n",
    "                    }\n",
    "\n",
    "                    # compute WER metric\n",
    "                    wer_desc = \"\"\n",
    "                    if training_args.predict_with_generate:\n",
    "                        wer_metric, pred_str, label_str, norm_pred_str, norm_label_str = compute_metrics(\n",
    "                            eval_preds, eval_labels\n",
    "                        )\n",
    "                        eval_metrics.update(wer_metric)\n",
    "                        wer_desc = \" \".join([f\"Eval {key}: {value} |\" for key, value in wer_metric.items()])\n",
    "                        log_pred(\n",
    "                            accelerator,\n",
    "                            pred_str,\n",
    "                            label_str,\n",
    "                            norm_pred_str,\n",
    "                            norm_label_str,\n",
    "                            step=cur_step,\n",
    "                            prefix=eval_split,\n",
    "                        )\n",
    "\n",
    "                    # Print metrics and update progress bar\n",
    "                    steps_trained_progress_bar.write(\n",
    "                        f\"Eval results for step ({cur_step} / {total_train_steps} | Eval Loss: {eval_metrics['loss']} |\"\n",
    "                        f\" {wer_desc})\"\n",
    "                    )\n",
    "\n",
    "                    log_metric(\n",
    "                        accelerator,\n",
    "                        metrics=eval_metrics,\n",
    "                        train_time=eval_time,\n",
    "                        step=cur_step,\n",
    "                        epoch=epoch,\n",
    "                        prefix=eval_split,\n",
    "                    )\n",
    "\n",
    "                # flush the train metrics\n",
    "                train_start = time.time()\n",
    "\n",
    "            # break condition\n",
    "            if cur_step == total_train_steps:\n",
    "                continue_training = False\n",
    "                break\n",
    "\n",
    "    if not continue_training:\n",
    "        break\n",
    "\n",
    "accelerator.end_training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f733de3f-ea66-4fc2-bc61-caf1c6e33ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accelerator.end_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d465b47-3dae-4eb2-90da-077f17204201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a41c8c-20e6-4ee9-8975-2e69d7a4af97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcc8967-8758-4c6b-9437-95ab254e1575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd80cfd9-8875-415f-85cf-9a2acbac0bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991385ee-f919-4068-8bb1-3b99fdcdcb26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059f0bc0-fd48-4d57-bbb8-a0f87e9e9d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28687f92-bf90-42ba-b4d7-6d33519dcdcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4b32e4-6d68-4d14-89c2-e54d13dc2eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd9d1d-d95d-41f9-9d64-9314c6ca6377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e9b8a8-fe9a-4803-8cf3-a220ca589cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5320f351-fd9d-4a0b-ab62-fc18ac0b8b54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
