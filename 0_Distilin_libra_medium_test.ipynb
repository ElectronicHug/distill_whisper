{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dp4g6lliBrLI",
    "outputId": "c90cefd7-c969-4694-8bca-e18225a39d82",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/ElectronicHug/distil-whisper.git\n",
    "# !pip install -r /content/distil-whisper/training/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oHHw0XpyBsLh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cp /content/distil-whisper/training/create_student_model.py /content/create_student_model.py\n",
    "# !cp /content/distil-whisper/training/run_pseudo_labelling.py /content/run_pseudo_labelling.py\n",
    "# !cp /content/distil-whisper/training/run_distillation.py /content/run_distillation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HrIfSoVZBtys",
    "outputId": "bfbfa883-87b8-47e6-e815-acf524ffc842",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: read).\n",
      "Your token has been saved in your configured git credential helpers (manager,store).\n",
      "Your token has been saved to C:\\Users\\Zhenya\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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', add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "90ce_YgqBvK_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import os\n",
    "# You can also adapt this script for your own pseudo-labelling tasks. Pointers for this are left as comments.\n",
    "import logging\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from accelerate import Accelerator, InitProcessGroupKwargs\n",
    "from accelerate.logging import get_logger\n",
    "from datasets import (\n",
    "    DatasetDict,\n",
    "    IterableDatasetDict,\n",
    "    load_dataset,\n",
    ")\n",
    "from huggingface_hub import HfFolder, Repository, create_repo, get_full_repo_name\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    WhisperConfig,\n",
    "    WhisperFeatureExtractor,\n",
    "    WhisperForConditionalGeneration,\n",
    "    WhisperProcessor,\n",
    "    WhisperTokenizerFast,\n",
    ")\n",
    "from transformers.models.whisper.english_normalizer import EnglishTextNormalizer, BasicTextNormalizer\n",
    "from transformers.utils import check_min_version\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "\n",
    "# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n",
    "check_min_version(\"4.34.0.dev0\")\n",
    "\n",
    "require_version(\"datasets>=2.14.6\", \"To fix: `pip install --upgrade datasets`\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FgmRr9JYByjo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ME9Ez_3IBzpk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from run_pseudo_labelling import (ModelArguments, DataTrainingArguments, shift_tokens_right,\n",
    "                                  DataCollatorSpeechSeq2SeqWithPadding, log_metric, log_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_datasets = load_dataset(\n",
    "#     \"mozilla-foundation/common_voice_16_0\", \"uk\",\n",
    "#     split=[\"train\", 'validation', 'test'],\n",
    "#     cache_dir='raw_dataset_with_cache/cache',\n",
    "#     data_dir='raw_dataset_with_cache/dataset',\n",
    "#     )\n",
    "\n",
    "# raw_datasets[0].save_to_disk('dataset_saved/mozila_uk/train')\n",
    "# raw_datasets[1].save_to_disk('dataset_saved/mozila_uk/validation')\n",
    "# raw_datasets[2].save_to_disk('dataset_saved/mozila_uk/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "validation\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "# 3. Load dataset\n",
    "raw_datasets = DatasetDict()\n",
    "token = HfFolder().get_token()\n",
    "\n",
    "for split in ['train', 'validation','test']:\n",
    "    print(split)\n",
    "    raw_datasets[split] = datasets.load_from_disk(\n",
    "            f'dataset_saved/mozila_uk/{split}',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
       "    num_rows: 9791\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Parse input arguments\n",
    "# We keep distinct sets of args, for cleaner separation of model/data/training related args\n",
    "parser = HfArgumentParser((ModelArguments, DataTrainingArguments, Seq2SeqTrainingArguments))\n",
    "\n",
    "list_args = [\n",
    "'--model_name_or_path=./local_whisper_medium',\n",
    "# '--dataset_name=mozilla-foundation/common_voice_13_0',\n",
    "# '--dataset_config_name=en',\n",
    "# '--dataset_split_name=train+validation+test',\n",
    "'--text_column_name=sentence',\n",
    "'--id_column_name=path',\n",
    "'--output_dir=dataset_saved/labeled_uk',\n",
    "# '--wandb_project=distil-whisper-labelling-v2',\n",
    "'--language=uk',\n",
    "'--per_device_eval_batch_size=40',\n",
    "'--dtype=float16',\n",
    "'--dataloader_num_workers=4',\n",
    "'--preprocessing_num_workers=4',\n",
    "'--logging_steps=100',\n",
    "'--max_label_length=128',\n",
    "'--task=transcribe',\n",
    "#'--attn_type=None',\n",
    "# '--streaming=True',\n",
    "'--generation_num_beams=1',\n",
    "'--decode_token_ids=False',\n",
    "'--cache_dir=model_cache/',\n",
    "'--dataset_cache_dir=cache',\n",
    "'--preprocessing_only=False',\n",
    "'--report_to=wandb'\n",
    "]\n",
    "\n",
    "model_args, data_args, training_args = parser.parse_args_into_dataclasses(list_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTrainingArguments(dataset_name=None, dataset_config_name=None, dataset_cache_dir='cache', overwrite_cache=False, preprocessing_num_workers=4, audio_column_name='audio', text_column_name='sentence', id_column_name='path', max_label_length=128, preprocessing_only=False, dataset_split_name='train+validation+test', wandb_project='distil-whisper', streaming=False, max_samples_per_split=None, return_timestamps=False, language='uk', task='transcribe', decode_token_ids=False, private_dataset=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "id": "bfbouFpkEqcL",
    "outputId": "7b836f95-7b85-466c-ac1c-79732af56ed5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzekamrozek\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\distiling_whisper_local\\wandb\\run-20240417_162056-ip3diqvn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zekamrozek/distil-whisper/runs/ip3diqvn' target=\"_blank\">comfy-meadow-34</a></strong> to <a href='https://wandb.ai/zekamrozek/distil-whisper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/zekamrozek/distil-whisper' target=\"_blank\">https://wandb.ai/zekamrozek/distil-whisper</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/zekamrozek/distil-whisper/runs/ip3diqvn' target=\"_blank\">https://wandb.ai/zekamrozek/distil-whisper/runs/ip3diqvn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/17/2024 16:21:04 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "04/17/2024 16:21:04 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=4,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_config=None,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=dataset_saved/labeled_uk\\runs\\Apr17_16-20-52_DESKTOP-9H5C6TS,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=100,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "output_dir=dataset_saved/labeled_uk,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=40,\n",
      "per_device_train_batch_size=8,\n",
      "predict_with_generate=False,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['wandb'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=dataset_saved/labeled_uk,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "split_batches=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 2. Initialize the accelerator\n",
    "# We will let the accelerator handle device placement for us in this example\n",
    "# We simply have to specify the training precision and any trackers being used\n",
    "# We'll use the same dtype arguments as our JAX/Flax training script and convert\n",
    "# it to accelerate format\n",
    "if model_args.dtype == \"float16\":\n",
    "    mixed_precision = \"fp16\"\n",
    "    torch_dtype = torch.float16\n",
    "elif model_args.dtype == \"bfloat16\":\n",
    "    mixed_precision = \"bf16\"\n",
    "    torch_dtype = torch.bfloat160\n",
    "else:\n",
    "    mixed_precision = \"no\"\n",
    "    torch_dtype = torch.float32\n",
    "\n",
    "kwargs = InitProcessGroupKwargs(timeout=timedelta(seconds=7200))\n",
    "\n",
    "accelerator = Accelerator(\n",
    "    gradient_accumulation_steps=training_args.gradient_accumulation_steps,\n",
    "    mixed_precision=mixed_precision,\n",
    "    log_with=training_args.report_to,\n",
    "    project_dir=training_args.output_dir,\n",
    "    kwargs_handlers=[kwargs],\n",
    ")\n",
    "\n",
    "accelerator.init_trackers(project_name=data_args.wandb_project)\n",
    "\n",
    "# 3. Set-up basic logging\n",
    "# Create one log on every process with the configuration for debugging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "# Log a small summary on each proces\n",
    "logger.warning(\n",
    "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}, \"\n",
    "    f\"distributed training: {training_args.parallel_mode.value == 'distributed'}, 16-bits training: {training_args.fp16}\"\n",
    ")\n",
    "\n",
    "\n",
    "# Set the verbosity to info of the Transformers logger (on main process only)\n",
    "if accelerator.is_local_main_process:\n",
    "    datasets.utils.logging.set_verbosity_warning()\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "else:\n",
    "    datasets.utils.logging.set_verbosity_error()\n",
    "    transformers.utils.logging.set_verbosity_error()\n",
    "logger.info(\"Training/evaluation parameters %s\", training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vmxoOpoeHYxr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if data_args.audio_column_name not in next(iter(raw_datasets.values())).column_names:\n",
    "    raise ValueError(\n",
    "        f\"--audio_column_name '{data_args.audio_column_name}' not found in dataset\"\n",
    "        f\" '{data_args.dataset_name}'. Make sure to set `--audio_column_name` to\"\n",
    "        \" the correct audio column - one of\"\n",
    "        f\" {', '.join(next(iter(raw_datasets.values())).column_names)}.\"\n",
    "    )\n",
    "\n",
    "if data_args.text_column_name not in next(iter(raw_datasets.values())).column_names:\n",
    "    raise ValueError(\n",
    "        f\"--text_column_name {data_args.text_column_name} not found in dataset\"\n",
    "        f\" '{data_args.dataset_name}'. Make sure to set `--text_column_name` to the\"\n",
    "        \" correct text column - one of\"\n",
    "        f\" {', '.join(next(iter(raw_datasets.values())).column_names)}.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jISUEsooHeX_",
    "outputId": "084bf907-9fbb-4f84-ab84-09250b658dd0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./local_whisper_medium\\config.json\n",
      "Model config WhisperConfig {\n",
      "  \"_name_or_path\": \"openai/whisper-medium\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"apply_spec_augment\": false,\n",
      "  \"architectures\": [\n",
      "    \"WhisperForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50257\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 24,\n",
      "  \"decoder_start_token_id\": 50258,\n",
      "  \"dropout\": 0.0,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 24,\n",
      "  \"eos_token_id\": 50257,\n",
      "  \"forced_decoder_ids\": [\n",
      "    [\n",
      "      1,\n",
      "      50259\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      50359\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      50363\n",
      "    ]\n",
      "  ],\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"max_length\": 448,\n",
      "  \"max_source_positions\": 1500,\n",
      "  \"max_target_positions\": 448,\n",
      "  \"median_filter_width\": 7,\n",
      "  \"model_type\": \"whisper\",\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_mel_bins\": 80,\n",
      "  \"pad_token_id\": 50257,\n",
      "  \"scale_embedding\": false,\n",
      "  \"suppress_tokens\": [\n",
      "    1,\n",
      "    2,\n",
      "    7,\n",
      "    8,\n",
      "    9,\n",
      "    10,\n",
      "    14,\n",
      "    25,\n",
      "    26,\n",
      "    27,\n",
      "    28,\n",
      "    29,\n",
      "    31,\n",
      "    58,\n",
      "    59,\n",
      "    60,\n",
      "    61,\n",
      "    62,\n",
      "    63,\n",
      "    90,\n",
      "    91,\n",
      "    92,\n",
      "    93,\n",
      "    359,\n",
      "    503,\n",
      "    522,\n",
      "    542,\n",
      "    873,\n",
      "    893,\n",
      "    902,\n",
      "    918,\n",
      "    922,\n",
      "    931,\n",
      "    1350,\n",
      "    1853,\n",
      "    1982,\n",
      "    2460,\n",
      "    2627,\n",
      "    3246,\n",
      "    3253,\n",
      "    3268,\n",
      "    3536,\n",
      "    3846,\n",
      "    3961,\n",
      "    4183,\n",
      "    4667,\n",
      "    6585,\n",
      "    6647,\n",
      "    7273,\n",
      "    9061,\n",
      "    9383,\n",
      "    10428,\n",
      "    10929,\n",
      "    11938,\n",
      "    12033,\n",
      "    12331,\n",
      "    12562,\n",
      "    13793,\n",
      "    14157,\n",
      "    14635,\n",
      "    15265,\n",
      "    15618,\n",
      "    16553,\n",
      "    16604,\n",
      "    18362,\n",
      "    18956,\n",
      "    20075,\n",
      "    21675,\n",
      "    22520,\n",
      "    26130,\n",
      "    26161,\n",
      "    26435,\n",
      "    28279,\n",
      "    29464,\n",
      "    31650,\n",
      "    32302,\n",
      "    32470,\n",
      "    36865,\n",
      "    42863,\n",
      "    47425,\n",
      "    49870,\n",
      "    50254,\n",
      "    50258,\n",
      "    50358,\n",
      "    50359,\n",
      "    50360,\n",
      "    50361,\n",
      "    50362\n",
      "  ],\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 51865\n",
      "}\n",
      "\n",
      "loading configuration file preprocessor_config.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\abdf7c39ab9d0397620ccaea8974cc764cd0953e\\preprocessor_config.json\n",
      "Feature extractor WhisperFeatureExtractor {\n",
      "  \"chunk_length\": 30,\n",
      "  \"feature_extractor_type\": \"WhisperFeatureExtractor\",\n",
      "  \"feature_size\": 80,\n",
      "  \"hop_length\": 160,\n",
      "  \"n_fft\": 400,\n",
      "  \"n_samples\": 480000,\n",
      "  \"nb_max_frames\": 3000,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0.0,\n",
      "  \"processor_class\": \"WhisperProcessor\",\n",
      "  \"return_attention_mask\": false,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\abdf7c39ab9d0397620ccaea8974cc764cd0953e\\vocab.json\n",
      "loading file tokenizer.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\abdf7c39ab9d0397620ccaea8974cc764cd0953e\\tokenizer.json\n",
      "loading file merges.txt from cache at model_cache/models--openai--whisper-medium\\snapshots\\abdf7c39ab9d0397620ccaea8974cc764cd0953e\\merges.txt\n",
      "loading file normalizer.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\abdf7c39ab9d0397620ccaea8974cc764cd0953e\\normalizer.json\n",
      "loading file added_tokens.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\abdf7c39ab9d0397620ccaea8974cc764cd0953e\\added_tokens.json\n",
      "loading file special_tokens_map.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\abdf7c39ab9d0397620ccaea8974cc764cd0953e\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\abdf7c39ab9d0397620ccaea8974cc764cd0953e\\tokenizer_config.json\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file preprocessor_config.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\abdf7c39ab9d0397620ccaea8974cc764cd0953e\\preprocessor_config.json\n",
      "Feature extractor WhisperFeatureExtractor {\n",
      "  \"chunk_length\": 30,\n",
      "  \"feature_extractor_type\": \"WhisperFeatureExtractor\",\n",
      "  \"feature_size\": 80,\n",
      "  \"hop_length\": 160,\n",
      "  \"n_fft\": 400,\n",
      "  \"n_samples\": 480000,\n",
      "  \"nb_max_frames\": 3000,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0.0,\n",
      "  \"processor_class\": \"WhisperProcessor\",\n",
      "  \"return_attention_mask\": false,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\abdf7c39ab9d0397620ccaea8974cc764cd0953e\\vocab.json\n",
      "loading file tokenizer.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\abdf7c39ab9d0397620ccaea8974cc764cd0953e\\tokenizer.json\n",
      "loading file merges.txt from cache at model_cache/models--openai--whisper-medium\\snapshots\\abdf7c39ab9d0397620ccaea8974cc764cd0953e\\merges.txt\n",
      "loading file normalizer.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\abdf7c39ab9d0397620ccaea8974cc764cd0953e\\normalizer.json\n",
      "loading file added_tokens.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\abdf7c39ab9d0397620ccaea8974cc764cd0953e\\added_tokens.json\n",
      "loading file special_tokens_map.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\abdf7c39ab9d0397620ccaea8974cc764cd0953e\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at model_cache/models--openai--whisper-medium\\snapshots\\abdf7c39ab9d0397620ccaea8974cc764cd0953e\\tokenizer_config.json\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading weights file ./local_whisper_medium\\model.safetensors\n",
      "Instantiating WhisperForConditionalGeneration model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50257\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"decoder_start_token_id\": 50258,\n",
      "  \"eos_token_id\": 50257,\n",
      "  \"forced_decoder_ids\": [\n",
      "    [\n",
      "      1,\n",
      "      50259\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      50359\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      50363\n",
      "    ]\n",
      "  ],\n",
      "  \"max_length\": 448,\n",
      "  \"pad_token_id\": 50257,\n",
      "  \"suppress_tokens\": [\n",
      "    1,\n",
      "    2,\n",
      "    7,\n",
      "    8,\n",
      "    9,\n",
      "    10,\n",
      "    14,\n",
      "    25,\n",
      "    26,\n",
      "    27,\n",
      "    28,\n",
      "    29,\n",
      "    31,\n",
      "    58,\n",
      "    59,\n",
      "    60,\n",
      "    61,\n",
      "    62,\n",
      "    63,\n",
      "    90,\n",
      "    91,\n",
      "    92,\n",
      "    93,\n",
      "    359,\n",
      "    503,\n",
      "    522,\n",
      "    542,\n",
      "    873,\n",
      "    893,\n",
      "    902,\n",
      "    918,\n",
      "    922,\n",
      "    931,\n",
      "    1350,\n",
      "    1853,\n",
      "    1982,\n",
      "    2460,\n",
      "    2627,\n",
      "    3246,\n",
      "    3253,\n",
      "    3268,\n",
      "    3536,\n",
      "    3846,\n",
      "    3961,\n",
      "    4183,\n",
      "    4667,\n",
      "    6585,\n",
      "    6647,\n",
      "    7273,\n",
      "    9061,\n",
      "    9383,\n",
      "    10428,\n",
      "    10929,\n",
      "    11938,\n",
      "    12033,\n",
      "    12331,\n",
      "    12562,\n",
      "    13793,\n",
      "    14157,\n",
      "    14635,\n",
      "    15265,\n",
      "    15618,\n",
      "    16553,\n",
      "    16604,\n",
      "    18362,\n",
      "    18956,\n",
      "    20075,\n",
      "    21675,\n",
      "    22520,\n",
      "    26130,\n",
      "    26161,\n",
      "    26435,\n",
      "    28279,\n",
      "    29464,\n",
      "    31650,\n",
      "    32302,\n",
      "    32470,\n",
      "    36865,\n",
      "    42863,\n",
      "    47425,\n",
      "    49870,\n",
      "    50254,\n",
      "    50258,\n",
      "    50358,\n",
      "    50359,\n",
      "    50360,\n",
      "    50361,\n",
      "    50362\n",
      "  ]\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing WhisperForConditionalGeneration.\n",
      "\n",
      "All the weights of WhisperForConditionalGeneration were initialized from the model checkpoint at ./local_whisper_medium.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use WhisperForConditionalGeneration for predictions without further training.\n",
      "loading configuration file ./local_whisper_medium\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"alignment_heads\": [\n",
      "    [\n",
      "      13,\n",
      "      15\n",
      "    ],\n",
      "    [\n",
      "      15,\n",
      "      4\n",
      "    ],\n",
      "    [\n",
      "      15,\n",
      "      15\n",
      "    ],\n",
      "    [\n",
      "      16,\n",
      "      1\n",
      "    ],\n",
      "    [\n",
      "      20,\n",
      "      0\n",
      "    ],\n",
      "    [\n",
      "      23,\n",
      "      4\n",
      "    ]\n",
      "  ],\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50257\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"decoder_start_token_id\": 50258,\n",
      "  \"eos_token_id\": 50257,\n",
      "  \"forced_decoder_ids\": [\n",
      "    [\n",
      "      1,\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      50359\n",
      "    ]\n",
      "  ],\n",
      "  \"is_multilingual\": true,\n",
      "  \"lang_to_id\": {\n",
      "    \"<|af|>\": 50327,\n",
      "    \"<|am|>\": 50334,\n",
      "    \"<|ar|>\": 50272,\n",
      "    \"<|as|>\": 50350,\n",
      "    \"<|az|>\": 50304,\n",
      "    \"<|ba|>\": 50355,\n",
      "    \"<|be|>\": 50330,\n",
      "    \"<|bg|>\": 50292,\n",
      "    \"<|bn|>\": 50302,\n",
      "    \"<|bo|>\": 50347,\n",
      "    \"<|br|>\": 50309,\n",
      "    \"<|bs|>\": 50315,\n",
      "    \"<|ca|>\": 50270,\n",
      "    \"<|cs|>\": 50283,\n",
      "    \"<|cy|>\": 50297,\n",
      "    \"<|da|>\": 50285,\n",
      "    \"<|de|>\": 50261,\n",
      "    \"<|el|>\": 50281,\n",
      "    \"<|en|>\": 50259,\n",
      "    \"<|es|>\": 50262,\n",
      "    \"<|et|>\": 50307,\n",
      "    \"<|eu|>\": 50310,\n",
      "    \"<|fa|>\": 50300,\n",
      "    \"<|fi|>\": 50277,\n",
      "    \"<|fo|>\": 50338,\n",
      "    \"<|fr|>\": 50265,\n",
      "    \"<|gl|>\": 50319,\n",
      "    \"<|gu|>\": 50333,\n",
      "    \"<|haw|>\": 50352,\n",
      "    \"<|ha|>\": 50354,\n",
      "    \"<|he|>\": 50279,\n",
      "    \"<|hi|>\": 50276,\n",
      "    \"<|hr|>\": 50291,\n",
      "    \"<|ht|>\": 50339,\n",
      "    \"<|hu|>\": 50286,\n",
      "    \"<|hy|>\": 50312,\n",
      "    \"<|id|>\": 50275,\n",
      "    \"<|is|>\": 50311,\n",
      "    \"<|it|>\": 50274,\n",
      "    \"<|ja|>\": 50266,\n",
      "    \"<|jw|>\": 50356,\n",
      "    \"<|ka|>\": 50329,\n",
      "    \"<|kk|>\": 50316,\n",
      "    \"<|km|>\": 50323,\n",
      "    \"<|kn|>\": 50306,\n",
      "    \"<|ko|>\": 50264,\n",
      "    \"<|la|>\": 50294,\n",
      "    \"<|lb|>\": 50345,\n",
      "    \"<|ln|>\": 50353,\n",
      "    \"<|lo|>\": 50336,\n",
      "    \"<|lt|>\": 50293,\n",
      "    \"<|lv|>\": 50301,\n",
      "    \"<|mg|>\": 50349,\n",
      "    \"<|mi|>\": 50295,\n",
      "    \"<|mk|>\": 50308,\n",
      "    \"<|ml|>\": 50296,\n",
      "    \"<|mn|>\": 50314,\n",
      "    \"<|mr|>\": 50320,\n",
      "    \"<|ms|>\": 50282,\n",
      "    \"<|mt|>\": 50343,\n",
      "    \"<|my|>\": 50346,\n",
      "    \"<|ne|>\": 50313,\n",
      "    \"<|nl|>\": 50271,\n",
      "    \"<|nn|>\": 50342,\n",
      "    \"<|no|>\": 50288,\n",
      "    \"<|oc|>\": 50328,\n",
      "    \"<|pa|>\": 50321,\n",
      "    \"<|pl|>\": 50269,\n",
      "    \"<|ps|>\": 50340,\n",
      "    \"<|pt|>\": 50267,\n",
      "    \"<|ro|>\": 50284,\n",
      "    \"<|ru|>\": 50263,\n",
      "    \"<|sa|>\": 50344,\n",
      "    \"<|sd|>\": 50332,\n",
      "    \"<|si|>\": 50322,\n",
      "    \"<|sk|>\": 50298,\n",
      "    \"<|sl|>\": 50305,\n",
      "    \"<|sn|>\": 50324,\n",
      "    \"<|so|>\": 50326,\n",
      "    \"<|sq|>\": 50317,\n",
      "    \"<|sr|>\": 50303,\n",
      "    \"<|su|>\": 50357,\n",
      "    \"<|sv|>\": 50273,\n",
      "    \"<|sw|>\": 50318,\n",
      "    \"<|ta|>\": 50287,\n",
      "    \"<|te|>\": 50299,\n",
      "    \"<|tg|>\": 50331,\n",
      "    \"<|th|>\": 50289,\n",
      "    \"<|tk|>\": 50341,\n",
      "    \"<|tl|>\": 50348,\n",
      "    \"<|tr|>\": 50268,\n",
      "    \"<|tt|>\": 50351,\n",
      "    \"<|uk|>\": 50280,\n",
      "    \"<|ur|>\": 50290,\n",
      "    \"<|uz|>\": 50337,\n",
      "    \"<|vi|>\": 50278,\n",
      "    \"<|yi|>\": 50335,\n",
      "    \"<|yo|>\": 50325,\n",
      "    \"<|zh|>\": 50260\n",
      "  },\n",
      "  \"max_initial_timestamp_index\": 50,\n",
      "  \"max_length\": 448,\n",
      "  \"no_timestamps_token_id\": 50363,\n",
      "  \"pad_token_id\": 50257,\n",
      "  \"prev_sot_token_id\": 50361,\n",
      "  \"return_timestamps\": false,\n",
      "  \"suppress_tokens\": [\n",
      "    1,\n",
      "    2,\n",
      "    7,\n",
      "    8,\n",
      "    9,\n",
      "    10,\n",
      "    14,\n",
      "    25,\n",
      "    26,\n",
      "    27,\n",
      "    28,\n",
      "    29,\n",
      "    31,\n",
      "    58,\n",
      "    59,\n",
      "    60,\n",
      "    61,\n",
      "    62,\n",
      "    63,\n",
      "    90,\n",
      "    91,\n",
      "    92,\n",
      "    93,\n",
      "    359,\n",
      "    503,\n",
      "    522,\n",
      "    542,\n",
      "    873,\n",
      "    893,\n",
      "    902,\n",
      "    918,\n",
      "    922,\n",
      "    931,\n",
      "    1350,\n",
      "    1853,\n",
      "    1982,\n",
      "    2460,\n",
      "    2627,\n",
      "    3246,\n",
      "    3253,\n",
      "    3268,\n",
      "    3536,\n",
      "    3846,\n",
      "    3961,\n",
      "    4183,\n",
      "    4667,\n",
      "    6585,\n",
      "    6647,\n",
      "    7273,\n",
      "    9061,\n",
      "    9383,\n",
      "    10428,\n",
      "    10929,\n",
      "    11938,\n",
      "    12033,\n",
      "    12331,\n",
      "    12562,\n",
      "    13793,\n",
      "    14157,\n",
      "    14635,\n",
      "    15265,\n",
      "    15618,\n",
      "    16553,\n",
      "    16604,\n",
      "    18362,\n",
      "    18956,\n",
      "    20075,\n",
      "    21675,\n",
      "    22520,\n",
      "    26130,\n",
      "    26161,\n",
      "    26435,\n",
      "    28279,\n",
      "    29464,\n",
      "    31650,\n",
      "    32302,\n",
      "    32470,\n",
      "    36865,\n",
      "    42863,\n",
      "    47425,\n",
      "    49870,\n",
      "    50254,\n",
      "    50258,\n",
      "    50358,\n",
      "    50359,\n",
      "    50360,\n",
      "    50361,\n",
      "    50362\n",
      "  ],\n",
      "  \"task_to_id\": {\n",
      "    \"transcribe\": 50359,\n",
      "    \"translate\": 50358\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Load pretrained model, tokenizer, and feature extractor\n",
    "config = WhisperConfig.from_pretrained(\n",
    "    (model_args.config_name if model_args.config_name else model_args.model_name_or_path),\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    token=token,\n",
    ")\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\n",
    "    # (model_args.feature_extractor_name if model_args.feature_extractor_name else model_args.model_name_or_path),\n",
    "    \"openai/whisper-medium\",\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    token=token,\n",
    ")\n",
    "tokenizer = WhisperTokenizerFast.from_pretrained(\n",
    "    # (model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path),\n",
    "    \"openai/whisper-medium\",\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    use_fast=model_args.use_fast_tokenizer,\n",
    "    revision=model_args.model_revision,\n",
    "    token=token,\n",
    ")\n",
    "processor = WhisperProcessor.from_pretrained(\n",
    "    # (model_args.processor_name if model_args.processor_name else model_args.model_name_or_path),\n",
    "    \"openai/whisper-medium\",\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    token=token,\n",
    ")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    config=config,\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    subfolder=model_args.subfolder,\n",
    "    token=token,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    use_flash_attention_2=model_args.attn_type == \"flash_attn_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "1l9mPbUaHiZ4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_args.attn_type == \"flash_attn\":\n",
    "    model = model.to_bettertransformer()\n",
    "elif model_args.attn_type not in [None, \"flash_attn\", \"flash_attn_2\"]:\n",
    "    raise ValueError(\n",
    "        f\"Argument `attn_type` is set to {model_args.attn_type}. Should be one of:\"\n",
    "        \"1. `None`: default Transformers attention implementation.\"\n",
    "        \"2. `flash_attn`: Flash Attention through PyTorch SDPA. Requires `torch>=2.0` and `optimum` to be installed. Recommended for hardware where Flash Attention 2 is not supported, e.g. Turing GPUs, (T4, RTX 2080).\"\n",
    "        \"3. `flash_attn_2`: Flash Attention 2 through the Flash Attention package https://github.com/Dao-AILab/flash-attention. **Always** recommended on supported hardware (Ampere, Ada, or Hopper GPUs, e.g., A100, RTX 3090, RTX 4090, H100).\"\n",
    "    )\n",
    "\n",
    "model.eval()\n",
    "\n",
    "if model.config.decoder_start_token_id is None:\n",
    "    raise ValueError(\"Make sure that `config.decoder_start_token_id` is correctly defined\")\n",
    "\n",
    "return_timestamps = data_args.return_timestamps\n",
    "if hasattr(model.generation_config, \"is_multilingual\") and model.generation_config.is_multilingual:\n",
    "    # We need to set the language and task ids for multilingual checkpoints\n",
    "    tokenizer.set_prefix_tokens(\n",
    "        language=data_args.language, task=data_args.task, predict_timestamps=return_timestamps\n",
    "    )\n",
    "elif data_args.language is not None:\n",
    "    raise ValueError(\n",
    "        \"Setting language token for an English-only checkpoint is not permitted. The language argument should \"\n",
    "        \"only be set for multilingual checkpoints.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "f66ef2a647a34ecda62ad1376ecc0787",
      "b25f2d354f9c4ec3b1d81a8d1d039266",
      "116f8c908f1d42f9bee1525787dc60b0",
      "b50ac10536424294a4391bed34d4d101",
      "85230fee517245a1b9db2d19eb87a46f",
      "25eb176a19c340dda3b264a28e203cbf",
      "3e8bd264b90b4b16a08d5ce3952f0561",
      "4f5b8f35e56d492995c1ef3d824da234",
      "1f7fd128e7ba4f2a8556a5a6997fd946",
      "41fb328527f541afbc7c86e963f7ba21",
      "a2b830af92a4492d89ea87e8280bf1b7",
      "8ac4f7ff7d594defbe6a662f45affd3b",
      "7732642b5f394f43b843346b9bb6300e",
      "1bda516d2d99431ebe4694090fa5c8fa",
      "8b421cf642cd407491a002a3223fc00f",
      "37a59b12c6d5445aa4266cea168f3a0f",
      "dc514e78b8454182abd681ee7f196dd7",
      "fd01f17c91ff4fcc9c32fd3e674e52cf",
      "17951ff284bc44cc8025a23d7403dfb5",
      "f8f7a9e8383f4dbba1199f8ae38c9de7",
      "5a1b7e1a32494ac7bb671b7046d51c09",
      "c02e564fec994102a5df7f2b8aac1af3"
     ]
    },
    "id": "-Lt3p9y_HnRP",
    "outputId": "672011b1-0ce8-4b66-bc71-407a248ccd7b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baafd6a5743947888c757171c98ef66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocess dataset:   0%|          | 0/23799 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m     vectorized_datasets \u001b[38;5;241m=\u001b[39m raw_datasets\u001b[38;5;241m.\u001b[39mmap(prepare_dataset, remove_columns\u001b[38;5;241m=\u001b[39mraw_datasets_features)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     vectorized_datasets \u001b[38;5;241m=\u001b[39m \u001b[43mraw_datasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprepare_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_datasets_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# num_proc=1,\u001b[39;49;00m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpreprocess dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# for large datasets it is advised to run the preprocessing on a\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# single machine first with `args.preprocessing_only` since there will mostly likely\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# be a timeout when running the script in distributed mode.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# In a second step `args.preprocessing_only` can then be set to `False` to load the\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# cached dataset\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_args\u001b[38;5;241m.\u001b[39mpreprocessing_only:\n",
      "File \u001b[1;32mf:\\anaconda\\envs\\disenv\\lib\\site-packages\\datasets\\dataset_dict.py:855\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    853\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m--> 855\u001b[0m     {\n\u001b[0;32m    856\u001b[0m         k: dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m    857\u001b[0m             function\u001b[38;5;241m=\u001b[39mfunction,\n\u001b[0;32m    858\u001b[0m             with_indices\u001b[38;5;241m=\u001b[39mwith_indices,\n\u001b[0;32m    859\u001b[0m             with_rank\u001b[38;5;241m=\u001b[39mwith_rank,\n\u001b[0;32m    860\u001b[0m             input_columns\u001b[38;5;241m=\u001b[39minput_columns,\n\u001b[0;32m    861\u001b[0m             batched\u001b[38;5;241m=\u001b[39mbatched,\n\u001b[0;32m    862\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    863\u001b[0m             drop_last_batch\u001b[38;5;241m=\u001b[39mdrop_last_batch,\n\u001b[0;32m    864\u001b[0m             remove_columns\u001b[38;5;241m=\u001b[39mremove_columns,\n\u001b[0;32m    865\u001b[0m             keep_in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory,\n\u001b[0;32m    866\u001b[0m             load_from_cache_file\u001b[38;5;241m=\u001b[39mload_from_cache_file,\n\u001b[0;32m    867\u001b[0m             cache_file_name\u001b[38;5;241m=\u001b[39mcache_file_names[k],\n\u001b[0;32m    868\u001b[0m             writer_batch_size\u001b[38;5;241m=\u001b[39mwriter_batch_size,\n\u001b[0;32m    869\u001b[0m             features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[0;32m    870\u001b[0m             disable_nullable\u001b[38;5;241m=\u001b[39mdisable_nullable,\n\u001b[0;32m    871\u001b[0m             fn_kwargs\u001b[38;5;241m=\u001b[39mfn_kwargs,\n\u001b[0;32m    872\u001b[0m             num_proc\u001b[38;5;241m=\u001b[39mnum_proc,\n\u001b[0;32m    873\u001b[0m             desc\u001b[38;5;241m=\u001b[39mdesc,\n\u001b[0;32m    874\u001b[0m         )\n\u001b[0;32m    875\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    876\u001b[0m     }\n\u001b[0;32m    877\u001b[0m )\n",
      "File \u001b[1;32mf:\\anaconda\\envs\\disenv\\lib\\site-packages\\datasets\\dataset_dict.py:856\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    853\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m    855\u001b[0m     {\n\u001b[1;32m--> 856\u001b[0m         k: \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    875\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    876\u001b[0m     }\n\u001b[0;32m    877\u001b[0m )\n",
      "File \u001b[1;32mf:\\anaconda\\envs\\disenv\\lib\\site-packages\\datasets\\arrow_dataset.py:591\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    590\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 591\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    592\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32mf:\\anaconda\\envs\\disenv\\lib\\site-packages\\datasets\\arrow_dataset.py:556\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    549\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    554\u001b[0m }\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 556\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    557\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    558\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mf:\\anaconda\\envs\\disenv\\lib\\site-packages\\datasets\\arrow_dataset.py:3089\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3083\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[0;32m   3084\u001b[0m         disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mis_progress_bar_enabled(),\n\u001b[0;32m   3085\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3086\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3087\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3088\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3089\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3090\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3091\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mf:\\anaconda\\envs\\disenv\\lib\\site-packages\\datasets\\arrow_dataset.py:3442\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3440\u001b[0m _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   3441\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[1;32m-> 3442\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m update_data:\n\u001b[0;32m   3444\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mf:\\anaconda\\envs\\disenv\\lib\\site-packages\\datasets\\arrow_dataset.py:3345\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[0;32m   3344\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[1;32m-> 3345\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m function(\u001b[38;5;241m*\u001b[39mfn_args, \u001b[38;5;241m*\u001b[39madditional_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_kwargs)\n\u001b[0;32m   3346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3347\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3348\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[0;32m   3349\u001b[0m     }\n",
      "Cell \u001b[1;32mIn[20], line 34\u001b[0m, in \u001b[0;36mprepare_dataset\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_dataset\u001b[39m(batch):\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# process audio\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     sample \u001b[38;5;241m=\u001b[39m batch[audio_column_name]\n\u001b[1;32m---> 34\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marray\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msampling_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# process audio length\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     batch[model_input_name] \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mget(model_input_name)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mf:\\anaconda\\envs\\disenv\\lib\\site-packages\\transformers\\models\\whisper\\feature_extraction_whisper.py:250\u001b[0m, in \u001b[0;36mWhisperFeatureExtractor.__call__\u001b[1;34m(self, raw_speech, truncation, pad_to_multiple_of, return_tensors, return_attention_mask, padding, max_length, sampling_rate, do_normalize, **kwargs)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# make sure list is in array format\u001b[39;00m\n\u001b[0;32m    248\u001b[0m input_features \u001b[38;5;241m=\u001b[39m padded_inputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 250\u001b[0m input_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_np_extract_fbank_features(waveform) \u001b[38;5;28;01mfor\u001b[39;00m waveform \u001b[38;5;129;01min\u001b[39;00m input_features[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_features[\u001b[38;5;241m0\u001b[39m], List):\n\u001b[0;32m    253\u001b[0m     padded_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_features\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39masarray(feature, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m input_features]\n",
      "File \u001b[1;32mf:\\anaconda\\envs\\disenv\\lib\\site-packages\\transformers\\models\\whisper\\feature_extraction_whisper.py:250\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# make sure list is in array format\u001b[39;00m\n\u001b[0;32m    248\u001b[0m input_features \u001b[38;5;241m=\u001b[39m padded_inputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 250\u001b[0m input_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_np_extract_fbank_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m waveform \u001b[38;5;129;01min\u001b[39;00m input_features[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_features[\u001b[38;5;241m0\u001b[39m], List):\n\u001b[0;32m    253\u001b[0m     padded_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_features\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39masarray(feature, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m input_features]\n",
      "File \u001b[1;32mf:\\anaconda\\envs\\disenv\\lib\\site-packages\\transformers\\models\\whisper\\feature_extraction_whisper.py:99\u001b[0m, in \u001b[0;36mWhisperFeatureExtractor._np_extract_fbank_features\u001b[1;34m(self, waveform)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_np_extract_fbank_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, waveform: np\u001b[38;5;241m.\u001b[39marray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    Compute the log-mel spectrogram of the provided audio, gives similar results to Whisper's original torch\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m    implementation with 1e-5 tolerance.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m     log_spec \u001b[38;5;241m=\u001b[39m \u001b[43mspectrogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhann\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmel_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmel_filters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_mel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlog10\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m     log_spec \u001b[38;5;241m=\u001b[39m log_spec[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    109\u001b[0m     log_spec \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(log_spec, log_spec\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m8.0\u001b[39m)\n",
      "File \u001b[1;32mf:\\anaconda\\envs\\disenv\\lib\\site-packages\\transformers\\audio_utils.py:452\u001b[0m, in \u001b[0;36mspectrogram\u001b[1;34m(waveform, window, frame_length, hop_length, fft_length, power, center, pad_mode, onesided, preemphasis, mel_filters, mel_floor, log_mel, reference, min_value, db_range, remove_dc_offset, dtype)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# note: ** is much faster than np.power\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m power \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 452\u001b[0m     spectrogram \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspectrogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m power\n\u001b[0;32m    454\u001b[0m spectrogram \u001b[38;5;241m=\u001b[39m spectrogram\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mel_filters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 6. Resample speech dataset: `datasets` takes care of automatically loading and resampling the audio,\n",
    "# so we just need to set the correct target sampling rate.\n",
    "raw_datasets = raw_datasets.cast_column(\n",
    "    data_args.audio_column_name,\n",
    "    datasets.features.Audio(sampling_rate=feature_extractor.sampling_rate),\n",
    ")\n",
    "\n",
    "# 7. Preprocessing the datasets.\n",
    "# We need to read the audio files as arrays and tokenize the targets.\n",
    "max_label_length = (\n",
    "    data_args.max_label_length if data_args.max_label_length is not None else model.config.max_length\n",
    ")\n",
    "audio_column_name = data_args.audio_column_name\n",
    "num_workers = data_args.preprocessing_num_workers\n",
    "dataloader_num_workers = training_args.dataloader_num_workers\n",
    "text_column_name = data_args.text_column_name\n",
    "model_input_name = feature_extractor.model_input_names[0]\n",
    "id_column_name = data_args.id_column_name\n",
    "normalizer = (\n",
    "    BasicTextNormalizer() if data_args.language is not None else EnglishTextNormalizer(tokenizer.english_spelling_normalizer)\n",
    ")\n",
    "\n",
    "# if data_args.max_samples_per_split is not None:\n",
    "#     for split in data_splits:\n",
    "#         raw_datasets[split] = (\n",
    "#             raw_datasets[split].take(data_args.max_samples_per_split)\n",
    "#             if data_args.streaming\n",
    "#             else raw_datasets[split].select(range(data_args.max_samples_per_split))\n",
    "#         )\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    # process audio\n",
    "    sample = batch[audio_column_name]\n",
    "    inputs = feature_extractor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"])\n",
    "    # process audio length\n",
    "    batch[model_input_name] = inputs.get(model_input_name)[0]\n",
    "\n",
    "    # process targets\n",
    "    input_str = batch[text_column_name]\n",
    "    batch[\"labels\"] = tokenizer(input_str, max_length=max_label_length, truncation=True).input_ids\n",
    "\n",
    "    # record the id of the sample as token ids\n",
    "    batch[\"file_id\"] = tokenizer(batch[id_column_name], add_special_tokens=False).input_ids\n",
    "    return batch\n",
    "\n",
    "raw_datasets_features = list(next(iter(raw_datasets.values())).features.keys())\n",
    "if data_args.streaming:\n",
    "    vectorized_datasets = raw_datasets.map(prepare_dataset, remove_columns=raw_datasets_features)\n",
    "else:\n",
    "    vectorized_datasets = raw_datasets.map(\n",
    "        prepare_dataset,\n",
    "        remove_columns=raw_datasets_features,\n",
    "        # num_proc=1,\n",
    "        desc=\"preprocess dataset\",\n",
    "    )\n",
    "\n",
    "# for large datasets it is advised to run the preprocessing on a\n",
    "# single machine first with `args.preprocessing_only` since there will mostly likely\n",
    "# be a timeout when running the script in distributed mode.\n",
    "# In a second step `args.preprocessing_only` can then be set to `False` to load the\n",
    "# cached dataset\n",
    "if data_args.preprocessing_only:\n",
    "    cache = {k: v.cache_files for k, v in vectorized_datasets.items()}\n",
    "    logger.info(f\"Data preprocessing finished. Files cached at {cache}.\")\n",
    "    # return\n",
    "\n",
    "if data_args.streaming and dataloader_num_workers > 0:\n",
    "    logger.warning(\n",
    "        \"Using multiple dataloader num workers with streaming mode will result in different shards of \"\n",
    "        \"data being transcribed in parallel. This is not advised if you want to preserve the order of the \"\n",
    "        \"audio-text data.\"\n",
    "    )\n",
    "\n",
    "# Handle the repository creation\n",
    "output_dir = training_args.output_dir\n",
    "if training_args.push_to_hub:\n",
    "    if training_args.hub_model_id is None:\n",
    "        repo_name = get_full_repo_name(\n",
    "            Path(output_dir).absolute().name,\n",
    "            token=token,\n",
    "        )\n",
    "    else:\n",
    "        repo_name = training_args.hub_model_id\n",
    "    create_repo(repo_name, exist_ok=True, token=token, repo_type=\"dataset\", private=data_args.private_dataset)\n",
    "    repo = Repository(\n",
    "        output_dir,\n",
    "        clone_from=repo_name,\n",
    "        token=token,\n",
    "        repo_type=\"dataset\",\n",
    "    )\n",
    "    # Ensure large txt files can be pushed to the Hub with git-lfs\n",
    "    with open(os.path.join(output_dir, \".gitattributes\"), \"r+\") as f:\n",
    "        git_lfs_extensions = f.read()\n",
    "        if \"*.csv\" not in git_lfs_extensions:\n",
    "            f.write(\"*.csv filter=lfs diff=lfs merge=lfs -text\")\n",
    "else:\n",
    "    # this is where we'll save our transcriptions\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "# 8. Load Metric\n",
    "metric = evaluate.load(\"wer\")\n",
    "\n",
    "def compute_metrics(preds, labels, file_ids):\n",
    "    # replace padded labels by the padding token\n",
    "    for idx in range(len(labels)):\n",
    "        labels[idx][labels[idx] == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(preds, skip_special_tokens=True, decode_with_timestamps=return_timestamps)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    wer_ortho = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    # normalize everything and re-compute the WER\n",
    "    norm_pred_str = [normalizer(pred) for pred in pred_str]\n",
    "    norm_label_str = [normalizer(label) for label in label_str]\n",
    "    # for logging, we need the pred/labels to match the norm_pred/norm_labels, so discard any filtered samples here\n",
    "    pred_str = [pred_str[i] for i in range(len(norm_pred_str)) if len(norm_label_str[i]) > 0]\n",
    "    label_str = [label_str[i] for i in range(len(norm_label_str)) if len(norm_label_str[i]) > 0]\n",
    "    file_ids = [file_ids[i] for i in range(len(file_ids)) if len(norm_label_str[i]) > 0]\n",
    "    # filtering step to only evaluate the samples that correspond to non-zero normalized references:\n",
    "    norm_pred_str = [norm_pred_str[i] for i in range(len(norm_pred_str)) if len(norm_label_str[i]) > 0]\n",
    "    norm_label_str = [norm_label_str[i] for i in range(len(norm_label_str)) if len(norm_label_str[i]) > 0]\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=norm_pred_str, references=norm_label_str)\n",
    "\n",
    "    return {\"wer\": wer, \"wer_ortho\": wer_ortho}, pred_str, label_str, norm_pred_str, norm_label_str, file_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "RuwkOQkjHomk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 12. Define Training Schedule\n",
    "per_device_eval_batch_size = int(training_args.per_device_eval_batch_size)\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,  # <|startoftranscript|>\n",
    "    input_padding=\"longest\",\n",
    "    target_padding=\"max_length\",\n",
    "    max_target_length=max_label_length,\n",
    ")\n",
    "\n",
    "# 14. Define generation arguments - we need to do this before we wrap the models in DDP\n",
    "# so that we can still access the configs\n",
    "num_beams = (\n",
    "    training_args.generation_num_beams\n",
    "    if training_args.generation_num_beams is not None\n",
    "    else getattr(model.generation_config, \"num_beams\", 1)\n",
    ")\n",
    "\n",
    "gen_kwargs = {\n",
    "    \"max_length\": max_label_length,\n",
    "    \"num_beams\": num_beams,\n",
    "    \"return_timestamps\": return_timestamps,\n",
    "}\n",
    "if hasattr(model.generation_config, \"is_multilingual\") and model.generation_config.is_multilingual:\n",
    "    # forcing the language and task tokens helps multilingual models in their generations\n",
    "    gen_kwargs.update(\n",
    "        {\n",
    "            \"language\": data_args.language,\n",
    "            \"task\": data_args.task,\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjN4iScSHpsU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# 15. Prepare everything with accelerate\n",
    "model = accelerator.prepare(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UeOJVpJHrcB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_step_with_save(split=\"eval\"):\n",
    "    # ======================== Evaluating ==============================\n",
    "    eval_preds = []\n",
    "    eval_labels = []\n",
    "    eval_ids = []\n",
    "    eval_start = time.time()\n",
    "\n",
    "    eval_loader = DataLoader(\n",
    "        vectorized_datasets[split],\n",
    "        batch_size=per_device_eval_batch_size,\n",
    "        collate_fn=data_collator,\n",
    "        num_workers=dataloader_num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    eval_loader = accelerator.prepare(eval_loader)\n",
    "    batches = tqdm(eval_loader, desc=f\"Evaluating {split}...\", disable=not accelerator.is_local_main_process)\n",
    "\n",
    "    # make the split name pretty for librispeech etc\n",
    "    # split = split.replace(\".\", \"-\").split(\"/\")[-1]\n",
    "    output_csv = os.path.join(output_dir, f\"{split}-transcription.csv\")\n",
    "\n",
    "    for step, batch in enumerate(batches):\n",
    "        file_ids = batch.pop(\"file_ids\")\n",
    "        # Generate predictions and pad to max generated length\n",
    "        generate_fn = model.module.generate if accelerator.num_processes > 1 else model.generate\n",
    "        generated_ids = generate_fn(batch[\"input_features\"].to(dtype=torch_dtype), **gen_kwargs)\n",
    "        generated_ids = accelerator.pad_across_processes(generated_ids, dim=1, pad_index=tokenizer.pad_token_id)\n",
    "        # Gather all predictions and targets\n",
    "        file_ids, generated_ids, labels = accelerator.gather_for_metrics(\n",
    "            (file_ids, generated_ids, batch[\"labels\"])\n",
    "        )\n",
    "        eval_preds.extend(generated_ids.cpu().numpy())\n",
    "        eval_labels.extend(labels.cpu().numpy())\n",
    "        file_ids = tokenizer.batch_decode(file_ids, skip_special_tokens=True)\n",
    "        eval_ids.extend(file_ids)\n",
    "\n",
    "        if step % training_args.logging_steps == 0 and step > 0:\n",
    "            batches.write(f\"Saving transcriptions for split {split} step {step}\")\n",
    "            accelerator.wait_for_everyone()\n",
    "            if data_args.decode_token_ids:\n",
    "                eval_preds = tokenizer.batch_decode(\n",
    "                    eval_preds, skip_special_tokens=True, decode_with_timestamps=return_timestamps\n",
    "                )\n",
    "            csv_data = [[eval_ids[i], eval_preds[i]] for i in range(len(eval_preds))]\n",
    "\n",
    "            with open(output_csv, \"w\", encoding=\"UTF8\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                # write multiple rows\n",
    "                writer.writerow([\"file_id\", \"whisper_transcript\"])\n",
    "                writer.writerows(csv_data)\n",
    "\n",
    "            if training_args.push_to_hub and accelerator.is_main_process:\n",
    "                repo.push_to_hub(\n",
    "                    commit_message=f\"Saving transcriptions for split {split} step {step}.\",\n",
    "                    blocking=False,\n",
    "                )\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    eval_time = time.time() - eval_start\n",
    "\n",
    "    # compute WER metric for eval sets\n",
    "    wer_desc = \"\"\n",
    "    if \"validation\" in split or \"test\" in split:\n",
    "        wer_metric, pred_str, label_str, norm_pred_str, norm_label_str, eval_ids = compute_metrics(\n",
    "            eval_preds, eval_labels, eval_ids\n",
    "        )\n",
    "        wer_desc = \" \".join([f\"Eval {key}: {value} |\" for key, value in wer_metric.items()])\n",
    "        # Save metrics + predictions\n",
    "        # log_metric(\n",
    "        #     accelerator,\n",
    "        #     metrics=wer_metric,\n",
    "        #     train_time=eval_time,\n",
    "        #     prefix=split,\n",
    "        # )\n",
    "        # log_pred(\n",
    "        #     accelerator,\n",
    "        #     pred_str,\n",
    "        #     label_str,\n",
    "        #     norm_pred_str,\n",
    "        #     norm_label_str,\n",
    "        #     prefix=split,\n",
    "        # )\n",
    "        if data_args.decode_token_ids:\n",
    "            eval_preds = pred_str\n",
    "    elif data_args.decode_token_ids:\n",
    "        eval_preds = tokenizer.batch_decode(\n",
    "            eval_preds, skip_special_tokens=True, decode_with_timestamps=return_timestamps\n",
    "        )\n",
    "\n",
    "    batches.write(f\"Saving final transcriptions for split {split}.\")\n",
    "    csv_data = [[eval_ids[i], eval_preds[i]] for i in range(len(eval_preds))]\n",
    "    with open(output_csv, \"w\", encoding=\"UTF8\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        # write multiple rows\n",
    "        writer.writerow([\"file_id\", \"whisper_transcript\"])\n",
    "        writer.writerows(csv_data)\n",
    "\n",
    "    # Print metrics\n",
    "    logger.info(wer_desc)\n",
    "\n",
    "    if not data_args.streaming:\n",
    "        raw_datasets[split] = raw_datasets[split].add_column(\"whisper_transcript\", eval_preds)\n",
    "        \n",
    "    # return eval_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# train_100_df = pd.read_csv('librespeach_labeled/train-100-transcription.csv')\n",
    "# row = train_100_df['whisper_transcript'].iloc[-1]\n",
    "\n",
    "\n",
    "# def read_train_trans_array(row):\n",
    "#     array_str = row.replace('[', '').replace(']', '').replace('\\n', '')\n",
    "#     result_array = np.fromstring(array_str, sep=' ',dtype='int64')\n",
    "#     return result_array\n",
    "\n",
    "\n",
    "# train_100_df['whisper_transcript_arr'] = train_100_df['whisper_transcript'].apply(lambda row: read_train_trans_array(row))\n",
    "# eval_preds = train_100_df['whisper_transcript_arr'].to_list()\n",
    "# raw_datasets[split] = raw_datasets[split].add_column(\"whisper_transcript\", eval_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     wer_desc = \"\"\n",
    "#     if \"validation\" in split or \"test\" in split:\n",
    "#         wer_metric, pred_str, label_str, norm_pred_str, norm_label_str, eval_ids = compute_metrics(\n",
    "#             eval_preds, eval_labels, eval_ids\n",
    "#         )\n",
    "#         wer_desc = \" \".join([f\"Eval {key}: {value} |\" for key, value in wer_metric.items()])\n",
    "#         # Save metrics + predictions\n",
    "#         # log_metric(\n",
    "#         #     accelerator,\n",
    "#         #     metrics=wer_metric,\n",
    "#         #     train_time=eval_time,\n",
    "#         #     prefix=split,\n",
    "#         # )\n",
    "#         # log_pred(\n",
    "#         #     accelerator,\n",
    "#         #     pred_str,\n",
    "#         #     label_str,\n",
    "#         #     norm_pred_str,\n",
    "#         #     norm_label_str,\n",
    "#         #     prefix=split,\n",
    "#         # )\n",
    "#         if data_args.decode_token_ids:\n",
    "#             eval_preds = pred_str\n",
    "#     elif data_args.decode_token_ids:\n",
    "#         eval_preds = tokenizer.batch_decode(\n",
    "#             eval_preds, skip_special_tokens=True, decode_with_timestamps=return_timestamps\n",
    "#         )\n",
    "\n",
    "#     batches.write(f\"Saving final transcriptions for split {split}.\")\n",
    "#     csv_data = [[eval_ids[i], eval_preds[i]] for i in range(len(eval_preds))]\n",
    "#     with open(output_csv, \"w\", encoding=\"UTF8\", newline=\"\") as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         # write multiple rows\n",
    "#         writer.writerow([\"file_id\", \"whisper_transcript\"])\n",
    "#         writer.writerows(csv_data)\n",
    "\n",
    "#     # Print metrics\n",
    "#     logger.info(wer_desc)\n",
    "\n",
    "#     if not data_args.streaming:\n",
    "#         raw_datasets[split] = raw_datasets[split].add_column(\"whisper_transcript\", eval_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_pred_custom_table(\n",
    "    accelerator,\n",
    "    pred_str: List[str],\n",
    "    label_str: List[str],\n",
    "    norm_pred_str: List[str],\n",
    "    norm_label_str: List[str],\n",
    "    prefix: str = \"eval\",\n",
    "    num_lines: int = 200000,\n",
    "):\n",
    "    \"\"\"Helper function to log target/predicted transcriptions to weights and biases (wandb).\"\"\"\n",
    "    if accelerator.is_main_process:\n",
    "        wandb_tracker = accelerator.get_tracker(\"wandb\")\n",
    "        wandb_tracker.init(key='1f66b21fc46ede46b6bb2532b457545962b60ac4')\n",
    "        # pretty name for split\n",
    "        prefix = prefix.replace(\"/\", \"-\")\n",
    "\n",
    "        # convert str data to a wandb compatible format\n",
    "        str_data = [[label_str[i], pred_str[i], norm_label_str[i], norm_pred_str[i]] for i in range(len(pred_str))]\n",
    "        # log as a table with the appropriate headers\n",
    "        wandb_tracker.log_table(\n",
    "            table_name=f\"{prefix}/all_predictions\",\n",
    "            columns=[\"Target\", \"Pred\", \"Norm Target\", \"Norm Pred\"],\n",
    "            data=str_data[:num_lines],\n",
    "        )\n",
    "\n",
    "        # log incorrect normalised predictions\n",
    "        str_data = np.asarray(str_data)\n",
    "        str_data_incorrect = str_data[str_data[:, -2] != str_data[:, -1]]\n",
    "        # log as a table with the appropriate headers\n",
    "        wandb_tracker.log_table(\n",
    "            table_name=f\"{prefix}/incorrect_predictions\",\n",
    "            columns=[\"Target\", \"Pred\", \"Norm Target\", \"Norm Pred\"],\n",
    "            data=str_data_incorrect[:num_lines],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wandb_tracker = accelerator.get_tracker(\"wandb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wandb_tracker = accelerator.get_tracker(\"wandb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "94b72KMDHtJ6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/16/2024 12:37:57 - INFO - __main__ - ***** Running Labelling *****\n",
      "04/16/2024 12:37:57 - INFO - __main__ -   Instantaneous batch size per device = 32\n",
      "04/16/2024 12:37:57 - INFO - __main__ -   Total eval batch size (w. parallel & distributed) = 32\n",
      "04/16/2024 12:37:57 - INFO - __main__ -   Predict labels with timestamps = False\n",
      "04/16/2024 12:37:57 - INFO - __main__ -   Decode labels to transcriptions = False\n",
      "Evaluating train...:  13%|        | 100/744 [05:01<30:45,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving transcriptions for split train step 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train...:  27%|       | 200/744 [09:40<29:40,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving transcriptions for split train step 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train...:  40%|      | 300/744 [14:13<19:39,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving transcriptions for split train step 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train...:  54%|    | 400/744 [18:58<15:05,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving transcriptions for split train step 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train...:  67%|   | 500/744 [23:54<11:48,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving transcriptions for split train step 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train...:  81%|  | 600/744 [29:06<07:08,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving transcriptions for split train step 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train...:  94%|| 700/744 [33:58<02:02,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving transcriptions for split train step 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train...: 100%|| 744/744 [36:06<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving final transcriptions for split train.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/16/2024 13:14:05 - INFO - __main__ - \n",
      "Evaluating validation...:  33%|      | 100/306 [05:12<10:36,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving transcriptions for split validation step 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating validation...:  65%|   | 200/306 [10:04<05:03,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving transcriptions for split validation step 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating validation...:  98%|| 300/306 [14:58<00:17,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving transcriptions for split validation step 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating validation...: 100%|| 306/306 [15:14<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving final transcriptions for split validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/16/2024 13:29:27 - INFO - __main__ - Eval wer: 29.17995444191344 | Eval wer_ortho: 37.47467357046376 |\n",
      "Evaluating test...:  33%|      | 100/306 [05:16<10:10,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving transcriptions for split test step 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test...:  65%|   | 200/306 [10:07<05:04,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving transcriptions for split test step 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test...:  98%|| 300/306 [15:05<00:19,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving transcriptions for split test step 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test...: 100%|| 306/306 [15:21<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving final transcriptions for split test.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/16/2024 13:44:54 - INFO - __main__ - Eval wer: 30.21025763964294 | Eval wer_ortho: 39.2633676611993 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ae823424b146eaad1e2c79bbc9ac30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/4 shards):   0%|          | 0/23799 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144c5288f89f49d79c10a69c83ea1cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/4 shards):   0%|          | 0/9786 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1103bac27b4b34987c9d7212a779f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/4 shards):   0%|          | 0/9791 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e508338e8ff4415a96d3c26cfa16ec93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">smart-butterfly-18</strong> at: <a href='https://wandb.ai/zekamrozek/distil-whisper/runs/280y4v0c' target=\"_blank\">https://wandb.ai/zekamrozek/distil-whisper/runs/280y4v0c</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240416_123730-280y4v0c\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger.info(\"***** Running Labelling *****\")\n",
    "logger.info(\"  Instantaneous batch size per device =\" f\" {training_args.per_device_eval_batch_size}\")\n",
    "logger.info(\n",
    "    f\"  Total eval batch size (w. parallel & distributed) = {training_args.per_device_eval_batch_size * accelerator.num_processes}\"\n",
    ")\n",
    "logger.info(f\"  Predict labels with timestamps = {return_timestamps}\")\n",
    "logger.info(f\"  Decode labels to transcriptions = {data_args.decode_token_ids}\")\n",
    "for split in [#'train', 'validation', \n",
    "              'test'\n",
    "              ]:#data_splits:\n",
    "    eval_preds = eval_step_with_save(split=split)\n",
    "    accelerator.wait_for_everyone()\n",
    "    if training_args.push_to_hub and accelerator.is_main_process:\n",
    "        repo.push_to_hub(\n",
    "            commit_message=f\"Saving final transcriptions for split {split.replace('.', '-').split('/')[-1]}\",\n",
    "            blocking=False,\n",
    "        )\n",
    "if not data_args.streaming and accelerator.is_main_process:\n",
    "    raw_datasets.save_to_disk(output_dir, num_proc=num_workers)\n",
    "    if training_args.push_to_hub:\n",
    "        raw_datasets.push_to_hub(repo_name, config_name=data_args.dataset_config_name)\n",
    "accelerator.end_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "04/16/2024 12:37:57 - INFO - __main__ - ***** Running Labelling *****\n",
    "04/16/2024 12:37:57 - INFO - __main__ -   Instantaneous batch size per device = 32\n",
    "04/16/2024 12:37:57 - INFO - __main__ -   Total eval batch size (w. parallel & distributed) = 32\n",
    "04/16/2024 12:37:57 - INFO - __main__ -   Predict labels with timestamps = False\n",
    "04/16/2024 12:37:57 - INFO - __main__ -   Decode labels to transcriptions = False\n",
    "Evaluating train...:  13%|        | 100/744 [05:01<30:45,  2.87s/it]\n",
    "Saving transcriptions for split train step 100\n",
    "Evaluating train...:  27%|       | 200/744 [09:40<29:40,  3.27s/it]\n",
    "Saving transcriptions for split train step 200\n",
    "Evaluating train...:  40%|      | 300/744 [14:13<19:39,  2.66s/it]\n",
    "Saving transcriptions for split train step 300\n",
    "Evaluating train...:  54%|    | 400/744 [18:58<15:05,  2.63s/it]\n",
    "Saving transcriptions for split train step 400\n",
    "Evaluating train...:  67%|   | 500/744 [23:54<11:48,  2.90s/it]\n",
    "Saving transcriptions for split train step 500\n",
    "Evaluating train...:  81%|  | 600/744 [29:06<07:08,  2.98s/it]\n",
    "Saving transcriptions for split train step 600\n",
    "Evaluating train...:  94%|| 700/744 [33:58<02:02,  2.79s/it]\n",
    "Saving transcriptions for split train step 700\n",
    "Evaluating train...: 100%|| 744/744 [36:06<00:00,  2.91s/it]\n",
    "Saving final transcriptions for split train.\n",
    "04/16/2024 13:14:05 - INFO - __main__ - \n",
    "Evaluating validation...:  33%|      | 100/306 [05:12<10:36,  3.09s/it]\n",
    "Saving transcriptions for split validation step 100\n",
    "Evaluating validation...:  65%|   | 200/306 [10:04<05:03,  2.86s/it]\n",
    "Saving transcriptions for split validation step 200\n",
    "Evaluating validation...:  98%|| 300/306 [14:58<00:17,  2.91s/it]\n",
    "Saving transcriptions for split validation step 300\n",
    "Evaluating validation...: 100%|| 306/306 [15:14<00:00,  2.99s/it]\n",
    "Saving final transcriptions for split validation.\n",
    "04/16/2024 13:29:27 - INFO - __main__ - Eval wer: 29.17995444191344 | Eval wer_ortho: 37.47467357046376 |\n",
    "Evaluating test...:  33%|      | 100/306 [05:16<10:10,  2.96s/it]\n",
    "Saving transcriptions for split test step 100\n",
    "Evaluating test...:  65%|   | 200/306 [10:07<05:04,  2.87s/it]\n",
    "Saving transcriptions for split test step 200\n",
    "Evaluating test...:  98%|| 300/306 [15:05<00:19,  3.30s/it]\n",
    "Saving transcriptions for split test step 300\n",
    "Evaluating test...: 100%|| 306/306 [15:21<00:00,  3.01s/it]\n",
    "Saving final transcriptions for split test.\n",
    "04/16/2024 13:44:54 - INFO - __main__ - Eval wer: 30.21025763964294 | Eval wer_ortho: 39.2633676611993 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "116f8c908f1d42f9bee1525787dc60b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f5b8f35e56d492995c1ef3d824da234",
      "max": 28539,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1f7fd128e7ba4f2a8556a5a6997fd946",
      "value": 28539
     }
    },
    "17951ff284bc44cc8025a23d7403dfb5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bda516d2d99431ebe4694090fa5c8fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17951ff284bc44cc8025a23d7403dfb5",
      "max": 104014,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f8f7a9e8383f4dbba1199f8ae38c9de7",
      "value": 48474
     }
    },
    "1f7fd128e7ba4f2a8556a5a6997fd946": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "25eb176a19c340dda3b264a28e203cbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37a59b12c6d5445aa4266cea168f3a0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e8bd264b90b4b16a08d5ce3952f0561": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41fb328527f541afbc7c86e963f7ba21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f5b8f35e56d492995c1ef3d824da234": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a1b7e1a32494ac7bb671b7046d51c09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7732642b5f394f43b843346b9bb6300e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc514e78b8454182abd681ee7f196dd7",
      "placeholder": "",
      "style": "IPY_MODEL_fd01f17c91ff4fcc9c32fd3e674e52cf",
      "value": "preprocess dataset:  47%"
     }
    },
    "85230fee517245a1b9db2d19eb87a46f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ac4f7ff7d594defbe6a662f45affd3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7732642b5f394f43b843346b9bb6300e",
       "IPY_MODEL_1bda516d2d99431ebe4694090fa5c8fa",
       "IPY_MODEL_8b421cf642cd407491a002a3223fc00f"
      ],
      "layout": "IPY_MODEL_37a59b12c6d5445aa4266cea168f3a0f"
     }
    },
    "8b421cf642cd407491a002a3223fc00f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a1b7e1a32494ac7bb671b7046d51c09",
      "placeholder": "",
      "style": "IPY_MODEL_c02e564fec994102a5df7f2b8aac1af3",
      "value": " 48474/104014 [1:54:24&lt;1:51:28,  8.30 examples/s]"
     }
    },
    "a2b830af92a4492d89ea87e8280bf1b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b25f2d354f9c4ec3b1d81a8d1d039266": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25eb176a19c340dda3b264a28e203cbf",
      "placeholder": "",
      "style": "IPY_MODEL_3e8bd264b90b4b16a08d5ce3952f0561",
      "value": "preprocess dataset: 100%"
     }
    },
    "b50ac10536424294a4391bed34d4d101": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41fb328527f541afbc7c86e963f7ba21",
      "placeholder": "",
      "style": "IPY_MODEL_a2b830af92a4492d89ea87e8280bf1b7",
      "value": " 28539/28539 [1:05:38&lt;00:00, 10.22 examples/s]"
     }
    },
    "c02e564fec994102a5df7f2b8aac1af3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc514e78b8454182abd681ee7f196dd7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f66ef2a647a34ecda62ad1376ecc0787": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b25f2d354f9c4ec3b1d81a8d1d039266",
       "IPY_MODEL_116f8c908f1d42f9bee1525787dc60b0",
       "IPY_MODEL_b50ac10536424294a4391bed34d4d101"
      ],
      "layout": "IPY_MODEL_85230fee517245a1b9db2d19eb87a46f"
     }
    },
    "f8f7a9e8383f4dbba1199f8ae38c9de7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fd01f17c91ff4fcc9c32fd3e674e52cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
